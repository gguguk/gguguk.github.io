---
title: T-SNE μ΄ν•΄ν•κΈ°
author: Gukwon Koo
categories: [ML, Basic]
tags: [tsne]
pin: false
math: true
comments: false
date: 2025-08-30 14:52:00 +0900
---

T-SNEλ” κ³ μ°¨μ›μ μ„λ² λ”©μ„ μ €μ°¨μ›μΌλ΅ λ³€ν™ν•κ³  μ‹κ°ν™”ν™”μ—¬ μ„λ² λ”©μ„ ν’μ§λ“¤ λ€λµμ μΌλ΅ νμ•…ν•λ” κ²ƒμ„ λ•λ” λ€ν‘μ μΈ μ°¨μ› μ¶•μ† μ•κ³ λ¦¬μ¦μ…λ‹λ‹¤. μ‹¤μ λ΅ μ•„μ§λ„ ν„μ—…μ—μ„λ„ λ§μ΄ μ‚¬μ©λλ” μ•κ³ λ¦¬μ¦μ΄κ³ , μ—¬λ¬ λ…Όλ¬Έμ—μ„λ„ μ„λ² λ”©μ μ§μ„ μ‹κ°μ μΌλ΅ λ³΄μ—¬μ£ΌκΈ° μ„ν• λ°©λ²•μΌλ΅ λ§μ΄ ν™μ©λκ³  μμµλ‹λ‹¤.

κ·Έλ¬λ‚ μ–΄λ μκ°„ T-SNEμ μ›λ¦¬λ¥Ό μ™„λ²½ν•κ² μ΄ν•΄ν•μ§€ λ»ν•κ³  μ‚¬μ©ν•κ³  μλ‹¤λ” μƒκ°μ΄ λ“¤μ—μµλ‹λ‹¤. π«  μ•μΌλ΅ ν„μ—…μ—μ„ μ„λ² λ”©μ„ λ‹¤λ£° μΌμ΄ λ§μ•„μ§ κ²ƒ κ°™μ€ λλ‚μ΄ λ“¤μ–΄μ„ μ΄λ² κΈ°νμ— μ •ν™•ν• λ™μ‘ μ›λ¦¬λ¥Ό κ³µλ¶€ν•΄λ³΄μ•μµλ‹λ‹¤. κ³µλ¶€ν•΄λ³΄λ‹ ML κΈ°μ΄ μ΄λ΅ μ„ λ³µμµν•κΈ°μ—λ„ μΆ‹μ€ μ•κ³ λ¦¬μ¦μ΄λΌλ” μƒκ°μ΄ λ“¤λ”λΌκµ¬μ”. μ•μΌλ΅ μ„¤λ… λ“λ¦΄ λ‚΄μ©μ€ λ‹¤μμ λ°°κ²½ μ§€μ‹μ„ μ”κµ¬ν•©λ‹λ‹¤.

- Gaussian distribution
- T distribution
- KL-Divergence
- Gradient decent
- (μµμ…) PCA

<br>

# T-SNE = Gaussian + Student T + KL-Divergence + Gradient Decent

---

T-SNEμ ν•µμ‹¬ μ‘λ™ μ›λ¦¬λ” 4κ°μ ν‚¤μ›λ“λ΅ ν‘ν„ν•  μ μμµλ‹λ‹¤.

- **Gaussian distribution**: κ³ μ°¨μ› κ³µκ°„(μ›λ λ²΅ν„°λ“¤μ΄ μ΅΄μ¬ν•λ” κ³µκ°„)μ„ κ°€μ°μ‹μ• λ¶„ν¬λ΅ ν‘ν„ν•©λ‹λ‹¤. μ΄λ• μ›λ κ°€κΉμ΄ λ²΅ν„°λ“¤μ€ λ†’μ€ ν™•λ¥ κ°’μ„ κ°–λ„λ΅, κ·Έ λ°λ€λ” λ°λ€κ°€ λλ„λ΅ ν•©λ‹λ‹¤.
- **Student T-distribution**: μ €μ°¨μ› κ³µκ°„(μ‹κ°ν™”λ¥Ό μ„ν• κ³µκ°„, μΌλ°μ μ„ 2~3μ°¨μ›)μ„ T λ¶„ν¬λ΅ ν‘ν„ν•©λ‹λ‹¤. μ΄λ• κ³ μ°¨μ›μ—μ„ μ›λ κ°€κΉμ΄ λ²΅ν„°λ“¤μ€ λ†’μ€ ν™•λ¥ μ„ κ°€μ§€λ„λ΅, κ·Έ λ°λ€λ” λ°λ€κ°€ λλ„λ΅ ν‘ν„ν•λ” T λ¶„ν¬λ¥Ό μ°Ύλ” κ²ƒμ΄ λ©ν‘μ…λ‹λ‹¤.
- **KL-Divergence**: κ°€μ°μ‹μ• λ¶„ν¬μ™€ T λ¶„ν¬κ°€ μ°¨μ΄κ°€ λ‚λ” μ •λ„λ¥Ό κ³„μ‚°ν•©λ‹λ‹¤.
- **Gradient Decent**: KL-Divergenceμ κ°’μ— λ€ν• μ €μ°¨μ› λ²΅ν„°μ gradientλ¥Ό κ³„μ‚°ν•κ³ , KL-Divergenceκ°€ μ‘μ•„μ§€λ” λ°©ν–¥μΌλ΅ μ €μ°¨μ› λ²΅ν„°λ¥Ό μ μ§„μ μΌλ΅ μ΄λ™μ‹ν‚µλ‹λ‹¤.

<br>

##  μμ‹λ΅ ν•™μµ λ°©μ‹ μ§κ΄€μ μΌλ΅ μ΄ν•΄ν•΄ λ³΄κΈ°

---

T-SNEμ ν•™μµ λ°©μ‹μ„ μμ‹λ¥Ό λ“¤μ–΄λ΄…μ‹λ‹¤. μ§κ΄€μ μΌλ΅ μ΄ν•΄ν•κΈ° μ‰¬μΈ κ±°μμ”. T-SNEλ” λ¨Όμ € κ³ μ°¨μ›μ—μ„ κ° λ°μ΄ν„° ν¬μΈνΈ(μ: ν•™μƒ A, B)κ°€ μ„λ΅ **μ–Όλ§λ‚ κ°€κΉμ΄μ§€λ¥Ό κ³„μ‚°**ν•©λ‹λ‹¤.

- κ°€κΉμ°λ©΄: μ΄ λ‘μ€ μ„λ΅ λΉ„μ·ν•λ„¤
- λ©€λ©΄: μ΄ λ‘μ€ μ„λ΅ λ‹¤λ¥΄λ„¤



κ°™μ€ λ§μ„ **ν™•λ¥ **λ΅ ν‘ν„ν•λ©΄ μ΄λ ‡κ²λ„ ν‘ν„ν•  μ μμµλ‹λ‹¤.

- κ°€κΉμ°λ©΄: μ΄ λ‘μ΄ μ„λ΅ μΉκµ¬μΌ ν™•λ¥ μ€ 0.8
- λ©€λ©΄: μ΄ λ‘μ΄ μ„λ΅ μΉκµ¬μΌ ν™•λ¥ μ€ 0.1



μ΄μ  λ°μ΄ν„° ν¬μΈνΈλ¥Ό μ €μ°¨μ› κ³µκ°„(μ: 2μ°¨μ›)μ— λ°°μΉν•λ”λ°, μ΄ λ• **μ„μ—μ„ κ³„μ‚°ν• μΉκµ¬μΌ ν™•λ¥ μ„ μµλ€ν• μ μ§€ν•λ” κ²ƒ**μ΄ μ¤‘μ”ν•©λ‹λ‹¤.

- κ³ μ°¨μ›μ—μ„ **κ°€κΉμ› λ‹¤λ©΄**: μ €μ°¨μ› κ³µκ°„μ—μ„λ„ μ„λ΅ μΉκµ¬μΌ ν™•λ¥ μ„ **ν¬κ²**
- κ³ μ°¨μ›μ—μ„ **λ©€μ—λ‹¤λ©΄**: μ €μ°¨μ› κ³µκ°„μ—μ„λ„ μ„λ΅ μΉκµ¬μΌ ν™•λ¥ μ„ **μ‘κ²**



κ³ μ°¨μ› κ³µκ°„μ ν™•λ¥ κ³Ό μ €μ°¨μ› κ³µκ°„μ ν™•λ¥  κµ¬μ΅°λ¥Ό λΉ„μ·ν•κ² μ μ§€ν•κΈ° μ„ν•΄μ„ **λ²μ μ„ λ¶€κ³Ό**ν•©λ‹λ‹¤.

- κ³ μ°¨μ›μ—μ„ κ°€κΉμ› μ§€λ§(ν™•λ¥  νΌ) μ €μ°¨μ›μ—μ„ λ©€λ©΄(ν™•λ¥  μ‘μ): λ²μ μ΄ μ»¤μ§
- κ³ μ°¨μ›μ—μ„ κ°€κΉμ› κ³ (ν™•λ¥  νΌ) μ €μ°¨μ›μ—μ„λ„ κ°€κΉμ°λ©΄(ν™•λ¥  νΌ): λ²μ μ΄ μ‘μ•„μ§



λ§μ§€λ§‰μΌλ΅ μ΄ **λ²μ μ„ μ¤„μ΄κΈ° μ„ν• λ°©ν–¥**μΌλ΅ **μ €μ°¨μ› κ³µκ°„μ λ°μ΄ν„° ν¬μΈν„°λ¥Ό μ μ§„μ μΌλ΅ μ΄λ™**μ‹ν‚µλ‹λ‹¤.

- λ²μ μ΄ ν° λ²΅ν„°: λ²μ μ΄ μ‘μ•„μ§€λ” λ°©ν–¥μΌλ΅ ν¬κ² μ΄λ™ μ‹ν‚΄
- λ²μ μ΄ μ‘μ€ λ²΅ν„°: λ²μ μ΄ μ‘μ•„μ§€λ” λ°©ν–¥μΌλ΅ μ‘κ² μ΄λ™ μ‹ν‚΄

<br>

## μμ‹κ³Ό ν•¨κ» λ” μμ„Έν μ΄ν•΄ν•΄ λ³΄κΈ°

---

T-SNEμ ν•™μµ λ°©μ‹μ„ μμ‹λ¥Ό ν†µν•΄ μ§κ΄€μ μΌλ΅ μ΄ν•΄ν•΄ λ³΄μ•μµλ‹λ‹¤. μ΄μ  μμ‹μ„ κ³λ“¤μ—¬μ„ μΆ€ λ” μμ„Έν μ΄ν•΄ν•΄ λ³΄μ£ !



### κ³ μ°¨μ› ν™•λ¥  λ¶„ν¬ μ •μ - κ°€μ°μ‹μ• λ¶„ν¬

![](/assets/img/post_img/normal_distribution_pdf.png){:width="250"}_κ°€μ°μ‹μ• λ¶„ν¬ _



T-SNEλ” κ³ μ°¨μ› κ³µκ°„μ— λ°μ΄ν„° ν¬μΈνΈ $$ x_i, \cdots, x_N $$κ°€ μμ„ λ•($$i \neq j$$) $$x_i$$μ™€ $$x_j$$μ μ μ‚¬λ„(κ±°λ¦¬)μ— λΉ„λ΅€ν•λ” ν™•λ¥  λ¶„ν¬ $$p_{ij}$$λ¥Ό κ³„μ‚°ν•λ” κ²ƒμ΄ μ²«λ²μ§Έ λ©ν‘μ…λ‹λ‹¤. μ΄λ¥Ό μ„ν•΄ $$x_i$$κ°€ $$x_j$$λ¥Ό μ΄μ›ƒμΌλ΅ μ„ νƒν•  ν™•λ¥  $$p_{j \mid i}$$λ¥Ό μ΅°κ±΄λ¶€ ν™•λ¥ λ΅ λ‚νƒ€λƒ…λ‹λ‹¤. μ΄ λ•, $$p_{i \mid i} = 0$$μ΄κ³  $$\sum_{j}P_{j \mid i}=1, \forall i$$μ…λ‹λ‹¤.



$$
p_{j \mid i} = \frac{\exp\!\left(-\| \mathbf{x}_i - \mathbf{x}_j \|^2 / 2\sigma_i^2 \right)}
{\sum_{k \neq i} \exp\!\left(-\| \mathbf{x}_i - \mathbf{x}_k \|^2 / 2\sigma_i^2 \right)}
$$



μ΄ μμ‹μ€ $$\mathbf{x}_i$$λ¥Ό **ν‰κ· **μΌλ΅ ν•λ” **κ°€μ°μ‹μ• λ¶„ν¬**μ μμ‹κ³Ό μ‚¬μ‹¤μƒ κ°™λ‹¤λ” κ²ƒμ„ μ• μ μμµλ‹λ‹¤.



$$
N(x; \mu, \sigma^2) = \cfrac{1}{\sqrt{2\pi\sigma^2}} \exp(- (x-\mu)^2/2\sigma^2)
$$



μ¦‰, κ³ μ°¨μ› κ³µκ°„μ—μ„μ λ²΅ν„°μ κ±°λ¦¬λ¥Ό ν™•λ¥ λ΅ λ³€ν™ν•λ”λ° μ΄λ• κ°€μ°μ‹μ• λ¶„ν¬λ¥Ό ν™μ©ν•λ‹¤λ” κ²ƒμ„ μ• μ μμµλ‹λ‹¤. λν• $$p_{j \mid i}$$μ λ¶„λ¨μ μμ‹μ— μν•΄ μ‹μ΄ λ…Έλ§λΌμ΄μ¦ λλ©΄μ„ $$\sum_{j}P_{j \mid i}=1, \forall i$$κ°€ λ§μ΅±λ  μ μμμ„ μ• μ μμµλ‹λ‹¤.



λ§μ§€λ§‰μΌλ΅ μ΅°κ±΄λ¶€ ν™•λ¥ μ„ λ€μΉ­ ν™•λ¥ λ΅ λ³€ν™ν•©λ‹λ‹¤. μ΄λ” $$i$$μ™€ $$j$$κ°€ μ„λ΅ μ΄μ›ƒμΌ ν™•λ¥  μ •λ„λ΅ ν•΄μ„ν•λ©΄ λ©λ‹λ‹¤.



$$
p_{ij} = \cfrac{p_{j \mid i} + p_{i \mid j}}{2N}
$$



ν•νΈ, $$p_{j \mide i}$$ μμ‹μ—μ„ $$\sigma_i^2$$μ€ λ°μ΄ν„° ν¬μΈνΈμ— κ°λ³„μ μΌλ΅ κ²°μ •λλ”λ°, μ΄λ” T-SNEμ ν•μ΄νΌνλΌλ―Έν„°μΈ perplexityμ— λ”°λΌ κ°’μ΄ κ²°μ •λ©λ‹λ‹¤. perplexityλ” μ•„λμ—μ„ λ” μμ„Έν μ„¤λ…ν•κ² μµλ‹λ‹¤.



<br>

### μ €μ°¨μ› ν™•λ¥  λ¶„ν¬ μ •μ - T λ¶„ν¬

![](/assets/img/post_img/student_t_pdf.png){:width="250"}_μμ λ„μ— λ”°λ¥Έ Student-t λ¶„ν¬ _

μ €μ°¨μ›μ—μ„λ” T λ¶„ν¬μ— κΈ°λ°ν•μ—¬ λ‘ λ²΅ν„°κ°„μ κ±°λ¦¬λ¥Ό ν™•λ¥ μ κ°λ…μΌλ΅ ν‘ν„ν•λ” κ²ƒλ§ μ μ™Έν•λ©΄ μ„ μ ‘κ·Όλ²•κ³Ό κ±°μ μ μ‚¬ν•©λ‹λ‹¤. μ €μ°¨μ› κ³µκ°„μ— $$ y_1, \cdots, y_N (y_i \in \mathbb{R}^d)$$ λ°μ΄ν„° ν¬μΈνΈκ°€ μ΅΄μ¬ν•  λ•, μ•„λ μμ‹μΌλ΅ λ‘ λ°μ΄ν„° ν¬μΈνΈ $$y_i$$μ™€ $$y_j$$ μ‚¬μ΄μ κ±°λ¦¬(μ μ‚¬λ„)λ¥Ό ν™•λ¥  $$q_{ij}$$λ΅ λ³€ν™ν•©λ‹λ‹¤.


$$
q_{ij} = \frac{(1 + \| \mathbf{y}_i - \mathbf{y}_j \|^2)^{-1}}
{\sum_k \sum_{l \neq k} (1 + \| \mathbf{y}_k - \mathbf{y}_l \|^2)^{-1}}
$$


μ΄ μμ‹μ€ μμ λ„κ°€ 1μΈ student t-λ¶„ν¬μ™€ μ‚¬μ‹¤μƒ κ°™λ‹¤λ” κ²ƒμ„ μ• μ μμµλ‹λ‹¤. λ¨Όμ € student t-λ¶„ν¬μ PDFλ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.


$$
f(t; \nu) = \frac{\Gamma\!\left(\tfrac{\nu+1}{2}\right)}{\sqrt{\pi \nu}\,\Gamma\!\left(\tfrac{\nu}{2}\right)}\left(1 + \frac{t^2}{\nu}\right)^{-\tfrac{\nu+1}{2}}
$$


μ΄λ• $$\nu = 1$$μ΄λΌκ³  ν•λ‹¤λ©΄, λ‹¤μκ³Ό κ°™μ΄ ν‘ν„ν•  μ μμµλ‹λ‹¤.
$$
f(t) = c\left(1 + t^2\right)^{-1}
$$
<br>

### μ €μ°¨μ› λ°μ΄ν„° ν¬μΈνΈ μ—…λ°μ΄νΈ - KL-Divergence & gradient descent

μ§€κΈκΉμ§€ λ…Όμλ¥Ό ν†µν•΄μ„ μ›λ κ³ μ°¨μ› κ³µκ°„μ—μ„μ λ°μ΄ν„° ν¬μΈνΈ κ°„μ κ±°λ¦¬λ¥Ό ν™•λ¥ λ΅ ν‘ν„ν•κ³ , λΉ„μ·ν• λ°©λ²•μΌλ΅ μ €μ°¨μ› κ³µκ°„μ—μ„μ λ°μ΄ν„° ν¬μΈνΈ κ°„μ κ±°λ¦¬λ¥Ό ν™•λ¥ λ΅ ν‘ν„ν•λ” λ°©λ²•μ„ μ‚΄ν΄ λ³΄μ•μµλ‹λ‹¤. κ·Έλ ‡λ‹¤λ©΄, μ €μ°¨μ› κ³µκ°„μ—μ„ κ²°μ •λ λ°μ΄ν„° ν¬μΈνΈκ°€ μ μ‚¬μƒλ κ²ƒμΈμ§€ μ–΄λ–»κ² κ²€μ¦ν•  μ μμ„κΉμ”? κ·Έλ¦¬κ³  λ°μ΄ν„° ν¬μΈνΈλ¥Ό λ” μ μ ν• μ„μΉλ΅ μ®κΈ°λ ¤λ©΄ μ–΄λ–»κ² ν•΄μ•Όν• κΉμ”? μ΄λ• λ”¥λ¬λ‹μ ν•™μµμ κΈ°λ°μ΄ λλ” μ λ…ν• KL-Divergenceμ™€ gradient descentκ°€ ν™μ©λ©λ‹λ‹¤.



λ¨Όμ €, KL-Divergenceλ” μ•„λμ μμ‹μ΄κ³ , μ΄ μμ‹μ€ ν™•λ¥  λ¶„ν¬ $$p_{ij}$$μ™€ $$q_{ij}$$μ μ°¨μ΄λ¥Ό μΈ΅μ •ν•κ² λ©λ‹λ‹¤.
$$
KL(P \parallel Q) = \sum_{i \neq j} p_{ij} \log \frac{p_{ij}}{q_{ij}}
$$


λ§μ§€λ§‰μΌλ΅ κ³„μ‚°λ KL-Divergenceλ¥Ό $$y_{i}$$μ— λ€ν•΄ λ―Έλ¶„ν•μ—¬ gradientλ¥Ό μ–»κ³ , μ΄λ¥Ό ν™μ©ν•μ—¬ $$y_i$$μ κ°’μ„ λ³€κ²½ν•λ” gradienct descentλ¥Ό μ μ©ν•κ² λ©λ‹λ‹¤. κ²°κ³Όμ μΌλ΅ λ”°λΌμ„ T-SNEλ” κ³ μ°¨μ› κ³µκ°„μ—μ„μ λ¶„ν¬λ¥Ό μ λ°μν•  μ μλ” μ €μ°¨μ› κ³µκ°„μ„ μ°Ύλ” μ°¨μ› μ¶•μ† μ•κ³ λ¦¬μ¦μ΄λΌκ³  λ³Ό μ μμµλ‹λ‹¤.


$$
y_i \leftarrow y_i - \eta \cfrac{\partial KL(P \parallel Q)}{\partial y_i}{}
$$




## ν•μ΄νΌνλΌλ―Έν„°

- perplexity: μ΄μ›ƒ μμ— λ€ν• κΈ°λ“κ°’





# μ°Έκ³ μλ£

- [t-distributed stochastic neighbor embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding#External_links)
- [Student's t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution)

