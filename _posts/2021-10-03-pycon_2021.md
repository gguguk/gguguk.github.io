---
title: Pycon 2021 발표 요약
author: Gukwon Koo
categories: [Conference, Pycon]
tags: [pycon, python]
pin: false
math: false
comments: false
date: 2021-10-03 18:59:00 +0900
---

[파이콘 2021](https://2021.pycon.kr/session/) 발표 영상을 보면서 인상 깊었던 발표를 간단하게 요약합니다.

<br>

## 기획자가 한 번 추천한 음식은 '당분간' 추천하지 말라고 했다.

---

- 인간의 정성적 심리 상태를 정량화 하려는 시도가 돋보임
  - 한번 추천 했던 음식은 언제 다시 먹고 싶을까?
  - 3일 뒤면 다시 100% 먹고 싶어 진다는 가설에서 출발해서 그 심리 상태를 회복하기까지의 변화를 정량적으로 측정
- 여러가지 그래프(단조증가함수, 지수함수, 시그모이드 함수)를 찾아가는 과정이 재미있었음
- 기획 -> 리서치 -> 코드 구현 -> 적용의 cycle을 빨리 돌려서 문제점을 개선해 나가는 과정이 인상 깊었음
- (연사분께서도 말씀하셨지만) 추천 가중치 조절 이후에 목표 지표가 어떻게 변화 했는지 궁금했음
- 회사에서 시퀀스 기반 추천에 exponential decay 함수를 통해 최신성에 대한 가중치 조절을 검토해 본 적 있는데 실행에 옮기진 못함. 이번 기회에 실험 해 봐도 좋을듯.
- A/B 테스트가 가능한 환경이 선행 되어야 의미 있는 작업이 될 수 있을 것 같음

<br>

## 파이썬이 빅테이터를 다루기엔 느리다구요?

---

- 빅데이터 처리의 사실상의 표준(de facto standard)인 spark
- 고수준 API인 DataFrame을 쓴다면 pyspark도 scala 만큼의 성능 낼 수 있음. 성능 차이가 작다고 함
- pyspark best practice를 알려 줘서 좋았음. 팀원들에게도 전달할 필요성이 있겠음
  - RDD 대신 DataFrame을 사용: DF를 쓴다면 쿼리 분석 및 실행 계획이 자동으로 최적화 됨
  - UDF를 최대한 피해라
    - UDF는 spark 입장에서 블랙박스. 따라서 최적화가 어려움
    - 최대한 내장 함수를 찾아보고 그래도 없을 때만 UDF를 활용하라
  - UDF를 써야만 한다면 python UDF가 아니라 pandas UDF를 써라
    - python UDF 대신 pandas UDF 도입시 성능이 3~100배 향상 가능

- 더욱 pythonic한 spark를 만들기 위한 프로젝트들이 계속 생겨나고 있음
  - project Zen
    - pyspark를 보다 더 python스럽게 하자
  - pandas API on Spark
    - 기존에는 [koals](https://koalas.readthedocs.io/en/latest/)라는 이름으로 따로 진행된 프로젝트였으나 pyspark 3.2 버전부터 spark 생태계에 포함됨
    - pandas API를 그대로 pyspark에서 활용 가능함
- 버전업이 되면서 pandas에 익숙한 분석가나 사이언티스트에게 더욱 친화적으로 변화되고 있다는 사실을 알 수 있었음
  - 데이터 엔지니어 팀원과 함께 기존 아키텍처와 spark 3.2 버전의 호환성 및 안정성 확인 필요
  - 분석용으로 충분히 도입할만 하다면 분석가나 사이언티스트에게 큰 도움이 될 것 같음 (pyspark를 쓰기 위한 러닝 커브가 낮음)

<br>

## Reference

---

- [PYCON.KR 2021](https://2021.pycon.kr/)
- [Koalas: pandas API on Apache Spark](https://koalas.readthedocs.io/en/latest/)
- [Koalas: 스파크에서 쓰는 Pandas API](https://pizzathief.oopy.io/10min-koalas)
