<!DOCTYPE html><html lang="en" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"><meta http-equiv="Expires" content="0"><meta http-equiv="Pragma" content="no-cache"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="중심 극한 정리(CLT, Central Limit Theorem)" /><meta name="author" content="Gukwon Koo" /><meta property="og:locale" content="en" /><meta name="description" content="데이터 사이언스, 추천 시스템, Data Science, Recommender" /><meta property="og:description" content="데이터 사이언스, 추천 시스템, Data Science, Recommender" /><link rel="canonical" href="https://gguguk.github.io/posts/CLT/" /><meta property="og:url" content="https://gguguk.github.io/posts/CLT/" /><meta property="og:site_name" content="생각과 고민." /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-12-11T13:32:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="중심 극한 정리(CLT, Central Limit Theorem)" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@Gukwon Koo" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Gukwon Koo"},"dateModified":"2020-12-11T13:32:00+09:00","datePublished":"2020-12-11T13:32:00+09:00","description":"데이터 사이언스, 추천 시스템, Data Science, Recommender","headline":"중심 극한 정리(CLT, Central Limit Theorem)","mainEntityOfPage":{"@type":"WebPage","@id":"https://gguguk.github.io/posts/CLT/"},"url":"https://gguguk.github.io/posts/CLT/"}</script><title>중심 극한 정리(CLT, Central Limit Theorem) | 생각과 고민.</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="생각과 고민."><meta name="application-name" content="생각과 고민."><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/sample/bear.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">생각과 고민.</a></div><div class="site-subtitle font-italic">주니어 데이터 사이언티스트입니다.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/gguguk" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/%EA%B5%AD%EC%9B%90-%EA%B5%AC-32a9691a1/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>중심 극한 정리(CLT, Central Limit Theorem)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>중심 극한 정리(CLT, Central Limit Theorem)</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Gukwon Koo </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Dec 11, 2020, 1:32 PM +0900" >Dec 11, 2020<i class="unloaded">2020-12-11T13:32:00+09:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2558 words">14 min read</span></div></div><div class="post-content"><p><img data-proofer-ignore data-src="https://upload.wikimedia.org/wikipedia/commons/c/cd/Clt_in_action.gif" alt="https://upload.wikimedia.org/wikipedia/commons/c/cd/Clt_in_action.gif" /></p><p>석사과정 때부터 중심극한정리에 의해서 표본의 크기가 30 이상이면 정규분포가 되어서…’ 라는 말을 많이 들어왔습니다. 그래서 ‘설문자료를 수집할 때 표본이 30개 이상이면 분석을 할 수 있겠구나…’ 라고 단순하게 생각 했던 때가 있었는데요. 최근에 하버드 확률론 기초 강의(Statistics 110)를 수강하면서 수업 말미에 등장한 중심극한정리에 대한 내용을 들으면서 제가 너무 단순하게 알고 있었다는 것을 깨달았습니다. 그래서 이 주제로 정리를 꼭 한번 해봐야지라고 생각하고 있었는데, 제가 생각 했던 것 보다 어려운 개념이었습니다… 😩 이 분야를 공부하면 정말 겸손해지네요. 아무튼 제가 아는 선에서 중심극한정리에 대한 내용을 담아 냈습니다. 틀린 부분 있으면 지적해 주시면 감사하겠습니다.</p><p><br /></p><h2 id="1--중심-극한-정리central-limit-theorem-clt란">1   중심 극한 정리(Central Limit Theorem, CLT)란?</h2><hr /><h3 id="정의">정의</h3><p>중심 극한 정리란 i.i.d. 확률 변수 \(X_1, X_2, ...\) 가 표본의 크기 \(n\)이 \(\infty\)에 다가가면, 표본평균 \(\bar{X}\)의 분포가 정규 분포에 분포 수렴한다는 정리을 말합니다. 만약 표본 평균이 표준화(standardization)된 상태(\(\mu=0, \sigma^2=1\))이면 표준 정규 분포에 수렴합니다.</p><h3 id="큰수의-법칙으로는-표본의-분포shape를-알-수-없다">큰수의 법칙으로는 표본의 분포(shape)를 알 수 없다.</h3><p>먼저 큰수의 법칙을 다시 상기해 봅시다. 큰수의 법칙은 모집단에서 추출한 표본 \(X_1, X_2, \cdots, X_n\) 이 i.i.d. 이면서 평균 \(\mu\), 분산 \(\sigma^2\)를 따를 때, \(n \rightarrow \infty\)이면 \(\bar{X}\)가 1의 확률로 \(\mu\)에 수렴함을 말합니다. 그러나 큰수의 법칙은 표본 평균 \(\bar{X}\)의 shape 즉, 분포 대해서는 전혀 알려 주지 못합니다.</p><h3 id="중심-극한-정리는-표본의-분포shape를-설명할-수-있다">중심 극한 정리는 표본의 분포(shape)를 설명할 수 있다.</h3><p>그렇다면 \(n \rightarrow \infty\)일때, \(\bar{X}\)의 <strong>분포</strong>는 어떤지 알 수 있을까요? 결론적으로 말하면 중심 극한 정리를 통해 표본 평균 \(\bar{X}\)의 분포를 설명할 수 있습니다. 중심 극한 정리는 모집단에서 크기가 \(n\)인 표본 \(X_1, X_2, \cdots, X_n\)을 임의 복원 추출 했을 때 \(n \rightarrow \infty\) 이면 표본평균 \(\bar{X}\)는 정규 분포에 수렴한다는 것을 말합니다. 만일 표본 평균 \(\bar{X}\)가 표준화(standardization)되었다면, 표준 정규 분포에 수렴합니다.</p>\[\text{As } n \rightarrow \infty, \\\] \[\cfrac{\sqrt{n}\big(\bar{X}_{n}-\mu \big)}{\sigma} \rightarrow N(0,1)\]<p>참고로 표준화 되지 않은 표본 평균은 \(n\)이 충분히 크다면, 평균 \(\mu\), 분산 \(\cfrac {\sigma^2} {n}\)인 정규분포를 따릅니다.</p>\[\text{As } n \rightarrow \infty,\\[1em]\] \[\bar{X}_n \rightarrow N\bigg(\mu, \cfrac{\sigma^2}{n}\bigg)\]<p><br /></p><h2 id="2-표본-평균의-평균과-분산-계산">2   표본 평균의 평균과 분산 계산</h2><hr /><h3 id="표본-평균은-확률-변수">표본 평균은 확률 변수</h3><p>먼저 반드시 헷갈리지 말아야 할 것이 <strong>표본 평균(sample mean)은 확률 변수</strong>라는 점입니다. 따라서 표본 평균은 기대값(표본평균의 평균), 분산(표본평균의 분산), 표준 편차(표본평균의 표준편차)를 가지게 됩니다. 말이 굉장히 헷갈릴 수 있으므로 주의해서 살펴보셔야 합니다.</p><h3 id="표본-평균의-평균기대값">표본 평균의 평균(기대값)</h3>\[\begin{aligned} E(\bar{X}_n) &amp;= E\bigg(\cfrac{1}{n}\bigg(X_1+\cdots+X_n\bigg)\bigg) \\ &amp;= \cfrac{1}{n}E\bigg(X_1+\cdots + X_n \bigg) \\ &amp;= \cfrac{1}{n}\bigg(E(X_1)+\cdots+E(X_n)\bigg) \\ &amp;= \cfrac{1}{n} \cdot n \cdot \mu \\ &amp;= \mu \end{aligned}\]<h3 id="표본-평균의-표준편차">표본 평균의 표준편차</h3>\[\begin{aligned} Var(\bar{X}_n) &amp;= Var\bigg(\cfrac{1}{n}\bigg(X_1+\cdots+X_n\bigg)\bigg) \\ &amp;= \cfrac{1}{n^2}\cdot Var\bigg(X_1+ \cdots + X_n \bigg) \\ &amp;= \cfrac{1}{n^2} \cdot \bigg(Var(X_1)+\cdots+Var(X_n)\bigg) \\ &amp;= \cfrac{1}{n^2} \cdot n \cdot \sigma^2 \\ &amp;= \cfrac{\sigma^2}{n} \\ \therefore \space SD(\bar{X}_n) &amp;= \cfrac{\sigma}{\sqrt{n}} \end{aligned}\]<h3 id="표본-평균의-표준화">표본 평균의 표준화</h3><p>먼저 표준화는 다음의 수식을 따릅니다. 그 결과 평균이 0, 분산 1이 되는 분포로 변화됩니다.</p>\[\cfrac{X-E(X)}{\sigma}\]<p>이를 활용해 표본 평균을 표준화 하면 아래의 값이 도출 됩니다.</p>\[\begin{aligned} \cfrac{\bar{X}_n-E(\bar{X}_n)}{SD(\bar{X}_n)} &amp;= \cfrac{\bar{X}_n-\mu}{\cfrac{\sigma}{\sqrt{n}}} \\[1em] &amp;= \cfrac{\sqrt{n}(\bar{X}_n-\mu)}{\sigma} \end{aligned}\]<p>참고로 표준화의 의미는 평균을 0, 분산을 1로 강제하는 것이지만 단순히 scaling, shift를 한 것이지 원래의 분포의 모양 자체를 바꿀 수는 없습니다. 다시 말해 표준화 한다고 해서 원래 정규 분포가 아닌 어떤 분포가 표준 정규 분포로 바뀌는 것은 아닙니다. 아래 그림을 보면 원래 분포(Before)를 표준화하여 \(\mu=0, \sigma^2=1\)로 만들었는데요. 그 결과가 <strong>표준 정규 분포가 아닙니다.</strong></p><p><img data-proofer-ignore data-src="https://i.stack.imgur.com/TOPfn.png" alt="분포의 표준화 예시" /></p><p><br /></p><h2 id="3--중심-극한-정리는-왜-중요할까">3   중심 극한 정리는 왜 중요할까?</h2><hr /><p>위에서 중심 극한 정리가 어떤 의미인지 살펴보았습니다. 그런데 중심 극한 정리의 놀라운 점은 i.i.d. 가정이 충족되고 유한한 평균 \(\mu\) 및 분산 \(\sigma^2\)만 정의 된다면 <strong>원래의 분포 \(X_j\)의 어떠한 정보가 없더라도 표본 평균의 분포가 표평균 \(\mu\), 분산 \(\cfrac{\sigma^2}{\sqrt{n}}\)인 정규 분포에 가까워 진다는 것을 알려 준다는 점</strong>입니다.</p><p>따라서 우리는 중심 극한 정리에 기반하여, 표본의 크기가 충분하다면 내가 수집한 표본의 표본 평균이 발생할 확률을 정규 분포에서 계산할 수 있게 됩니다. 특히 이러한 통계적 추론은 모집단의 분포가 어떤 모양이든지 관계 없이 가능 하다는 점에서 엄청난 편의성을 제공합니다. 정리하자면, 중심 극한 정리는 표본 평균과 모집단 간의 관계를 나타냄으로써 표본 통계량(statistics)를 이용해 모수(parameter)를 추정할 수 있는 수학적 근거를 제시합니다. 따라서 중심 극한 정리는 통계에서 가장 중요한 이론적 근거라고 하겠습니다.</p><p>여기부터는 사견입니다. 왜 모집단의 ‘분포’ 자체를 추정하지 않고 모집단의 ‘모수’를 추정하려고 할까요? 그 이유는 2가지 인 것 같습니다. 먼저, 모집단의 분포를 우리는 알 수 없습니다. 모집단의 분포를 알 수 없기에 통계적 추정을 하는 것이죠. 그리고 어떤 분포의 모수(모평균, 모분산 등)를 알면 그 분포를 거의 정확하게 그려 낼 수 있습니다. 우리가 흔히 들어 본 정규 분포, 이항 분포, 베타 분포 등 다양한 분포는 평균과 분산만 알면 그 PDF, PMF 식을 알 수 있습니다.</p><p><br /></p><h2 id="4중심-극한-정리를-증명해-보자">4  중심 극한 정리를 증명해 보자!</h2><hr /><h3 id="적률-생성-함수의-성질">적률 생성 함수의 성질</h3><p>증명을 위해서는 MGF(적률 생성 함수), 로피탈의 정리에 대한 사전 지식이 필요합니다. 이와 관련해서는 쉽고 자세 하게 정리된 글들이 많으니 자세한 내용은 해당 글들을 먼저 참고 부탁드립니다 🙏 간단히 언급하자면, 다음과 같은 적률 생성 함수의 성질에 대한 사전 지식이 필요합니다.</p><ul><li>확률 변수 \(X\), \(Y\)가 독립이라면, \(M_{X+Y}(t) = M_{X}(t)M_{Y}(t)\)<li>어떤 두 확률 분포의 적률 생성 함수가 동일하면, 두 확률 분포는 동일합니다.</ul><h3 id="증명-순서">증명 순서</h3><p>이제 수식을 통해 증명을 해보겠습니다. 증명 순서는 다음과 같습니다.</p><ul><li>표준화(standardization)한 표본 평균의 적률 생성 함수를 구합니다.<li>해당 함수를 \(n \rightarrow \infty\)로 보내 봅니다.<li>이 때 구해지는 적률 생성 함수가 표준 정규 분포의 적률 생성 함수와 동일하다는 것을 확인합니다.<li>따라서 표본의 크기가 충분히 클때 표본 평균은 표준 정규 분포에 분포 수렴한다는 결론을 내립니다. 먼저 표준화한 표본 평균의 적률 생성 함수를 구해보겠습니다.</ul><h3 id="증명-과정">증명 과정</h3>\[\begin{align} M_{\tfrac{\sqrt{n}(\bar{X}-\mu)}{\sigma}}(t) &amp;= M_{\tfrac{\sqrt{n}(\tfrac{1}{n}(X_1+\cdots+X_n)-\mu)}{\sigma}}(t) \\[1em] &amp;= M_{\tfrac{(X_1 + \cdots + X_n)-n\mu }{\sigma \sqrt{n}}}(t) \\[1em] &amp;= M_{\tfrac{X_1-\mu}{\sigma} + \cdots + \tfrac{X_n-\mu}{\sigma}}(t) \\[1em] &amp;= M_{\tfrac{X_1-\mu}{\sigma}}(t) M_{\tfrac{X_2-\mu}{\sigma}}(t) \cdots M_{\tfrac{X_n-\mu}{\sigma}}(t) \\[1em] &amp;= E\Big(\text{exp}\Big(\tfrac{(X_1-\mu)t}{\sigma\sqrt{n}}\Big)\Big) E\Big(\text{exp}\Big(\tfrac{(X_2-\mu)t}{\sigma\sqrt{n}}\Big)\Big) \cdots E\Big(\text{exp}\Big(\tfrac{(X_n-\mu)t}{\sigma\sqrt{n}}\Big)\Big) \\[1em] &amp;= \Big\{ E\Big(\text{exp}\Big(\tfrac{(X-\mu)t}{\sigma\sqrt{n}}\Big)\Big) \Big\}^n \\[1em] &amp;= \Big\{ M_{\tfrac{X-\mu}{\sigma}} \Big( \tfrac{t}{\sqrt{n}} \Big) \Big\}^n \\[1em] \end{align}\]<p>여기까지 표준화한 표본 평균의 적률 생성 함수를 유도했습니다. 이제 해당 함수를 \(n \rightarrow \infty\)으로 보내려고 하는데요. 약간의 문제가 있습니다. 위에서 유도한 식에 극한을 취해서 \(n \rightarrow \infty\)로 보내면 \(1^{\infty}\)라는 값이 등장하게 됩니다. 그래서 자연로그를 취한 후 극한을 취하는 테크닉을 적용하게 됩니다.</p>\[\begin{align} \lim_{n \rightarrow \infty} \text{ln} \Big\{ M_{\tfrac{X-\mu}{\sigma}} \Big( \tfrac{t}{\sqrt{n}} \Big) \Big\}^n &amp;= \lim_{n \rightarrow \infty} n \text{ln} M_{\tfrac{X-\mu}{\sigma}} \Big( \tfrac{t}{\sqrt{n}} \Big) \\[1em] &amp;= \lim_{y \rightarrow 0} \frac{\text{ln} M_{\tfrac{X-\mu}{\sigma}}(yt)}{y^2} \space\space\space\space\space\space\space\space\space\space\space\space\space \text{where } y=\frac{1}{\sqrt{n}} \\[1em] &amp;= \lim_{y \rightarrow 0} \frac{\cfrac{tM'(yt)}{M_{\tfrac{X-\mu}{\sigma}}(yt)}}{2y} \space\space\space\space\space\space\space\space\space\space\space\space\space\space \text{by L’Hˆopital’s rule} \\[1em] &amp;= \lim_{y \rightarrow 0} \frac{tM'_{\tfrac{X-\mu}{\sigma}}(yt)}{2y} \\[1em] &amp;= \cfrac{t}{2} \lim_{y \rightarrow 0} \frac{M'_{\tfrac{X-\mu}{\sigma}}(yt)}{y} \\[1em] &amp;= \cfrac{t}{2} \lim_{y \rightarrow 0} \cfrac{tM''_{\tfrac{X-\mu}{\sigma}}(yt)}{1} \\[1em] &amp;= \cfrac{t^2}{2} \lim_{y \rightarrow 0} M''_{\tfrac{X-\mu}{\sigma}}(yt) \space\space\space\space\space\space\space\space\space\space\space\space\space\space \text{by L’Hˆopital’s rule} \\[1em] &amp;= \cfrac{t^2}{2} M''(0) \\[1em] &amp;= \cfrac{t^2}{2} \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space \text{by MGF of standard normal dist.} \end{align}\]<p>위 식이 말하고자 하는 것은 \(n \rightarrow \infty\) 일 때,</p>\[\text{ln} \bigg\{ M_{\tfrac{X-\mu}{\sigma}}\bigg(\frac{t}{\sqrt{n}}\bigg) \bigg\}^n \rightarrow \frac{t^2}{2}\]<p>화살표 왼쪽은 증명의 첫 출발점이었던 표준화한 표본 평균의 MGF에 자연로그를 취한 것과 동일합니다. 따라서</p>\[\text{ln }M_{\tfrac{\sqrt{n}(\bar{X}-\mu)}{\sigma}}(t) \rightarrow \frac{t^2}{2}\]<p>최종적으로 \(n \rightarrow \infty\) 일 때 표준화된 표본 평균의 MGF는 표준 정규 분포의 MGF \(\big(=e^{t^2/2}\big)\)와 같으므로 표준화된 표본 평균은 표준 정규 분포에 분포 수렴한다는 사실을 증명할 수 있습니다.</p>\[M_{\tfrac{\sqrt{n}(\bar{X}-\mu)}{\sigma}}(t) \rightarrow e^{t^2/2}\]<h2 id="참고자료">참고자료</h2><ul><li><a href="https://ko.wikipedia.org/wiki/%EC%A4%91%EC%8B%AC_%EA%B7%B9%ED%95%9C_%EC%A0%95%EB%A6%AC">중심극한정리 - 위키피디아</a><li><a href="https://drhongdatanote.tistory.com/57">중심극한 정리는 무엇이고 왜 중요한가?</a><li><a href="https://stats.stackexchange.com/questions/366888/can-any-data-be-transformed-into-a-standard-normal-distribution">Can any data be transformed into a standard normal distribution?</a><li>“Introduction to Probability”, Joseph K. Blitzstein, Jessica Hwang</ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/math/'>Math</a>, <a href='/categories/statistics/'>Statistics</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/statistics/" class="post-tag no-text-decoration" >statistics</a> <a href="/tags/clt/" class="post-tag no-text-decoration" >clt</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=중심 극한 정리(CLT, Central Limit Theorem) - 생각과 고민.&url=https://gguguk.github.io/posts/CLT/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=중심 극한 정리(CLT, Central Limit Theorem) - 생각과 고민.&u=https://gguguk.github.io/posts/CLT/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=중심 극한 정리(CLT, Central Limit Theorem) - 생각과 고민.&url=https://gguguk.github.io/posts/CLT/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/tsne/">T-SNE 이해하기</a><li><a href="/posts/how_to_work_python/">CS50 - 파이썬이 소스 코드를 실행하는 과정과 원리</a><li><a href="/posts/OIDC/">IRSA의 원리를 파헤쳐보자 4 - OIDC</a><li><a href="/posts/OAuth/">IRSA의 원리를 파헤쳐보자 3 - OAuth2.0</a><li><a href="/posts/admission_webhook/">IRSA의 원리를 파헤쳐보자 1 - K8S Admission Webhook</a></ul></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/discrete_distributions/"><div class="card-body"> <span class="timeago small" >Nov 5, 2020<i class="unloaded">2020-11-05T20:53:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>이산형 확률 분포 정리</h3><div class="text-muted small"><p> 이산형 확률 분포에 대해서 정리해 보았습니다. 본 내용은 하버드 확률론 기초 강의(Statistics 110)를 참고하여 정리했음을 밝힙니다. 연속형 확률 분포에 대한 글은 이곳을 참고해주세요. 0   확률 변수(Random Variable)와 확률 분포(Distribution) 확률 변수란 표본 공간(\(S\))에서 발생 가능한 outc...</p></div></div></a></div><div class="card"> <a href="/posts/continuous_distributions/"><div class="card-body"> <span class="timeago small" >Nov 28, 2020<i class="unloaded">2020-11-28T16:26:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>연속형 확률 분포 정리</h3><div class="text-muted small"><p> 하버드 확률론 기초 강의(Statistics 110)을 수강 후, 교수님께서 강조하신 여러가지 분포에 대해 개념정리 할 필요성을 느꼈습니다. 특히 이커머스 도메인에서는 통계에 기반한 분석 기법들이 많이 활용되는데(LTV, MAB 등), 실무에서 주어진 태스크를 빠르고 정확히 수행하기 위해 미리 관련 개념 정리를 해두려고 합니다. 이번 포스트는 대표적인...</p></div></div></a></div><div class="card"> <a href="/posts/LLN/"><div class="card-body"> <span class="timeago small" >Dec 15, 2020<i class="unloaded">2020-12-15T22:03:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>큰수의 법칙(LLN, Law of Large Numbers)</h3><div class="text-muted small"><p> 표본의 크기가 커질수록 표본평균은 모평균에 근접해 갑니다. 우리는 공정한 동전을 던졌을 때 앞면이 나타날 확률이 \(\cfrac{1}{2}\)이라는 것을 특별히 증명하지 않아도 알 수 있습니다. 우리가 지금까지 살아오면서 겪은 수많은 경험들에 의하면 동전의 앞면이 나타날 확률이 \(\cfrac{1}{2}\)이기 때문이죠. 이처럼 수많은 경험의 경...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/continuous_distributions/" class="btn btn-outline-primary" prompt="Older"><p>연속형 확률 분포 정리</p></a> <a href="/posts/LLN/" class="btn btn-outline-primary" prompt="Newer"><p>큰수의 법칙(LLN, Law of Large Numbers)</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://github.com/gguguk">Gukwon Koo</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/retrospective/">retrospective</a> <a class="post-tag" href="/tags/k8s/">k8s</a> <a class="post-tag" href="/tags/kubernetes/">kubernetes</a> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/statistics/">statistics</a> <a class="post-tag" href="/tags/irsa/">irsa</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/mlops/">mlops</a> <a class="post-tag" href="/tags/paper/">paper</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://gguguk.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-8EWVG7CHCY"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-8EWVG7CHCY'); }); </script>
