[ { "title": "T-SNE 이해하기", "url": "/posts/tsne/", "categories": "ML, Basic", "tags": "tsne", "date": "2025-08-30 14:52:00 +0900", "snippet": "T-SNE는 고차원의 임베딩을 저차원으로 변환하고 시각화화여 임베딩을 품질들 대략적으로 파악하는 것을 돕는 대표적인 차원 축소 알고리즘입니다. 실제로 아직도 현업에서도 많이 사용되는 알고리즘이고, 여러 논문에서도 임베딩의 질을 시각적으로 보여주기 위한 방법으로 많이 활용되고 있습니다.그러나 어느 순간 T-SNE의 원리를 완벽하게 이해하지 못하고 사용하고 있다는 생각이 들었습니다. 🫠 앞으로 현업에서 임베딩을 다룰 일이 많아질 것 같은 느낌이 들어서 이번 기회에 정확한 동작 원리를 공부해보았습니다. 공부해보니 ML 기초 이론을 복습하기에도 좋은 알고리즘이라는 생각이 들더라구요. 앞으로 설명 드릴 내용은 다음의 배경 지식을 요구합니다. Gaussian distribution Student-T distribution KL-Divergence Gradient decentSummary T-SNE는 고차원 데이터를 저차원으로 내릴 때, 주변 이웃 정보를 최대한 보존하는 알고리즘입니다. 고차원에서 가까운 데이터는 저차원에서도 가깝게 만드는 것이 목표입니다. 이를 위해 기초 통계, 최적화 이론을 활용합니다.T-SNE = Gaussian + Student T + KL-Divergence + Gradient DecentT-SNE의 핵심 작동 원리는 4개의 키워드로 표현할 수 있습니다. Gaussian distribution: 고차원 공간(원래 벡터들이 존재하는 공간)을 가우시안 분포로 표현합니다. 이때 원래 가까운 벡터들은 높은 확률값을 갖도록, 그 반대는 반대가 되도록 합니다. Student T-distribution: 저차원 공간(시각화를 위한 공간, 일반적을 2~3차원)을 T 분포로 표현합니다. 이때 고차원에서 원래 가까운 벡터들은 높은 확률을 가지도록, 그 반대는 반대가 되도록 표현하는 T 분포를 찾는 것이 목표입니다. KL-Divergence: 가우시안 분포와 T 분포가 차이가 나는 정도를 계산합니다. Gradient Decent: KL-Divergence의 값에 대한 저차원 벡터의 gradient를 계산하고, KL-Divergence가 작아지는 방향으로 저차원 벡터를 점진적으로 이동시킵니다.예시로 학습 방식 직관적으로 이해해 보기T-SNE의 학습 방식을 예시를 들어봅시다. 직관적으로 이해하기 쉬울 거예요. T-SNE는 먼저 고차원에서 각 데이터 포인트(예: 학생 A, B)가 서로 얼마나 가까운지를 계산합니다. 가까우면: 이 둘은 서로 비슷하네 멀면: 이 둘은 서로 다르네같은 말을 확률로 표현하면 이렇게도 표현할 수 있습니다. 가까우면: 이 둘이 서로 친구일 확률은 0.8 멀면: 이 둘이 서로 친구일 확률은 0.1이제 데이터 포인트를 저차원 공간(예: 2차원)에 배치하는데, 이 때 위에서 계산한 친구일 확률을 최대한 유지하는 것이 중요합니다. 고차원에서 가까웠다면: 저차원 공간에서도 서로 친구일 확률을 크게 고차원에서 멀었다면: 저차원 공간에서도 서로 친구일 확률을 작게고차원 공간의 확률과 저차원 공간의 확률 구조를 비슷하게 유지하기 위해서 벌점을 부과합니다. 고차원에서 가까웠지만(확률 큼) 저차원에서 멀면(확률 작음): 벌점이 커짐 고차원에서 가까웠고(확률 큼) 저차원에서도 가까우면(확률 큼): 벌점이 작아짐마지막으로 이 벌점을 줄이기 위한 방향으로 저차원 공간의 데이터 포인터를 점진적으로 이동시킵니다. 벌점이 큰 벡터: 벌점이 작아지는 방향으로 크게 이동 시킴 벌점이 작은 벡터: 벌점이 작아지는 방향으로 작게 이동 시킴수식과 함께 더 자세히 이해해 보기T-SNE의 학습 방식을 예시를 통해 직관적으로 이해해 보았습니다. 이제 수식을 곁들여서 좀 더 자세히 이해해 보죠!고차원 확률 분포 정의 - 가우시안 분포가우시안 분포T-SNE는 고차원 공간에 데이터 포인트 \\(x_i, \\cdots, x_N\\)가 있을 때(\\(i \\neq j\\)) \\(x_i\\)와 \\(x_j\\)의 유사도(거리)에 비례하는 확률 분포 \\(p_{ij}\\)를 계산하는 것이 첫번째 목표입니다. 이를 위해 \\(x_i\\)가 \\(x_j\\)를 이웃으로 선택할 확률 \\(p_{j \\mid i}\\)를 조건부 확률로 나타냅니다. 이 때, \\(p_{i \\mid i} = 0\\)이고 \\(\\sum_{j}P_{j \\mid i}=1, \\forall i\\)입니다.\\[p_{j \\mid i} = \\frac{\\exp\\!\\left(-\\| \\mathbf{x}_i - \\mathbf{x}_j \\|^2 / 2\\sigma_i^2 \\right)}{\\sum_{k \\neq i} \\exp\\!\\left(-\\| \\mathbf{x}_i - \\mathbf{x}_k \\|^2 / 2\\sigma_i^2 \\right)}\\]이 수식은 \\(\\mathbf{x}_i\\)를 평균으로 하는 가우시안 분포의 수식과 사실상 같다는 것을 알 수 있습니다.\\[N(x; \\mu, \\sigma^2) = \\cfrac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(- (x-\\mu)^2/2\\sigma^2)\\]즉, 고차원 공간에서의 벡터의 거리를 확률로 변환하는데 이때 가우시안 분포를 활용한다는 것을 알 수 있습니다. 또한 \\(p_{j \\mid i}\\)의 분모의 수식에 의해 식이 노말라이즈 되면서 \\(\\sum_{j}P_{j \\mid i}=1, \\forall i\\)가 만족될 수 있음을 알 수 있습니다.마지막으로 조건부 확률을 대칭 확률로 변환하여 이는 \\(x_i\\)와 \\(x_j\\)가 이웃일 최종 확률을 구합니다. 이렇게 하는 이유는 \\(p_{j \\mid i}\\)와 \\(p_{i \\mid j}\\)의 분포가 다르기 때문입니다(분모가 다릅니다).\\[p_{ij} = \\cfrac{p_{j \\mid i} + p_{i \\mid j}}{2N} \\text{, where N=number of dimension}\\]아직 \\(p_{j \\mid i}\\)을 계산하기 위해 필요한 \\(\\sigma_i^2\\)를 설명하지 않았습니다. 이 값은 \\(x_i\\)를 중심으로 한 가우시안 분포의 분산입니다. 하지만 이 값은 아직 정확히 계산할 수는 없습니다. 이렇게 생각할 수도 있습니다. “그냥 기초적인 분산 공식에 따라 계산할 수 있는 거 아니야?”사실은 맞는 말입니다. 그러나 T-SNE 알고리즘은 이렇게 하진 않고, 실질적으로 몇 개의 이웃 데이터 포인트만 중요하게 생각할지에 따라서 분산을 결정하는 전략을 취하고 있습니다. 그리고 이 분산을 정하기 위해서 perplexity라는 하이퍼파라미터를 도입합니다. 직관적으로 생각 해보면, 더 많은 데이터 포인트를 실질적인 이웃이라고 고려할수록 분산은 커지고, 그 반대는 반대가 될 겁니다. 여기서는 이 하이퍼파라미터가 왜 필요한지만 직관적으로 이해하고 넘어가고, perplexity는 아래에서 더 자세히 설명하겠습니다.저차원 확률 분포 정의 - T 분포자유도에 따른 Student-t 분포저차원에서는 T 분포에 기반하여 두 벡터간의 거리를 확률의 개념으로 표현하는 것만 제외하면 위 접근법과 거의 유사합니다. 저차원 공간에 \\(y_1, \\cdots, y_N (y_i \\in \\mathbb{R}^d)\\) 데이터 포인트가 존재할 때, 아래 수식으로 두 데이터 포인트 \\(y_i\\)와 \\(y_j\\) 사이의 거리(유사도)를 확률 \\(q_{ij}\\)로 변환합니다.\\[q_{ij} = \\frac{(1 + \\| \\mathbf{y}_i - \\mathbf{y}_j \\|^2)^{-1}}{\\sum_k \\sum_{l \\neq k} (1 + \\| \\mathbf{y}_k - \\mathbf{y}_l \\|^2)^{-1}}\\]이 수식은 자유도가 1인 student t-분포와 사실상 같다는 것을 알 수 있습니다. 먼저 student t-분포의 PDF는 다음과 같습니다.\\[f(t; \\nu) = \\frac{\\Gamma\\!\\left(\\tfrac{\\nu+1}{2}\\right)}{\\sqrt{\\pi \\nu}\\,\\Gamma\\!\\left(\\tfrac{\\nu}{2}\\right)}\\left(1 + \\frac{t^2}{\\nu}\\right)^{-\\tfrac{\\nu+1}{2}}\\]이때 \\(\\nu = 1\\)이라고 한다면, 다음과 같이 표현할 수 있습니다.\\[f(t) = c\\left(1 + t^2\\right)^{-1}\\]저차원 데이터 포인트 업데이트 - KL-Divergence &amp;amp; gradient descent지금까지 논의를 통해서 원래 고차원 공간에서의 데이터 포인트 간의 거리를 확률로 표현하고, 비슷한 방법으로 저차원 공간에서의 데이터 포인트 간의 거리를 확률로 표현하는 방법을 살펴 보았습니다. 그렇다면, 저차원 공간에서 결정된 데이터 포인트가 잘 사상된 것인지 어떻게 검증할 수 있을까요? 그리고 데이터 포인트를 더 적절한 위치로 옮기려면 어떻게 해야할까요? 이때 딥러닝의 학습의 기반이 되는 유명한 KL-Divergence와 gradient descent가 활용됩니다.먼저, KL-Divergence는 아래의 수식이고, 이 수식은 확률 분포 \\(p_{ij}\\)와 \\(q_{ij}\\)의 차이를 측정하게 됩니다.\\[KL(P \\parallel Q) = \\sum_{i \\neq j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}}\\]마지막으로 계산된 KL-Divergence를 \\(y_{i}\\)에 대해 미분하여 gradient를 얻고, 이를 활용하여 \\(y_i\\)의 값을 변경하는 gradienct descent를 적용하게 됩니다. 결과적으로 따라서 T-SNE는 고차원 공간에서의 분포를 잘 반영할 수 있는 저차원 공간을 찾는 차원 축소 알고리즘이라고 볼 수 있습니다.\\[y_i \\leftarrow y_i - \\eta \\cfrac{\\partial KL(P \\parallel Q)}{\\partial y_i}{}\\]Perplexityperplexity란 \\(x_i\\)가 실질적으로 혹은 중요하게 고려하는 이웃 데이터 포인트, 즉 유효 이웃 수를 의미합니다. 이 값이 중요한 이유는 이에 따라 \\(\\sigma_i^2\\)가 결정되기 때문입니다. perplexity가 클수록 분산 \\(\\sigma_i^2\\)도 커집니다. perplexity가 작을수록 분산 \\(\\sigma_i^2\\)도 작아집니다.위에서 이론적으로는 분산 공식에 따라 \\(\\sigma_i^2\\)를 구할 수는 있지만, T-SNE는 그렇게 하지 않는다고 언급 했습니다. T-SNE는 굳이 perplexity라는 하이퍼파라미터를 통해 적절한 분산 \\(\\sigma_i^2\\)을 구합니다. 도대체 이유가 뭘까요? 그 이유는 데이터의 지역 밀도(local density)를 고려해서, 모든 데이터 포인트가 유사한 유효 이웃 수를 갖도록 균형을 맞추기 위함입니다.아래 그래프는 perplexity=5일 때, 밀집 영역에 있는 빨강 데이터 포인트와 희소 영역에 있는 파랑 데이터 포인트에 대해서 분산 공식에 따라 전역 분산을 구했을 때의 가우시안 분포(점선)와 perplexity에 따라 국소 분산을 구했을 때의 가우시안 분포(실선)을 시각화 했습니다.perplexity=5일 때, 지역 밀집도에 따른 가우시안 분포 국소 분산(실선): 데이터의 밀집도를 반영하여 본인 주위의 일부만을 유효 이웃으로 고려하고 있습니다. 전역 분산(점선):데이터의 밀집도를 반영하지 못하고, 클러스터 내의 모든 데이터 포인트를 유효 이웃으로 고려하고 있습니다.정리하면, T-SNE는 데이터의 지역 구조를 보존하기 위해 일반적인 분산 공식에 의한 전역 분산을 사용하지 않고, perplexity라는 값에 기반한 국소 분산을 활용한다고 할 수 있습니다. 일반적으로 perplexity는 5~50 사이의 값으로 설정한다고 합니다.perplexity는 shannon entropy에 기반한 다음의 공식을 따릅니다.\\[\\text{Perplexity}(P_i) = 2^{-\\sum p_{j \\mid i} \\log_2{p_{j \\mid i}}}\\]\\[\\text{where} -\\sum p_{j \\mid i} \\log_2{p_{j \\mid i}} \\text{ is Shannon entropy}\\]만약 \\(\\text{Perplexity}(P_i)=5\\)라고 설정 했으면, \\(2^{-\\sum p_{j \\mid i} \\log_2{p_{j \\mid i}}}=5\\)를 만족하는 분산 \\(\\sigma_i^2\\)을 찾으면 됩니다.T-SNE의 단점과 변형 알고리즘들T-SNE의 최대 단점은 데이터 포인트가 \\(N\\)개 일때, 한 이터레이션에서 \\(N^2\\)개의 쌍을 비교하는 연산이 필요하다는 것입니다. 즉, 시간 복잡도가 \\(O(N^2)\\)입니다. 이를 극복하기 위해 다양한 변형 알고리즘들이 있으니 참고해보세요. Barnes-Hut t-SNE: \\(O(N \\log N)\\) Flt-SNE: \\(O(N)\\)Laurens van der Maaten(T-SNE 저자)의 FAQHow should I set the perplexity in t-SNE? The performance of t-SNE is fairly robust under different settings of the perplexity. The most appropriate value depends on the density of your data. Loosely speaking, one could say that a larger / denser dataset requires a larger perplexity. Typical values for the perplexity range between 5 and 50.What is perplexity anyway? In t-SNE, the perplexity may be viewed as a knob that sets the number of effective nearest neighbors. It is comparable with the number of nearest neighbors k that is employed in many manifold learners.Every time I run t-SNE, I get a (slightly) different result? In contrast to, e.g., PCA, t-SNE has a non-convex objective function. The objective function is minimized using a gradient descent optimization that is initiated randomly. As a result, it is possible that different runs give you different solutions. Notice that it is perfectly fine to run t-SNE a number of times (with the same data and parameters), and to select the visualization with the lowest value of the objective function as your final visualization.참고자료 t-distributed stochastic neighbor embedding Student’s t-distribution https://lvdmaaten.github.io/tsne/" }, { "title": "IRSA의 원리를 파헤쳐보자 4 - OIDC", "url": "/posts/OIDC/", "categories": "MLOps, Kubernetes", "tags": "kubernetes, k8s, oauth2.0, oidc, irsa", "date": "2022-12-20 21:00:00 +0900", "snippet": "지난 글에서는 OAuth2.0를 살펴보았습니다. OAuth2.0을 이해해야 본 글에서 설명할 OIDC를 이해할 수 있습니다. OIDC는 인증(authentication)을 위한 프로토콜입니다.IRSA의 원리를 파헤쳐보자 시리즈 IRSA의 원리를 파헤쳐보자 1 - K8S Admission Webhook IRSA의 원리를 파헤쳐보자 2 - K8S Sevice Account와 Service Account Token Volume Projection IRSA의 원리를 파헤쳐보자 3 - OAuth2.0 IRSA의 원리를 파헤쳐보자 4 - OIDC IRSA의 원리를 파헤쳐보자 5 - IRSA ProcessOIDC(OpenID Connect)OIDC란?OIDC(OpenID Connect)란 OAuth 위에서 동작하는 사용하는 인증(authentication)을 위한 프로토콜입니다. 앞서 우리는 위에서 OAuth2.0에 대해서 배웠습니다. 인가를 담당하는 표준화된 프로토콜이라고 했죠. 그리고 인가를 하기 위해서 필연적으로 인증 과정이 수반되었습니다(구글 로그인, 페이스북 로그인 등) 이러한 사실 때문에 많은 사람들이 OAuth를 인가와 인증 두 가지 목적을 모두 담당하는 프로토콜이라고 오해하고 있습니다.(저도 포함입니다… 🙋‍♀️)OIDC와 OAuth를 구분하자사탕의 맛을 내기 위한 재료들과 사탕이 있습니다. 각각 인가와 인증으로 비유할 수 있습니다.그러나 이는 엄청난 오해입니다. 비유를 들어서 쉽게 설명해보겠습니다(이해를 돕기 위한 비약이 있을 수 있습니다). 사탕의 맛을 내기 위한 재료들이 있습니다. 오렌지, 딸기, 초콜릿 등이 있습니다. 이런 재료들은 그 자체로도 충분히 우리의 먹거리가 되어줍니다. 그리고 사탕도 많은 종류가 있습니다. 오렌지 맛 사탕, 딸기 맛 사탕, 초콜릿 맛 사탕을 예시로 들 수 있습니다. 여기서 중요한 점은 초콜릿과 초콜릿 맛 사탕은 서로 깊은 연관이 있지만, 결국엔 서로 다르다는 것입니다.이 비유에서 사탕의 맛을 내기 위한 재료들은 인가(authorization)를 구현하기 위한 여러가지 기술 또는 프로토콜이라고 할 수 있습니다. 그 중 가장 대중적으로 쓰이는 프로토콜이 바로 초콜릿, OAuth 2.0입니다. 그리고 초콜릿은 그 자체로 간식으로 먹는 것처럼 OAuth 2.0도 인가의 기능을 그 자체로 담당할 수 있습니다. 한편 사탕은 인증(authentication)을 구현하기 위한 기술 또는 프로토콜입니다. 특히 OIDC는 OAuth2.0에 기반을 둔 대표적인 프로토콜인데요, 일명 초콜릿 맛 사탕이라고 할 수 있겠습니다.이처럼 OAuth(초콜릿)와 OIDC(초콜릿 맛 사탕)는 뗄려야 뗄 수 없는 관계입니다. 그러나 이 둘은 서로 엄연히 다른 목적을 가지고 있으며, OAuth와 OIDC를 혼동하는 것은 OAuth 공식 문서에서도 지적하고 있는 매우 중대한 오류입니다(그 이유에 대해서는 부록에 번역 및 작성해 두었습니다). OAuth는 인가를 위한 프로토콜인데, 특정 범위(scope)의 권한을 인가하기 위해서는 어쩔 수 없이 인증의 과정을 거치기는 합니다. 그러나 OAuth 흐름에서 발생하는 인증은 OAuth 프로토콜의 본래의 목적이 아니라 하나의 수단에 불과합니다. 한편 OIDC는 OAuth 위에서 동작하는 인증 프로토콜입니다. OAuth가 인가를 위해 어쩔 수 없이 인증 과정을 거치는데, 이 과정에서 OIDC는 인증을 위해 사용자의 신원을 식별하는데 활용 되는 id_token을 추가적으로 발급합니다(이때 OAuth는 access_token`을 발급합니다).OIDC 주체OIDC는 OAuth2.0 위에서 동작하는 프로토콜이지만, OIDC에 참여하는 주체들의 명칭은 OAuth2.0과 조금 다릅니다. OpenID provider(IdP): ID token을 발급하는 인가 서버(authorization server)입니다. OAuth2.0에서의 인가 서버에 해당합니다. End user: 인증하는 주체입니다. OAuth2.0에서의 리소스 소유자(Resource owner)에 해당합니다. Relying party: OpenID provider에 id token을 요청하는 주체입니다. OAuth2.0에서의 클라이언트에 해당합니다. OIDC에서 id token을 발급 받는 과정OIDC는 OAuth 위에서 동작하는 프로토콜입니다. 따라서 이전 OAuth2.0 글에서 언급했던 플로우를 거의 그대로 따릅니다. 다만 다음과 같은 부분에서 차이가 있습니다: 로그인 페이지 요청시 scope=openid를 반드시 명시합니다. 이 경우에만 추후 id_token이라는 사용자의 신원을 확인할 수 있는 토큰이 발급됩니다. access_token 교환 요청이 성공적으로 수행되면 기존 OAuth2.0에서 발급되었던 access_token과 refresh_token 이외에 id_token이 추가 발급됩니다.발급된 id_token을 크게 2가지 용도로 사용될 수 있습니다. 클라이언트(relying party, 애플리케이션)가 유저를 자체적으로 인증 용도(e.g., 카카오 아이디로 로그인 등) 클라이언트가 다른 서비스에 인증하는 용도(e.g., k8s의 파드가 id_token을 이용하여 k8s api server에 인증)이 중 클라이언트가 유저를 인증하는 용도로 사용되는 것이 더 일반적인 경우입니다. 그리고 이 과정은 id_token을 검증하고, id_token에 담겨 있는 정보를 조회해서 내부 DB와 교차 검증을 하는 순서로 진행됩니다. 이를 이해하기 위해서 id_token이 실제로 어떻게 생겼는지 살펴봅시다.id_tokenid_token이 access_token과 가장 크게 구별되는 점은 실제로 사용자와 관련된 정보를 담고 있다는 점입니다. id_token은 크게 헤더(Header), 페이로드(Payload), 서명(Signature)라는 총 3개의 파트가 온점(.)으로 구분된 스트링입니다. 원 형태는 JWT(Json Web Token)이지만, 이를 각 파트별로 base64로 인코딩한 후 온점(.)으로 구분합니다. 실제 id_token은 다음과 같은 형태입니다. 디코딩 된 실제 값은 여기를 참조해주세요. eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJodHRwczovL2thdXRoLmtha2FvLmNvbSIsImF1ZCI6Imtvby1hcHAiLCJzdWIiOiJnd2tvbzgyQGdtYWlsLmNvbSIsImV4cCI6MTM1MzYwNDkyNiwiaWF0IjoxMzUzNjAxMDI2fQ.PEST2li71tPylFlh13cZDC_JqyCq13jLxIJt8vyNpLQHeader에는 토큰의 타입과 이 토큰을 서명할 때 어떤 암호화 알고리즘을 사용하였는지, 토큰의 유형은 무엇인지 명시되어 있습니다. 주로 사용되는 암호화 알고리즘은 HS256(HMAC SHA256)1이나 RSA입니다. 참고로 HS256은 대칭키 암호화 방식, RSA는 비대칭키 암호화 방식입니다.{ &quot;alg&quot;: &quot;HS256&quot;, # 해시 알고리즘 (HMAC, SHA256, RSA) &quot;typ&quot;: &quot;JWT&quot; # 토큰 유형}Payload는 JWT의 핵심 내용이 명시 되어 있는 부분으로 여러 종류의 claim2으로 구성되어 있습니다.{ &#39;iss&#39;: &#39;https://kauth.kakao.com&#39;, &#39;aud&#39;: &#39;koo-app&#39;, &#39;sub&#39;: &#39;gwkoo82@gmail.com&#39;, &#39;exp&#39;: 1353604926, &#39;iat&#39;: 1353601026}특히 중요한 claim들은 다음과 같습니다. iss(issuer): id_token을 발급한 주체(e.g., google, facebook, kakao, …) aud(audience): id_token을 활용하는 주체(e.g., 클라이언트, aws.sts) sub(subject): 리소스 오너(resource owner), 엔드 유저(end-user) (e.g., 사용자, 쿠버네티스 pod) exp: id_token 만료 시점 iat: id_token 발급 시점마지막으로 Signature(서명)는 id_token이 중간에 변조되진 않았는지, 유효성을 검사하기 위해 필요한 파트입니다. 대략 아래와 같은 pseudo 코드를 거쳐서 만들어집니다(HS256 알고리즘 기준).HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), SECRET_VALUE)이렇게 해시값으로 암호화된 서명은 값은 (HS256 기준) 암호화에 사용된 SECRET_VALUE가 있다면 복호화가 가능합니다. 따라서 메시지에 실린 JWT의 header나 payload가 변조되었는지 여부를 서명을 복호화 한 다음, 서명시 같이 포함한 header와 payload 값과 비교해보면 곧바로 확인 가능합니다.id_token 검증 과정 온점을 기준으로 id_token의 값을 헤더, 페이로드, 서명 부분으로 분리합니다. 페이로드를 base64 디코딩 합니다. iss가 실제 발급자와 일치하는지 확인합니다. aud가 현재 자기 자신 application의 키와 일치하는지 확인합니다. exp가 현재 유닉스 타임보다 큰 값인지, 즉 만료되었는지 확인합니다. 마지막으로 서명의 변조 여부를 확인합니다.서명을 이해해 보자.SHA-1은 쇄도효과의 좋은 예시입니다. 1비트만 바꿔도 결과 값이 완전히 달라집니다.지금까지 글의 논지를 살펴보면 OIDC flow는 인증 서버에서 id_token이라는 것을 클라이언트(relying party)에게 발급 해주는 과정이라고 할 수 있습니다. 그리고 클라이언트는 이 토큰을 활용해서 다른 서비스에 인증을 하는데 활용할 수 있는데요. 이 과정에서 ‘다른 서비스’는 해당 토큰이 원 형태를 유지한 채 변조 되지 않았다는 사실을 검증해야 합니다. 그리고 토큰의 유효성을 검증 하기 위해서는 서명(signature) 파트의 값을 활용합니다. 그렇다면 도대체 서명은 어떻게 하고, 이에 대한 검증은 어떻게 한다는 걸까요? 이 부분이 궁금해서 조금 더 찾아보게 되었습니다.먼저 서명은 암호화를 하는 것이 아님을 주의해야합니다. 어떤 데이터를 암호화 한다는 것은 그것을 사람이 쉽게 읽지 못하게 만든다는 것인데, 서명은 데이터를 읽지 못하게 하는 것이 아니라, 데이터가 ‘변조’ 되었는지 아닌지 여부만 체크하는데 활용됩니다. 변조 여부를 체크할 수 있는 것은 해시 함수의 쇄도 효과(산사태 효과, avalanche effect)의 원리에 기반합니다. 어떤 메시지가 아주 조금만 달라져도, 즉 변조가 아주 미세하게만 일어나도 해시값은 크게 바뀐다는 것입니다.이와 같은 사실을 숙지하고, HS256 알고리즘을 서명 및 검증이 어떻게 이루어지는지 살펴봅시다. 생각보다 매우 간단합니다. 먼저 서명하는 쪽과 검증을 하는 쪽은 ‘대칭키’를 공유하고 있어야 합니다. 키라는 것은 일종의 문자열인데, 해시 함수는 결국 문자열을 비트로 변환한 후 특정 로직을 수행하므로 문자열을 그대로 사용하진 않습니다. 그리고 다음과 같이 헤더와 페이로드를 각각 base64로 인코딩 한뒤, 서로 공유 했던 대칭키와 함께 HS256을 이용해 메시지를 해시값으로 변환 합니다. 최종적으로 JWT의 ‘서명’ 부분에 이 해시값이 들어가서 전송됩니다.HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), SECRET_VALUE)이 메시지를 받는 쪽에서 해당 메시지가 변조 되었는지 어떻게 확인할 수 있을까요? 메시지를 받는 쪽은 기본적으로 JWT를 받았기 때문에 헤더와 페이로드 정보를 알 수 있습니다. 그리고 대칭키도 역시 사전에 공유되었으므로 알고 있는 정보입니다. 그럼 다시 위에 수도 코드를 실행할 수 있고, 해시값을 얻을 수 있을텐데요. 이를 전송 받았던 JWT의 서명 파트에 있는 해시와 비교 해보면 됩니다. 만일 내가 전달 받은 헤더나 페이로드가 원래 메시지와 달라졌다면 HS256의 결과인 해시값은 JWT의 서명 파트에 있는 값과 크게 차이가 날 것입니다.Access token vs id token   access token id token audience Access tokens are meant to be read by the resource server(Access tokens must not be read or interpreted by the OAuth client. The OAuth client is not the intended audience of the token). ID tokens are meant to be read by the OAuth client information Access tokens do not convey user identity or any other information about the user to the OAuth client. An ID token contains information about what happened when a user authenticated. The ID token may also contain information about the user such as their name or email address, although that is not a requirement of an ID token. usage Access tokens should only be used to make requests to the resource server. ID tokens must not be used to make requests to the resource server. form can be JWTs but may also be a random string JWTs 부록access_token을 유저 인증에 사용하면 안될까?여기까지 오셨으면 OIDC와 OAuth와의 미묘한 차이를 이해하셨 것이라 생각합니다. 그런데 이렇게 생각해볼 수 있지 않을까요? OAuth는 어쨌든 인증 과정을 거쳐서 access_token을 발급해주었으니까 access_token을 인증 과정에 사용해도 되지 않을까요? 결론부터 말하면 이는 틀린 생각입니다. oauth.net에서는 OAuth로 인증을 하는 것의 위험성(Common pitfalls for authentication using OAuth)에 대해서 언급합니다.access token에는 유저를 식별할 수 있는 정보가 없습니다access token을 발급 받는 과정에 사용자 인증이 선행되기 때문에 OAuth 자체가 인증도 담당하고 있다고 생각할 수 있습니다. 그러나 access token은 근본적으로 client를 위한 개념이 아닙니다. 다시말해, access token의 audience(토근 발급 대상, 토근의 최종 사용 주체)는 client가 아니라 resource server(protected resource)입니다. client 입장에서 access token은 아무런 의미 없는 string에 불과합니다(the token is designed to be opaque to the client). 극단적으로 말하면, access token의 포맷이 바뀌었어도 authorization server와 resource server간의 로직만 이상없다면 client 입장에서는 신경 쓸 일이 전혀 없습니다. 그저 resource server로 access token을 전달하기만 하면 되니까요. 또한 access token에는 사용자와 관련된 데이터(user_id나 email 등)는 전혀 없으므로 클라이언트가 사용자를 식별할 수 있는 방법은 없습니다. client가 access token으로 사용자를 식별한다는 행위는 애초에 불가능한 행위라는 것입니다.유저의 인증 없이도 access token이 발급될 수 있습니다.OAuth 과정에서 유저의 로그인을 통해 인증을 수행하고 최종적으로 access token을 발급 받을 수 있습니다. 그러나 이것이 access token을 발급 받을 수 있는 유일한 방법은 아닙니다. refresh token을 활용하여 유저의 인증 없이도 access token을 새로 발급 받을 수도 있습니다. 즉 access token을 발급 받았다는 사실 자체가 유저가 인증되었음을 완벽하게 보장할 수 없다는 뜻입니다.인증 서버가 아닌 제 3자가 access token을 주입할 수도 있습니다.만일 acces token이 URL 파라미터로 전달되는 implicit flow를 따르고, client가 access token의 유효성을 점검할 수 있는 메커니즘이 없다면 access token의 진위 여부를 판별하기 어렵습니다. 따라서 access token만으로 유저가 진짜로 인증했는지 여부를 판별하기 어렵습니다.access token을 발급 해준 client인지 여부를 검증하는 메커니즘이 없습니다.예를 들어, A라는 client가 정상적인 방법을 통해 access token을 발급 받은 후에 B라는 client가 해당 access token을 그대로 사용한다면, 일반적인 OAuth API들은 client를 검증하는 메커니즘이 없으므로 정상적으로 resource server와 통신이 일어날 것입니다. B라는 client가 A라는 client가 발급 받은 access token을 사용함에 있어서 유저의 인증은 개입되지 않았다는 점에서 access token으로 유저 인증을 하기에는 부족한 면이 있습니다.access token에 대한 표준 형식이 없습니다.OAuth 상에서 유저 인증 과정을 처리하려는 시도에 있어서 가장 큰 문제점은 access token의 표준 형식이 정해져있지 않다는 것입니다(access tokens can have different formats, structures, and methods of utilization) 예를 들어서 google에서는 유저의 아이디를 user_id 필드에 넘겨주는데, 페이스북에서는 subject 필드에 넘겨줄 수도 있습니다. 두 필드는 의미상으로는 동일하지만, 이를 처리하기 위해서는 서로 다른 방식으로 처리하는 코드를 짜야하기 때문에 번거롭습니다.참고자료 JWT (Json Web Token) Audience “aud” versus Client_Id - What’s the difference? OAuth 그리고 OpenID Connect ID Tokens vs Access Tokens ID Token and Access Token: What’s the Difference? JWT(JSON Web Token)을 이용한 API 인증 - #1 개념 소개 OIDC (OpenID Connect) 인증과 인가 (권한 부여) 비교 – 특징 및 차이점 OpenID(OIDC) 개념과 동작원리 호다닥 공부해보는 SSO와 친구들 (SAML, OAuth, OIDC) OAuth 2.0 and OpenID Connect Overview 카카오 로그인 - OpenID Connect 쿠버네티스 인증 3편: Dex와 Github OAuth (OIDC) 를 이용한 사용자 인증하기 JWT algorithm: HS256, RS256 RS256 vs HS256: What’s The Difference? 해시 함수 - 쇄도 효과 HMAC(Hash-based Message Authentication Code) + SHA(Secure Hash Algorithm)-256)를 뜻합니다. &amp;#8617; JWT에서 claim이란 프로퍼티나 속성을 말합니다. &quot;iss&quot;: &quot;https://abc.com&quot; 를 하나의 claim이라고 할 수 있으며, iss를 claim 이름, https://abc.com을 claim 값이라고 합니다. &amp;#8617; " }, { "title": "IRSA의 원리를 파헤쳐보자 3 - OAuth2.0", "url": "/posts/OAuth/", "categories": "MLOps, Kubernetes", "tags": "kubernetes, k8s, oauth, irsa", "date": "2022-11-26 20:04:00 +0900", "snippet": "IRSA의 원리를 파헤쳐보자 시리즈의 세번째 글입니다. 지난 시간에는 service account token volume projection에 대해서 살펴보았습니다. 핵심은 projected service account token은 기본 service account token과 다르게 audience나 만료기간 등의 추가적인 정보를 삽입할 수 있으며 OIDC token의 표준적인 형식을 따르게 된다는 점이었습니다. IRSA를 위해서는 sub, aud 등의 정보, 즉 신뢰할만한 개체에 대한 정보를 미리 작성해 두는데 AWS 측에서 토큰의 유효성을 검증하기 위해 필요한 정보를 주입시킨다는 점에서 중요합니다.한편 IRSA를 공부하다 보면 id token, JWT에서 사용되는 단어들이 매우 많이 등장함을 알 수 있습니다. 이는 OIDC(OpenID Connect)라는 프로토콜과 깊은 관련이 있는데요. 애석하게도 OIDC를 이해하기 위해서는 먼저 OAuth2.0를 이해해야 합니다… OIDC는 OAuth2.0 위에서 동작하는 프로토콜이기 때문입니다. 따라서 이번 글에서는 IRSA를 이해하기 위한 배경지식으로서 OAuth2.0을 (수박 겉핥기 식으로 🍉) 살펴보겠습니다사실 공부하면서, IRSA가 완벽하게 OAuth2.0이나 OIDC를 따르는 것은 아니라는 생각이 들었습니다. 그래서 본 글을 정리할지 말지 고민을 많이 했는데, OAuth2.0과 OIDC에서 나오는 개념들을 계속 현업에서 부딪히다 보니 본 주제를 정리하기로 하였습니다. 머신러닝 엔지니어로서 언젠간 반드시 도움이 될 것이라고 생각하며… 😭IRSA의 원리를 파헤쳐보자 시리즈 - IRSA의 원리를 파헤쳐보자 1 - K8S Admission Webhook IRSA의 원리를 파헤쳐보자 2 - K8S Sevice Account와 Service Account Token Volume Projection IRSA의 원리를 파헤쳐보자 3 - OAuth2.0 IRSA의 원리를 파헤쳐보자 4 - OIDC IRSA의 원리를 파헤쳐보자 5 - IRSA인증(authentication)과 인가(authorization)인증과 인가의 차이(출처: okta)앞으로의 내용에 인증(authentication)과 인가(authorization)이라는 단어가 계속해서 등장할 것입니다. 인증과 인가는 한국어로 보면 큰 차이가 없어 보이는 단어인데요, 보안의 맥락에서는 엄연히 다른 개념입니다. 먼저 인증이란 사용자의 신원(identity)를 확인 및 검증 하는 행위입니다. 인증의 대표적인 예로는 아이디와 비밀번호를 통한 로그인이 있습니다. 한편 인가는 사용자에게 특정 리소스나 기능에 접근할 수 있는 권한 또는 권한의 범위(scope)를 부여하는 행위를 말합니다. 우리가 네이버에 로그인(인증)을 했다고 하더라도 다른 사람의 데이터에 접근할 수 있는 권한은 없습니다. 다시 말해 타인의 데이터에 접근하는 인가는 받지 못한 것입니다.이어지는 글에서 더 자세히 설명하겠지만 인증과 인가는 각각 OIDC, OAuth2.0와 관련이 깊습니다. OIDC는 인증을 담당하는 프로토콜이며, OAuth2.0은 인가를 담당하는 프로토콜입니다. 그렇다고 해서 OIDC와 OAuth2.0이 아예 별개의 개념이진 않습니다. 오히려 서로는 매우 깊은 관련이 있습니다.OAuth2.0, 왜 필요할까?카카오, 페이스북, 구글, 애플 아이디로 다른 사이트에 로그인 할 수 있습니다.만일 우리가 하나의 웹서비스를 만들었다고 하죠. 그리고 그 서비스에 접속하는 사용자가 구글 캘린더에 등록한 일정을 보여주는 화면을 만들고 싶습니다. 그렇다면 우리 서비스는 사용자를 대신해서 구글에 접속해서 캘린더 정보를 가져올 수 있어야겠죠. 가장 쉬운 방법은 무엇일까요? 바로 우리의 구글 아이디와 비밀번호를 웹서비스에 전달해준 다음, 웹서비스가 그 정보를 그대로 이용해서 구글 캘린더의 정보를 가져오면 됩니다. 그러나 직관적으로 생각해봐도 이는 그리 좋은 방법은 아닙니다. 이러면 웹서비스가 사용자의 아이디와 비밀번호를 관리해야하는 부담감이 있고, 구글에서는 우리 웹서비스를 신뢰하기가 어렵죠.이러한 문제를 해결하기 위해 OAuth가 등장했습니다. OAuth는 최초 1.0 버전이 있은 뒤로, 현재 거론되는 OAuth는 대부분 OAuth2.0입니다(OAuth2.0은 하위 버전과 호환되지 않는다고 합니다). OAuth는 표준화된 방법과 절차에 따라 권한을 인가(authorization)하기 위한 프로토콜입니다. 혹시 ‘~로 로그인 하기’와 같은 소셜 로그인 기능을 사용해 보신적 있지 않으신가요? 사용자가 특정 웹사이트에 접속한 다음, ‘구글 아이디로 로그인 하기’ 버튼을 누르면 아이디와 비밀번호를 입력하고, 어떤 권한을 허용할 것인지 묻는 창이 나타납니다. 그리고 허용하면 구글 아이디를 통해서 다른 웹사이트에 로그인이 이루어집니다. 이러한 과정은 결론적으로 특정 웹사이트에게 구글 사용자로서의 권한을 ‘위임’해준 것입니다. 지금은 매우 단순하게 표현했지만, 사실 매우 복잡한 과정이 밑단에서 이루어져야 하며 그 과정을 표준화한 것이 바로 OAuth2.0이라고 이해하시면 됩니다.OAuth2.0의 주체지금까지 사용자, 웹서비스, 구글 등의 표현을 사용하였는데요, 이를 OAuth 진영에서 사용하는 용어로 바꿔보겠습니다. 총 4가지의 주체가 있습니다. 리소스 소유자(resource owner): 예시에서 ‘사용자’입니다. 리소스에 대한 접근 권한을 부여할 수 있는 주체입니다. 만일 리소스 소유자가 사람이라면 엔드 유저(end-user)라고도 불립니다. 리소스 서버(resource sever): 예시에서 ‘구글’입니다. 리소스를 호스팅 하는 주체입니다. 엑세스 토큰(access token)을 확인하여 리소스에 접근하려는 요청을 허가할지 거부할지 결정 할수 있습니다. 아래에서 설명할 인가 서버와 합쳐서 표현하기도 합니다. 리소스 서버에게 클라이언트가 누구인지 미리 알려주는 과정이 선행되어야 OAuth 2.0 프로토콜이 제대로 동작합니다. 이는 리소스 서버에서 client id, client secret를 발급받고, redirect uri를 등록 해두는 행위를 말합니다. 아래 OAuth2.0 동작 흐름에서 더 자세히 설명하겠습니다. 클라이언트(client): 예시에서 ‘우리 웹서비스’입니다. 리소스 오너를 대신하여 리소스에 대한 접근을 요청 하는 주체입니다. 단어 때문에 리소스 소유자와 클라이언트를 헷갈릴 수도 있습니다. 그러나 클라이언트라는 단어는 상대적인 개념입니다. 우리 웹서비스는 리소스 서버나 인가 서버 입장에서 보았을 때 클라이언트이므로 이러한 이름을 갖게 되었다고 생각할 수 있습니다. 인가 서버(authorization server): 예시에서 ‘구글’입니다. 클라이언트에서 엑세스 토큰(access token)을 발급하는 주체입니다. 리소스 오너가 자신의 신분을 성공적으로 증명했을 때 엑세스 토큰을 발급 해 줍니다. 위에서 설명한 리소스 서버와 합쳐서 표현하기도 합니다. OAuth2.0의 동작 흐름(메커니즘)먼저, OAuth2.0은 클라이언트가 리소스 소유자에게 인가를 얻어서 리소스 소유자 대신에 리소스 서버에 접근할 수 있는 방법이나 절차를 정의한 프로토콜이라는 사실을 잊지 말아야 합니다. 클라이언트는 인가를 잘 받았다는 징표로서 최종적으로 access token이라는 것을 얻을 수 있게되고, 이를 통해 정해진 권한 범위(scope) 내에서 리소스 서버의 자원을 마음껏 이용할 수 있게 되는 것입니다.클라이언트가 access token, 즉 인가를 받기 위한 방법은 여러가지가 있습니다. 각 방식마다 장단점이 존재한다고 하는데, 더 자세한 내용은 관련 자료를 참고해주세요(구체적인 내용은 더 공부하고 정리해 보겠습니다). 본 글에서는 Authorization Code Grant 방식에 집중해서 살펴보겠습니다. Authorization Code Grant: 클라이언트가 웹 서버인 경우 사용. 안정성이 높아 일반적으로 많이 사용하는 방식. Implicit Grant: 인가 서버에서 클라이언트에 곧바로 access token을 발급함. 브라우저에 access token이 그대로 노출되기 때문에 안전하지 않음. Resource Owner Password Credentials: 리소스 소유자의 인증 정보가 클라이언트에 전송된 다음 바로 인증 서버로 전송해도 되는 경우 사용 Client Credentials Grant: 클라이언트가 리소스 소유자와 동일할 경우 사용OAuth2.0: Authorization Code Grant 흐름도 리소스 서버에 우리 웹서비스를 클라이언트로 등록 client_id, client_secret을 발급받고, redirect_uri를 등록합니다. 우리 웹서비스를 클라이언트를 등록하고 client_id와 client_secret을 발급 받아둡니다. 그리고 리소스 소유자가 인증에 성공 했을 때 authorization code와 함께 사용자를 돌려 보낼 redirect_uri를 설정해야합니다. redirect_uri는 기본적으로 보안을 위해 https를 사용해야하지만 localhost의 경우는 예외적으로 http로 설정할 수 있습니다. client_id와 client_secret 또한 인가를 받으려는 클라이언트가 사전에 승인된(등록된) 대상인지를 확인하고 access_token을 발급하는데 사용됩니다. client_id는 공개되어도 상관 없지만 client_secret은 절대 유출되면 안 되는 정보입니다. 로그인 요청 및 유저 로그인 진행 리소스 소유자가 로그인 하게하고, 로그인 성공시 허용할 권한 동의 여부를 묻는다(인가). 리소스 소유자가 클라이언트의 웹서비스에서 ‘구글 아이디로 로그인 하기’ 버튼을 클릭합니다. 그러면 클라이언트는 리소스 소유자를 인가 서버의 로그인을 담당하는 웹페이지로 보냅니다(예를 들어 구글 로그인 화면 등). 이 때 client_id, redirect_uri, response_type, scope 등의 파라미터를 쿼리 스트링을 URL에 포함합니다. 요청은 다음과 같은 형태입니다. https://accounts.google.com/o/oauth2/v2/auth? scope=scope&amp;amp; response_type=code&amp;amp; redirect_uri=https%3A//oauth2.example.com/code client_id=client_id 쿼리 스트링에는 보다 다양한 파라미터를 포함할 수 있지만, 필수적인 파라미터는 다음과 같습니다. client_id: 리소스 서버에 애플리케이션(웹서비스)를 등록하고 발급 받은 클라이언트 id입니다. redirect_uri: 리소스 소유자가 로그인에 성공할 경우 리소스 소유자를 리디렉션 하는 주소입니다. 애플리케이션을 등록할 때 설정해둔 값과 정확히 일치해야 합니다. 그렇지 않을 경우 redirect_uri_mismatch 에러가 발생하게 됩니다. response_type: authorization code grant 방식으로 진행할 경우 code라고 지정합니다. scope: 인가를 해줄 권한의 범위를 뜻합니다. 로그인에 성공한 후에 사용자에게 권한 동의 여부를 묻는데, 이와 관련된 파라미터입니다. 클라이언트가 위 주소로 리소스 소유자를 이동시키면 유저는 자신의 아이디와 비밀번호를 입력하여 리소스 소유자임을 인증합니다. 최종적으로는 scope에 포함된 권한 인가를 동의 하겠냐는 안내 페이지가 보여지는데, 리소스 소유자가 이에 동의를 하면 클라이언트는 리소스 소유자를 대신하여 해당 권한을 가지고 리소스 서버에 자원을 요청할 수 있는 발판이 마련된 것입니다. authorization code 발급2번 과정을 통해 리소스 소유자가 인증을 성공적으로 수행하였다면, 인증 서버는 사전에 등록해둔 redirect_uri로 사용자를 이동시킵니다. 이때 중요한 점은 쿼리 스트링에 authorization code가 포함된다는 것입니다. authorization code는 최종적으로 access token을 발급받기 위한 임시적 성격을 가지고 있으며, 일반적으로 수명이 매우 짧습니다. authorization code는 redirect_url 뒤에 code 라는 쿼리 스트링의 value로 전달됩니다. 다음과 같은 형태입니다. https://oauth2.example.com/code?code=4/0AWgavdfkHODwoqv-iaNh4aoTlahhQIw6MzxKJ7B3liHY0U4c1tNxJ-Xaae-XwdVJkORZzg access token 교환 요청 authorization code는 임시 코드라고 하였습니다. 클라이언트는 access token을 발급 받기 위해서 authorization code, client_id, client_secret를 (구글에 경우에) token endpoint에 전송합니다. 이러한 과정은 엑세스 토큰 교환(exchange)이라고도 합니다. 다음은 access token을 발급 받기 위한 요청의 예시입니다. POST /token HTTP/1.1Host: oauth2.googleapis.comContent-Type: application/x-www-form-urlencoded code=4/P7q7W91a-oMsCeLvIaQm6bTrgtp7&amp;amp;client_id=your_client_id&amp;amp;client_secret=your_client_secret&amp;amp;redirect_uri=https%3A//oauth2.example.com/code&amp;amp;grant_type=authorization_code code: 인가 서버가 발급한 authorization code입니다. client_id: 미리 설정해둔 client_id입니다. client_secret: 미리 설정해둔 시크릿 값입니다. access token으로 교환하기 위해 처음으로 사용됩니다. redirect_uri: 인가 서버 측에 등록해둔 redirect_uri와 같은 값인지 확인하기 위해 필요합니다. grant_type: 반드시 ‘authorization_code‘라는 문자열이어야 합니다. 위의 요청 예시를 보면 그간의 예시와 조금 형태가 달라졌음을 알 수 있는데요. access token의 경우 매우 중요한 토큰이다보니 기존처럼 브라우저를 통한 쿼리 스트링으로 전달할 경우 심각한 보안상 위협을 초래할 수 있습니다. 따라서 access_token을 다룰 때는 보통 클라이언트의 백엔드 서버가 이를 처리하는 것이 일반적인 프랙티스라고 할 수 있겠습니다. 백엔드가 처리하면 엔드 유저의 브라우저에는 엑세스 토큰이 직접적으로 노출되지 않기 때문에 훨씬 안전한 방법입니다. access token 발급 인증 서버는 authorization code, client_id, client_secret을 검증하고 access_token을 발급해줍니다. 이 토큰은 매우 중요하므로 절대 유출이 되어서는 안됩니다. 클라이언트는 이를 자신들의 안전한 백엔드 DB에 저장해두어야 합니다. 요청이 정상적으로 처리되면 아래와 같은 응답을 받게 됩니다. HTTP/1.1 200 OKContent-Type: application/json;charset=UTF-8Cache-Control: no-storePragma: no-cache {&quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,&quot;token_type&quot;:&quot;example&quot;,&quot;expires_in&quot;:3600,&quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;,&quot;example_parameter&quot;:&quot;example_value&quot;} access_token: 클라이언트가 리소스 오너를 대신해서 특정 권한 범위(scope)내에서 리소스 서버의 자원에 접근할 수 있게 만드는 중요한 토큰입니다. expires_in: access_token은 보안상 매우 중요하므로 만료 기간이 정해져있습니다. 만일 만료 기간이 지난 access_token으로 리소서 서버에 엑세스 한다면 HTTP 401 에러가 발생합니다. refresh_token: access_token의 만료기간이 지났을 경우 유저를 다시 로그인 시키게 하는 것은 번거로울 수 있습니다. access_token 발급 시에 refresh token이라는 것도 같이 발급되는데, 클라이언트 이를 저장해 두었다가 401 에러가 발생할 경우 refresh_token을 전송하면됩니다. 이 경우 access_token이 바로 발급 됩니다. access token으로 리소스 요청 및 응답클라이언트는 access token으로 리소스 서버에 엑세스 하여 리소스 오너의 자원을 가져올 수 있게 됩니다. 왜 귀찮게 authorization code를 access token으로 교환하는 과정이 있을까(참고1, 참고2)?OAuth를 정리하면서 가장 의문이 생겼던 점입니다. 굳이 왜 귀찮게 authorization 코드를 받은 다음, 이를 다시 access token으로 교환하는 과정이 있는 걸까요? 결론부터 말하면 보안상의 안전성을 위한 것입니다. 일반적인 OAuth의 흐름을 따른다면, 브라우저라는 존재가 반드시 끼게 됩니다. 엔드 유저가 클라이언트(웹 서버)에 접근하는 가장 일반적인 방법이 브라우저로 접속하는 것이니까요. 따라서 flow를 쭉 진행하다보면 자연스럽게 authorization code는 redirect_uri에 쿼리스트링으로 전달됩니다. 만일 redirect_uri에 access token을 한번에 쿼리 스트링으로 전달한다면 브라우저에 쉽게 저장되고 노출되기 때문에 보안상 심각한 위협이 될 수 있습니다.따라서 authorization code라는 임시 시크릿을 쿼리 스트링에 태워서 클라이언트의 프론트엔드로 전달한 뒤, 이를 안전하게 처리할 수 있는 백엔드 서버에서 access token으로 교환하는 과정이 아무래도 보안상 안전합니다. 브라우저에 그대로 노출되지 않기 때문입니다.참고자료 AWS EKS의 RBAC, IRSA 딥다이브 https://developers.google.com/identity/protocols/oauth2/openid-connect Naver D2 - OAuth와 춤을 JWT (Json Web Token) Audience “aud” versus Client_Id - What’s the difference? OAuth 그리고 OpenID Connect ID Tokens vs Access Tokens ID Token and Access Token: What’s the Difference? The OAuth 2.0 Authorization Framework JWT(JSON Web Token)을 이용한 API 인증 - #1 개념 소개 OIDC (OpenID Connect) 인증과 인가 (권한 부여) 비교 – 특징 및 차이점 OpenID(OIDC) 개념과 동작원리 OAuth 2.0 개념과 동작원리 OAuth 개념 및 동작 방식 이해하기 OAuth 2.0 기반 인증 방식 OAuth 2.0 - Authorization code Grant OAuth 2.0 - Implicit Grant OAuth 2.0을 사용하여 Google API에 액세스하기 웹 서버 애플리케이션용 OAuth 2.0 사용 What is the purpose of authorization code in OAuth OAuth" }, { "title": "IRSA의 원리를 파헤쳐보자 2 - K8S Sevice Account와 Service Account Token Volume Projection", "url": "/posts/service_account_volume_projection/", "categories": "MLOps, Kubernetes, IRSA", "tags": "kubernetes, k8s, service account, service account token volume projection, irsa", "date": "2022-10-26 22:12:00 +0900", "snippet": "IRSA의 원리를 파헤쳐보자 시리즈의 마지막 글입니다. 저번 글에서는 admission webhook을 학습했습니다. 요약하자면 EKS 클러스터를 설치하면 control plane에 pod identity webhook이라는 webhook server(일종의 API 서버)가 함께 배포되고, pod identity webhook은 서비스 어카운트에 iam arn이 annotation 되어 있으면 요청 내용을 변형하여 파드를 생성합니다. 생성된 파드에는 환경 변수와 토큰값이 저장되어 있어서 이를 활용해 AWS 리소스에 접근할 수 있게 됩니다.이번 글에서는 파드에 생성되는 환경 변수와 토큰값이 무엇인지 살펴보고, 최종적으로 어떻게 파드가 AWS 리소스와 통신을 할 수 있게 되는지 살펴보겠습니다.IRSA의 원리를 파헤쳐보자 시리즈 IRSA의 원리를 파헤쳐보자 1 - K8S Admission Webhook IRSA의 원리를 파헤쳐보자 2 - K8S Sevice Account와 Service Account Token Volume Projection서비스 어카운트(service account)와 토큰(token)쿠버네티스 클러스터에 파드를 생성하면 같은 네임스페이스에 default라는 서비스 어카운트(service account)와 여기에 마운트되는 시크릿(secret)이 자동적으로 생성됩니다. 이 시크릿을 살펴보면 토큰(token)이라는 필드가 있고, 매우 긴 스트링이 할당되어 있습니다. default 네임스페이스에 default라는 이름을 이름을 가진 서비스 어카운트의 정보를 확인해봅시다.kubectl describe sa default -n default그러면 default-token-64rhn라는 이름을 가진 시크릿이 해당 서비스 어카운트에 마운트 되어 있는 것을 확인할 수 있습니다.Name: defaultNamespace: defaultLabels: &amp;lt;none&amp;gt;Annotations: &amp;lt;none&amp;gt;Image pull secrets: &amp;lt;none&amp;gt;Mountable secrets: default-token-64rhnTokens: default-token-64rhnEvents: &amp;lt;none&amp;gt;그럼 저 시크릿에 어떤 정보가 있는지 확인해볼까요? 다음의 명령어로 확인 가능합니다.kubectl describe secrets default-token-64rhn -n default그러면 서두에서 언급했던 토큰(token) 정보가 저장되어 있음을 확인할 수 있습니다.Type: kubernetes.io/service-account-tokenData====ca.crt: 1066 bytesnamespace: 7 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6Il9MTTM0aHpjYmYwck5sWGNTcUZIVExEazc2M2xfTkZTenBkb3JyMHk1UlkifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRlZmF1bHQtdG9rZW4tNjRyaG4iLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVmYXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjI3NTI0OGFhLTQyNjMtNDU1My1iZDlmLWY3M2Y2MjAwYTQyZSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmRlZmF1bHQifQ.xIgO11X5hM5mHlPak8wcqHKq98BnppWq2OM07URa0JdXc4TeMySI534sHXlFiUNJfA7OX7_x4JtLyo7rxPQKl1c7lHnt2DYFMDhXyui9v6x7Y_IEH4vSe-7Vo5iyv0Nf9kKY8aKq5fqOS2MwsomZnrjhpDKBU6-mlxEF9XKtJH5YKN3FZ-ZDv-cJXlrTAUFwPj_KfY_ypAKBdhDtBJQTQKgQrNZXCDTXEJ4dqUhnPikLwv6_pwC0w1Kn9EyBLUfPjXka8A8kdsbl1RKGkfxetOR9-AJUlemg4ugCt7A5FP-nSF_95Q6RBYcCwgYg1595pj3YEOT8r-05bxOQEt8SrA여기에 방문해서 토큰 정보를 붙여 넣으면 토큰의 정보를 디코딩 할 수 있습니다. 토큰의 페이로드 부분만 떼 놓고 보면 아래의 정보가 담겨 있습니다. 이 토큰은 JWT(Json Web Token) 형태입니다.{ &quot;iss&quot;: &quot;kubernetes/serviceaccount&quot;, &quot;kubernetes.io/serviceaccount/namespace&quot;: &quot;default&quot;, &quot;kubernetes.io/serviceaccount/secret.name&quot;: &quot;default-token-64rhn&quot;, &quot;kubernetes.io/serviceaccount/service-account.name&quot;: &quot;default&quot;, &quot;kubernetes.io/serviceaccount/service-account.uid&quot;: &quot;275248aa-4263-4553-bd9f-f73f6200a42e&quot;, &quot;sub&quot;: &quot;system:serviceaccount:default:default&quot;}토큰의 발급자(iss)가 누구인지와 엔드 유저(sub)가 누구인지 적혀 있습니다. 다시 말해 kubernetes/serviceaccount가 이 토큰을 발급 했으며, system:serviceaccount:default:default가 이 토큰의 엔드 유저입니다. 이 토큰은 서비스 어카운트를 사용하는 파드에 마운트 됩니다 /var/run/secrets/kubernetes.io/serviceaccount 경로를 찾아가 보면 찾을 수 있습니다. 파드가 kube-apiserver와 통신을 할 때, header 부분에 토큰을 실어서 보내게 되는데 kube-apiserver에서는 이 토큰이 유효한지 판단한 후 토큰에서 서비스 어카운트의 이름을 얻어냅니다. 그리고 서비스 어카운트에 바인딩 된 롤을 확인하고 인가(authorization)를 통해 특정 행위를 수행할 권한이 있는지를 확인하고 요청 내용을 처리합니다.그러나 이러한 기본 토큰은 쿠버네티스 내에서 사용하기 설계되었기 때문에 다음의 문제점이 있습니다: 토큰에 유효기간이 없습니다. 만일 어드민 롤이 바인딩된 서비스 어카운트의 토큰이 유출된다면 보안에 심각한 문제가 발생할 것입니다. audience 개념이 없습니다. audience는 이 토큰을 활용하여 여러 서비스나 리소스에 접근하는 대상을 말합니다. 만일 어떤 유저가 웹사이트 A가 토큰을 웹사이트 B에 넘겨 주었을 때, 웹사이트 B가 웹사이트 A를 가장하여 기밀한 자원에 엑세스할 수 있습니다. 외부 서비스와 쉽게 통합되기 어렵습니다. 쿠버네티스 기본 서비스 어카운트 토큰은 쿠버네티스에서만 사용하는 필드들이 많이 있습니다. 따라서 OAuth2.0이나 OIDC 프로토콜 위에 구현된 웹서비스가 쿠버네티스 기본 토큰을 활용하기 위해서는 추가적으로 기능 개발을 해야하는 수고가 있습니다.이러한 문제들은 쿠버네티스 1.21 이상부터 제공하는 Service Account Token Volume Projection이라는 기능을 활용하면 해결할 수 있습니다.Service Account Token Volume Projection위에서 살펴본 것처럼 기본 쿠버네티스 서비스 어카운트가 제공하는 토큰은 내부에서의 활용만 고려하여 설계 되었기 때문에 외부 서비스에 엑세스 하기 위해서는 추가적인 정보들이 필요합니다. 추가적인 정보들엔 무엇이 있고, 왜 필요한지에 대해서는 이어지는 글에서 더 자세히 설명할 예정입니다. 지금은 기본 서비스 어카운트의 토큰은 외부의 리소스에 접근하는데 사용하기엔 뭔가 부족하구나~ 그래서 추가적인 정보를 주입해 주어야 하는구나~ 라고 생각하고 넘어가주세요.쿠버네티스 1.12 이후 부터는 Service Account Token Volume Projection라는 기능을 사용할 수 있는데, 이를 통해 kubelet이 토큰에 추가적인 정보(토큰의 유효기간, audience 등)를 주입시킬 수 있게 됩니다. 예를 들어 파드 생성시 토큰에 유효시간: 1시간, audience: foobar.com이라는 정보를 주입하고 싶으면 아래와 같이 매니패스트를 작성하면 됩니다. 새롭게 추가된 필드는 다음과 같습니다: spec.volumes[0].projected.source[0].serviceAccountToken.expirationSeconds: 7200 -&amp;gt; 유효시간 2시간 spec.volumes[0].projected.source[0].serviceAccountToken.audience-&amp;gt; audience는 vaultapiVersion: v1kind: Podmetadata: name: basic-debian-pod-bound-token namespace: defaultspec: serviceAccountName: default containers: - image: debian name: main command: [&quot;sleep&quot;, &quot;infinity&quot;] volumeMounts: - name: my-bound-token mountPath: /var/run/secrets/my-bound-token volumes: - name: my-bound-token projected: sources: - serviceAccountToken: path: token audience: foobar.com expirationSeconds: 3600위 매니패스트로 생성된 파드에는 /var/run/secrets/my-bound-token 경로에 다음과 같은 토큰이 마운트 되어 있습니다.{ &quot;aud&quot;: [ &quot;foobar.com&quot; ], &quot;exp&quot;: 1636151360, &quot;iat&quot;: 1636147760, &quot;iss&quot;: &quot;https://oidc.eks.ap-northeast-2.amazonaws.com/id/B0678ED568FC12BBC37256BBA2A4BB53&quot;, &quot;kubernetes.io&quot;: { &quot;namespace&quot;: &quot;default&quot;, &quot;pod&quot;: { &quot;name&quot;: &quot;basic-debian-pod-bound-token&quot;, &quot;uid&quot;: &quot;a593ded9-c93d-4ccf-b43f-bf33d2eb7635&quot; }, &quot;serviceaccount&quot;: { &quot;name&quot;: &quot;default&quot;, &quot;uid&quot;: &quot;ab71f2b0-abca-4bc7-905a-cc9b2d6832cf&quot; } }, &quot;nbf&quot;: 1636147760, &quot;sub&quot;: &quot;system:serviceaccount:default:default&quot;}기본 서비스 어카운트의 토큰과 생김새가 많이 다릅니다. 가장 크게 변화된 부분은 aud, exp, iat 필드가 있다는 점인데요, 이 토큰은 OIDC의 표준 포맷을 따른 다른다는 점이 중요합니다. 따라서 쿠버네티스 파드와 외부 서비스를 쉽게 통합할 수 있게 되었습니다. 또한 토큰의 유효기간(exp) 필드가 생겨서 외부 서비스가 이 토큰의 유효성을 쉽게 검증할 수 있습니다.마무리본 글에서는 IRSA를 이해하기 위한 배경 지식으로 쿠버네티스 서비스 어카운트와 서비스 어카운트 볼륨 프로젝션에 대해서 살펴보았습니다. 핵심은 기본 서비스 어카운트에 부족한 정보들을 서비스 어카운트 볼륨 프로젝션을 활용하여 추가적으로 주입시킬 수 있다는 것입니다. 그리고 새롭게 추가되는 정보들은 OIDC 프로토콜의 표준 포맷을 잘 따르기 때문에, 이에 기반하여 구축된 서비스들과 쉽게 통합될 수 있다는 점이 큰 장점입니다.다음 시간에는 지금까지 2개의 시리즈 글에서 배웠던 내용을 통해 IRSA의 전체적인 프로세스를 이해하는 시간을 가져볼 수 있을 것 같습니다. 저번 글에서 살펴본 pod identity webhook이 추가한 정보들은 무엇인지, 서비스 어카운트 볼륨 프로젝션을 통해 파드에 마운트된 토큰은 어떤 방식으로 활용되는지 등을 좀 더 구체적으로 살펴보겠습니다. 그리고 이번 시리즈 글을 마무리 하도록 하죠!참고자료 Configure Service Accounts for Pods 지구별 여행자 - Service Account Token Volume Projection OpenID Connect explained What GKE users need to know about Kubernetes’ new service account tokens" }, { "title": "IRSA의 원리를 파헤쳐보자 1 - K8S Admission Webhook", "url": "/posts/admission_webhook/", "categories": "MLOps, Kubernetes", "tags": "kubernetes, k8s, admission controller, admission webhook, pod identity webhook", "date": "2022-09-13 23:25:00 +0900", "snippet": "IRSA(IAM Role for Service Account)는 AWS EKS에서 파드 단위로 권한을 관리하기 위한 방법 또는 프로세스입니다. 요즘에 회사에서 kubeflow를 셋팅하고 있는데 AWS의 특정 리소스(S3 등)와의 통신을 위해 파드에 일정 권한을 부여해야할 상황이 자주 발생합니다. 저는 이때 주로 IRSA를 활용하여 업무를 진행하고 있습니다. IRSA를 활용하면 권한 관리가 매우 수월하고, 보안과 관련된 사항이 노출될 위험도가 낮기 때문입니다. IRSA의 대안으로 Secret을 활용할 수 있습니다. 그러나 Secret은 namespaced resource 이므로 작업성이 더 떨어진다고 느껴져서 그다지 선호하지 않습니다(하지만 직관적인 방법인 것은 사실입니다).IRSA를 활용하는 것 자체는 그다지 어려운 일은 아닙니다. AWS IAM의 체계와 쿠버네티스 기본 개념만 있다면 손쉽게 적용할 수 있습니다. 그러나 IRSA의 동작 방식을 이해하기 위해서는 많은 배경지식이 필요합니다. 이 시리즈를 시작한 목적도 제가 현업에서 IRSA의 동작 과정상 필요한 배경지식을 제대로 파악하지 못 하고 단순 활용만 하고 있었기에 제대로 된 정리가 필요하다는 생각이 들어서였습니다.그래서 준비 했습니다. IRSA의 원리를 파헤쳐보자 시리즈! 앞으로 IRSA의 작동 원리를 완벽하게 이해하기 위해서 필요한 요소들을 정리하고자 합니다. 그 첫번째 순서로 쿠버네티스 admission webhook을 다뤄보겠습니다. admission webhook은 IRSA가 이루어지기 위한 쿠버네티스쪽의 필수 오브젝트입니다.Admission Controller란?Admission Controlleradmission control(출처: Kubernetes Admission Control)admission controller란 kubernetes api server를 호출 했을 때, 요청 내용을 가로채서(intercept) 변형(mutating)하거나 검증(validating)하는 쿠버네티스 plugin의 집합을 가르킵니다. admission controller가 개입하여 무엇인가 하는 것을 admission control이라고도 표현할 수 있겠습니다. 앞서 언급 했지만 admission control은 크게 2단계로서 변형(mutating), 검증(validating) 단계가 있습니다. 모든 단계를 성공적으로 통과한 요청은 etcd에 저장(persistence) 됩니다.변형(mutating)은 요청 내용을 수정하는 것을 말합니다. 예를 들어 특정 조건을 만족시킬 때 환경 변수를 추가적으로 주입시키는 등의 행위를 할 수 있습니다. 검증(validating)은 해당 요청 내용이 실제 쿠버네티스 클러스터에 적용되어도 되는지 확인합니다. 만약 부적절한 요청일 경우 거절 될 수 있습니다. 예를 들어서 특정 네임스페이스가 차지할 수 있는 리소스의 총량을 초과한다면 해당 요청은 거절 될 수 있습니다. 너무 추상적인 개념 위주로만 설명하니 별로 와 닿지 않네요. 구체적인 사례를 들어 볼까요? 여러분이 아실만한 admission controller에는 다음과 같은 것들이 있습니다. LimitRange, ResourceQuota: 특정 네임스페이스의 자원의 한계치를 컨트롤 합니다. ServiceAccount: 자주 사용하던 ServiceAccount도 admission controller의 한 종류입니다. ServiceAccount에 대한 자동화(automation)가 구현되어 있습니다. NamespaceLifecycle: Terminating 단계에 있는 namespace에 object가 배포되는 것을 거절(deny) 합니다.이러한 admission controller는 쿠버네티스 클러스터를 생성하면 기본적으로 kube-apiserver에 binary 형태로 컴파일 되어 존재합니다. 만일 새로운 admission controller을 만들었고 이를 쿠버네티스 클러스터에 적용하고 싶다면, 이를 binary로 컴파일해서 kube-apiserver에 적용해야 합니다. 이러한 작업이 자주 발생한다면 어떨까요? 컴파일을 반복적으로 수행해야 하기 때문에 번거롭고 유연성이 떨어질 것입니다. 이와 같은 불편함을 해결하고자 admission webhook이라는 개념이 등장하게 되었습니다.Admission Webhooksadmission webhook (출처: Diving into Kubernetes MutatingAdmissionWebhook)admission webhooks이란 요청 내용을 변형(mutating)하는 mutating webhook과 검증(validating)하는 validating webhook을 통칭하는 개념입니다(admission webhook은 쿠버네티스 1.9 버전부터 등장했습니다). webhook이라는 단어가 여기저기 등장해서 개념이 혼용될 수 있는데, kube-apiserver에서 mutating admission을 담당하는 admission controller인 MutatingAdmissionWebhook과 admission webhook의 한 종류인 mutating webhook은 서로 다른 개념이라는 것을 꼭 인지해야합니다. MutatingAdmissionWebhook은 admission control 상의 하나의 과정 혹은 단계(phase)이며, mutating webhook은 실제로 요청 내용을 변형하거나 검증하는 주체입니다. 이는 validating에서도 동일하게 적용됩니다.공식 문서에서는 admission webhooks(mutating webhook 및 validating webhook)을 admission request를 받아서 특정 행위를 수행하는 HTTP callback이라고 표현합니다. 여기서 말하는 callback은 특정 이벤트에 따라 호출되어지는 함수라고 생각하는게 이해하기 쉽습니다.admission webhook은 흔히 생각할 수 있는 API 서버의 형태로 구현됩니다. 따라서 admission webhook을 좀 더 구체적으로 표현하기 위해 (admission) webhook sever라고 표현하기도 합니다(위 그림에서는 webhook sever로 표현되어 있습니다). 일반적인 admission controller는 유연성이 떨어진다고 언급하였는데요. admission webhooks는 어떤 방식으로 동작하기에 이런 한계를 극복할 수 있었을까요?어떤 요청이 kube-apiserver에 도착하면 인증 및 인가를 거친 후 여러가지 admission controller를 통과하며 그 요청 내용이 변화하게 됩니다. 그러다가 MutatingAdmissionWebhook에 단계에 도착하면 쿠버네티스는 MutatingWebhookConfiguration을 살펴보면서 해당 요청이 여기에 적힌 조건에 부합하는지를 판단합니다. 만일 특정 조건에 부합한다면 이를 처리할 수 있는, kube-apiserver 밖에 존재하는 mutating webhook (sever)로 해당 요청을 보냅니다. 이 때 admissionReview라는 데이터를 POST 방식으로 body에 실어서 보냅니다. mutating webhook에는 해당 데이터를 처리하는 로직이 구현되어 있고 그 결과를 응답으로 돌려 줍니다.정리하자면 쿠버네티스는 admission webhook이라는 새로운 개념을 통해서 admission control 로직을 외부의 API, 즉 admission webhook (sever)에 맡길 수 있게 되었습니다. 따라서 새로운 admission control 로직을 적용하고자 할 때 kube-apisever에 존재하는 admission controller들처럼 컴파일 과정을 거칠 필요가 없습니다. 그저 어떤 조건을 만족할 때 어느 API로 보낼지를 결정하고(MutatingWebhookConfiguration), admission webhook (server)를 새로 배포하기만 하면 됩니다. 그렇기 때문에 일반적인 admission controller 보다 유연성이 높다라고 할 수 있습니다. admission webhook은 다음과 같은 것들이 있습니다. Istio Envoy Sidecar: 파드 생성 요청이 오면 해당 파드에 Envoy Sidecar 컨테이너를 강제로 주입합니다. StorageClass 프로비저닝: PVC가 생성되는 것을 지켜보다가 자동으로 PVC에 미리 선언된 StorageClass를 주입합니다. pod-identity-webhook: EKS를 생성하면 control plane에 자동으로 생성되는 admission webhook입니다. serviceAccount에 iam arn이 선언되어 있으면 pod의 스펙을 변형합니다.admission webhook의 구현과 관련된 자세한 사항은 본 글의 범위를 벗어나므로 자세한 사항은 링크1, 링크2 등의 글을 참고해주세요. 본 글의 주제와 크게 관련이 없어 설명하진 않았지만 admission webhook이 작동하기 전에 kube-apiserver를 호출한 개체가 승인된 개체인지 인증(authentication)하는 과정과 그 개체가 특정 행위를 수행할 수 있는 권한이 있는지 인가(authorization)하는 과정이 먼저 선행됩니다.Admission Webhook 예시: Pod Identity WebhookEKS 클러스터를 셋팅하면 기본적으로 pod-identity-webhook(mutating webhook)이 생성됩니다. 그러나 해당 webhook은 EKS가 관리하는 control plane에 존재하기 때문에 일반적인 방법으로는 해당 admission webhook을 직접 보긴 어렵습니다. 그래도 우리는 간접적으로 그 존재를 알 수 있는데, 클러스터에 생성된 pod-identity-webhook MutatingWebhookConfiguration 오브젝트를 찾을 수 있습니다....kind: MutatingWebhookConfigurationwebhooks: clientConfig: url: https://127.0.0.1:23443/mutate rules: - apiGroups: - &quot;&quot; apiVersions: - v1 operations: - CREATE resources: - pods scope: &#39;*&#39;해당 매니패스트를 간단하게 살펴보면 다음과 같은 규칙이 적혀 있습니다: kube-apiserver에 pod를 생성하는 요청이 들어왔을 때, https://127.0.0.1:23443/mutate 주소를 가진 mutating webhook server로 보냅니다(아마 pod-identity-webhook의 주소라고 생각됩니다).해당 mutating webhook server는 파드의 ServiceAccount에 metadata.annotations.eks.amazonaws.com/role-arn가 선언되어 있는 요청일 경우, IRSA를 위한 환경 변수를 설정하거나 projected volume을 설정하는 요청으로 변환합니다. 즉 요청의 변형(mutating)이 일어나는 것이죠. 아래의 매니패스트를 클러스터에 배포해서 pod-identity-webhook의 개입(intercept) 결과를 확인 해보도록 하죠. iam role arn이 명시된 ServiceAccount와 그 ServiceAccount를 활용하는 파드를 생성하는 간단한 매니패스트입니다.apiVersion: v1kind: ServiceAccountmetadata: annotations: eks.amazonaws.com/role-arn: arn:aws:iam::1234567890:role/mutating-webhook-tutorial-role # 적절한 값으로 수정 필요 name: mutating-webhook-tutorial-sa namespace: default---apiVersion: v1kind: Podmetadata: name: mutating-webhook-tutorial-podspec: serviceAccount: mutating-webhook-tutorial-sa containers: - name: mutating-webhook-tutorial image: busybox command: [&#39;sh&#39;, &#39;-c&#39;, &#39;echo Mutating Webhook Tutorial!! &amp;amp;&amp;amp; sleep 3600&#39;]위 매니패스트를 작성하고 쿠버네티스에 배포하면 Pod에 다음과 같은 값들이 추가적으로 설정되어 있음을 알 수 있습니다. env[*].name env[*].value volumeMounts volumesapiVersion: v1kind: Podspec: ... env: - name: AWS_DEFAULT_REGION value: ap-northeast-2 - name: AWS_REGION value: ap-northeast-2 - name: AWS_ROLE_ARN value: arn:aws:iam::1234567890:role/mutating-webhook-tutorial-role - name: AWS_WEB_IDENTITY_TOKEN_FILE value: /var/run/secrets/eks.amazonaws.com/serviceaccount/token ... volumeMounts: - mountPath: /var/run/secrets/eks.amazonaws.com/serviceaccount name: aws-iam-token ... volumes: - name: aws-iam-token projected: defaultMode: 420 sources: - serviceAccountToken: audience: sts.amazonaws.com expirationSeconds: 86400 path: token분명히 매니패스트를 배포할 당시에는 이와 같은 환경 변수를 어디에도 설정하지 않았습니다. 그렇데 어떻게 실제 배포된 파드에 저런 환경 변수들이 셋팅되어 있을까요? 이는 admission webhook(구체적으로는 mutating webhook)인 pod-identity-webhook가 요청 내용을 가로채서 파드의 환경 변수에 AWS_DEFAULT_REGION, AWS_REGION, AWS_ROLE_ARN, AWS_WEB_IDENTITY_TOKEN_FILE를 생성하고, serviceAccountToken을 파드에 볼륨 마운트하는 내용으로 변형(mutating) 했기 때문입니다. 물론 검증(validating) 단계도 정상적으로 통과 했기 때문에 해당 요청 내용은 etcd에 적재 되었을 것입니다. 이와 관련된 좀 더 자세한 내용은 링크를 참조해 보시면 좋을 듯 합니다.마무리간단하게 admission controller를 살펴보았고, 그들의 한계점을 살펴보았습니다. 그리고 그 한계점을 극복하기 위한 새로운 개념인 admission webhooks도 살펴보았습다. kube-apiserver에 보내지는 요청 내용을 중간에서 변형(mutating) 하거나 검증(validating) 할 수 있으므로 안 그래도 자유로운 쿠버네티스에 더 유연성을 더해줄 수 있는 컴포넌트라는 생각이 듭니다. 그러나 아직 우리는 pod-identity-webhook이 요청을 변형한 결과의 의미를 명확하게 살펴보지 않았습니다. 그러나 마운트 되는 환경 변수를 자세히 보면 뭔가 AWS IAM과 관련된, 즉 권한 관리와 밀접하게 관련되어 있다는 사실을 짐작할 수는 있겠습니다. 앞으로 IRSA 시리즈 글에서 더 구체화 시켜 보시죠.참고자료 What are Kubernetes admission controllers? Dynamic Admission Control [Webhook] 웹훅이란? 쿠버네티스 Admission Control #1 EKS에서 쿠버네티스 포드의 IAM 권한 제어하기: Pod Identity Webhook 콜백 함수(Callback)의 정확한 의미는 무엇일까? Diving into Kubernetes MutatingAdmissionWebhook" }, { "title": "HTTPS의 동작 원리와 그 구성 요소들", "url": "/posts/https_ssl_tls/", "categories": "CS, Network", "tags": "https, ssl, tls, ca, certificate", "date": "2022-08-07 10:28:00 +0900", "snippet": "최근 회사에서 MLOps 업무를 진행 중입니다. 그 과정에서 HTTPS 연결을 셋팅해야 하는 일이 있는데, 이와 관련된 개념들이 헷갈리고 혼재된 것들이 스스로 많다고 느껴서 이참에 정리 해보려고합니다. 참고로 글을 나눌까 하다가… 어짜피 다 관련된 내용들이라 한 글에 다 정리하였습니다. 따라서 글이 좀 길 수는 있습니다만 관심 있으신 분들이라면 천천히 읽어 보시길 추천드립니다. 🐢본 글에서는 다음의 내용을 다룹니다. HTTPS SSL/TLS 인증 기관(CA) 및 인증서(SSL Cerificate) 대칭키 및 비대칭키(공개키, 개인키) SSL Handshake네트워크에서는 아무도 믿지 마라!HTTPS와 SSL/TLS는 네트워크에서 그 누구도 신뢰할 수 없다는 전제를 바탕으로 합니다. 우리는 거의 매일 접속하는 네이버, 구글 등의 사이트에 접속해서 많은 일을 합니다. 예를 들어 네이버에 접속하기 위해서 우리는 브라우저에 https://www.naver.com을 입력하고 엔터를 누르게 됩니다. 그리고 초록색 화면이 잔뜩한 사이트의 메인 페이지가 브라우저에 뜨게 되죠. 여러분이 보고 계신 화면은 진짜 우리가 접속을 의도 했던 ‘네이버’가 맞나요? 어떻게 신뢰할 수 있을까요?당연한 그 사이트는 진짜 내가 접속하려고 했던 네이버가 맞습니다. 그러면 어떻게 브라우저는 진짜 네이버가 맞는지를 신뢰하고 나에게 그 화면을 보여주는 것일까요? 바로 이 ‘신뢰’를 형성하는 네트워크 기술이 HTTPS, SSL/TLS 이라고 할 수 있습니다. 그리고 이들은 네트워크의 ‘보안’을 향상시키기 위한 장치들입니다.헷갈리는 용어 정리HTTP vs HTTPSHTTP는 하이퍼텍스트(HTML) 파일을 주고 받을 때 사용하는 통신 규약입니다(HTTP에 관한 자세한 이야기는 좋은 문서들이 많으니 생략하겠습니다). 브라우저에 http://www.naver.com을 입력하는 행위는 http를 활용하여 네이버와 통신하겠다는 의미입니다.그럼 HTTPS는 무엇일까요? 여러 자료를 참고해 보면 HTTP + {Secure, Over SLL, Over TLS} 등으로 다양한 용어가 혼재되어 있습니다. 하지만 보안이 강화된 HTTP를 의미한다는 것이 본질적 내용입니다. HTTPS는 SSL/TLS 프로토콜 위에서 동작하는 HTTP의 보안이 강화된 버전이라고 할 수 있습니다.SSL VS TLSSSL(Secure Socket Layer)과 TLS(Transport Layer Security)은 본질적으로 같은 용어입니다. SSL은 1994년 넷스케이프에서 처음 제안하였고, 이후에 표준화 관리 기구인 IETF(국제 인터넷 표준화 기구)에서 표준화 하면서 정의한 용어가 TLS입니다. 따라서 TLS와 SSL은 버전이 다른 정도라고 이해하면 되겠습니다.CA(Certificate authority)적어도 우리들에겐 네이버(https://www.naver.com)는 믿을만한, 신뢰할만한 웹사이트입니다. 그러나 네트워크에는 셀수 없이 많은 웹사이트가 존재할텐데, 이 중에는 개인 정보를 탈취하기 위해 만들어진 웹사이트도 있을 것입니다. 따라서 브라우저는 유저가 접속하려는 웹사이트가 신뢰할만한 곳인지 아닌지를 알아내는 것부터가 보안의 시작이라고 할 수 있겠습니다.웹사이트의 신뢰성을 인정해주는 민간 기업들이 있는데 이러한 기업들을 CA라고 합니다. CA에는 계층 구조가 있는데 가장 최상위의 CA를 루트 인증 기관(Root CA)라고 하며, 그 밑에 있는 CA들을 중간 인증 기관(intermediate CA)라고 합니다.SSL/TLS를 이용하여 암호화된 통신 방식을 활용하고 싶은 웹사이트는 이러한 CA들을 통해서 ‘인증서’를 구입하여야 합니다. CA들은 해당 웹사이트를 다각도로 평가하고 ‘인증서’를 발급해줍니다. 이 인증서가 있는 웹사이트는 신뢰할만한 기관에서 보안과 신뢰성을 보장해준 것이라고 할 수 있습니다.각 브라우저는 공인된 CA의 리스트와 해당 CA의 공개키를 미리 내장하고 있습니다. 이는 인증서가 CA측의 개인키로 암호화 되어 있기 때문에, 인증서의 내용을 읽기 위해서는 CA의 공개키가 필요하기 때문입니다. 공개키는 아래에서 자세히 설명할 것이며, 지금은 그냥 CA가 가진 시크릿(secret)이라고 생각하고 넘어가 주세요.SSL 인증서(SSL Certificate)네이버에 접속 했을 때 인증서 내용그렇다면 인증서에는 어떤 내용이 적혀 있을까요? 다음의 내용이 포함되어 있습니다. 웹사이트의 정보 인증서를 발급한 CA, 도메인 주소 웹사이트의 신뢰성 검증을 위한 용도 웹사이트의 공개키 정보 공개키 내용, 공개키 암호화 방법 클라이언트와 서버가 데이터를 주고 받을 때의 보안과 관련된 사항 도메인 주소나 공개키는 서버측에서 CA에서 인증서를 받고자 할 때 제출해야하는 정보입니다. CA는 웹사이트와 웹사이트의 공개키 정보를 CA측의 개인키로 암호화 합니다. 이것이 바로 인증서의 실체입니다. 위의 이미지는 해당 인증서를 CA의 공개키로 복호화한 내용이라고 할 수 있겠네요. 그리고 인증서에는 웹사이트의 공개키가 포함 되어 있다는 사실을 꼭 기억해주세요! 이후 설명할 SSL handshake 단계를 이해하기 위해 꼭 필요한 내용입니다.대칭키 및 비대칭키CA 및 인증서의 내용을 다루다보니 계속해서 ‘공개키’라는 단어가 등장했습니다. 이를 이해하기 위해서는 암호화 방식인 대칭키 및 비대칭키에 대한 개념적인 이해가 필요합니다 대칭키(symmetric cryptography): 암호화와 복호화에 같은 비밀키를 사용 하는 방식 비대칭키(asymmetric cryptography): 암호화와 복호화에 다른 비밀키를 사용하는 방식 참고로 앞으로 계속 등장할 비밀키란 일종의 랜덤한 숫자나 문자입니다. 평문(plain text)과 비밀키로 어떤 연산을 수행하면 암호문(ciphertext)을 얻을 수 있습니다. 어떤 암호화 방법이든지 이를 구현하는 알고리즘의 종류는 매우 많고 이에 따른 동작 방식도 다릅니다.대칭키대칭키 암호화 방식대칭키 암호화 방식은 암호화와 복호화에 동일한 비밀키를 사용합니다. 예를 들어 보죠. Bob이 Alice에서 ‘Hello Alice!’라는 평문(plain text)을 암호화 해서 보내고 싶다고 해봅시다. 그리고 Bob과 Alice는 암호화에 쓰인 비밀키를 서로 공유하고 있습니다. 따라서 Bob은 이 비밀키를 활용하여 평문을 암호화한 후 Alice에게 보냅니다. Alice는 암호화에 사용된 비밀키를 가지고 있기 때문에 이를 평문(‘Hello Alice!’)으로 복호화 할 수 있습니다. 대표적인 대칭키 알고리즘은 AES(Advanced Encryption Standart), DES(Data Encryption Standart) 등이 있습니다.현대의 암호화 기법은 매우 복잡하여 암호문을 보고 평문을 알아내는 것은 사실상 불가능하다고 합니다. 그렇다면 대칭키 암호화 기법은 항상 안전하다고 할 수 있을까요? 그렇지 않습니다. 만일 암호화와 복호화에 사용되는 비밀 자체를 누군가가 탈취하면 암호화를 한 의미가 없어지겠죠. 그러나 모순적으로 대칭키 방식이 정상적으로 이루어지려면 비밀키(key)의 ‘공유’가 선행되어야 합니다. 따라서 이제는 이 비밀키(key)를 어떻게 하면 내밀하게 공유할 수 있을지를 고민해 봐야 하겠습니다.비대칭키비대칭키 암호화 방식우리는 대칭키 암호화 방식을 살펴보면서, 비밀키 그 자체를 어떻게 내밀하게 공유할 수 있을까에 대한 의문을 가지게 되었습니다. 그런데 이렇게 한번 생각 해보면 어떨까요? 같은 비밀키(key)를 공유해서 문제가 발생하는 것이니 서로 다른 두 개 비밀키를 만드는 겁니다. 그래서 하나는 누구에게든 공유하되, 나머지 하나는 비밀키를 만든 사람만 가지고 있는 것이죠. 그리고 공유 받은 키로 암호화한 내용은 무조건 비밀키를 만든 사람만이 가지고 있는 키로만 복호화를 할 수 있는 메커니즘을 설계하는 겁니다. 이를 공개키(public key) 및 개인키(private key) 기반의 비대칭키 암호화 방식이라고 하고 가장 대표적으로 RSA 알고리즘을 들 수 있습니다. 누구에게나 공유할 수 있는 비밀키: 공유키(public key)라고 합니다. 만든 사람만 소유하는 비밀키: 개인키(private key)라고 합니다.비대칭키의 작동 원리상 핵심은 공개키로 암호화 하면 이에 대응하는 개인키로만 복호화되고, 개인키로 암호화 하면 이에 대응되는 공개키로만 복호화가 가능합니다. 즉 서로 양방향으로 암호화 복호화가 가능한데, 어떤 키로 암호화 하느냐에 따라 사용 분야가 다릅니다: 공개키로 암호화: 데이터 보안에 중점을 둡니다. 공개키로 암호화된 데이터는 개인키를 가진 사람만이 복호화를 할 수 있기 때문입니다. 개인키만 공유하지 않는다면 공개키로 암호화된 내용을 중간에서 누군가 탈취하더라도 평문으로 복호화 하는 것이 불가능합니다. 개인키를 공유하지 않기 때문에 대칭키 방식의 단점을 극복할 수 있습니다. 비밀키로 암호화: 사용자 인증(authentication)에 중점을 둡니다. 비밀키로 암호화된 데이터는 공개키를 가진 불특정 다수가 복호화를 할 수 있습니다. 따라서 비밀키로 암호화하는 것은 데이터의 보호 목적이 아닙니다. 개인키는 공유하는 키가 아니기 때문에 원칙적으로는 개인키와 사람은 일대일 대응 관계입니다. 따라서 누군가가 보내온 메시지를 그 사람의 공개키로 복호화에 성공 했다면 이는 세상에 하나뿐인 개인키를 가진 사람이 보내온 메시지이므로 이 사람의 신원을 확인할 수 있습니다. 이를 공인 인증 체계의 바탕이 되는 전자 서명이라고 합니다.비대칭키의 메커니즘을 통해 대칭키 방식의 보안상 문제점을 완벽하게 해결할 수 있습니다.대칭키와 비대칭키의 결합지금까지 대칭키와 비대칭키의 개념을 살펴보았는데, 여기까지만 보면 비대칭키만 사용하면 될 것 같습니다. 대칭키 방식은 너무 구식처럼 보이네요. 그러나 HTTPS 및 SSL/TLS는 대칭키과 비대칭키 방식을 결합해서 사용합니다. 사실 대칭키과 비대칭키는 각각의 장단점이 명확해서 상호 보완적인 관계입니다. 대칭키 방식: 대칭키는 보안에 취약하지만 알고리즘 작동 방식이 단순하여 암호화/복호화 속도가 빠릅니다. 비대칭키 방식: 보안이 강력하지만 알고리즘 작동 방식이 복잡하여 암호화/복호화 속도가 느립니다.그렇다면 이렇게 생각 해보죠. 실제 데이터를 주고 받을 때는 대칭키 방식을 이용하여 암호화/복호화를 하는 겁니다. 데이터를 주고 받는 속도가 느리면 안되니까요. 그러면 서로 간에 키를 공유해야 하기 때문에 보안에 문제가 생기죠. 이때 비대칭키 방식을 적용합니다. 대칭키 자체를 비대칭키 방식으로 암호화 하는 겁니다. 헷갈릴 수 있는데, 대칭키 자체를 암호화/복호화의 대상으로 보고 대칭키에 대한 공개키, 개인키를 만듭니다. 데이터: 대칭키를 이용하여 암호화/복호화 대칭키 자체: 대칭키에 대한 공개키, 개인키를 만들어서 암호화/복호화SSL HandshakeSSL handshake 과정. 이 전에 TCP 3-way handshake가 수행된다.이제 우리는 SSL/TLS 프로토콜을 이용하여 암호화 통신을 수행할 때 필요한 배경 지식을 갖추게 되었습니다. 이제 암호화 통신이 실제로 일어나는 과정을 살펴 볼 시간입니다! 참고로 SSL handshake는 TCP 3-way handshake을 통해 서로간에 연결이 수립된 이후에 진행됩니다. 본 글에서는 TCP 3-way handshake 과정에 대한 설명은 생략 하겠습니다.1. Client Hello 클라이언트(브라우저) 측에서 서버에 SSL 통신을 시작하는 것을 알리는 단계입니다. 다음의 데이터를 서버로 보냅니다: 클라이언트 랜덤 데이터(client random data): 대칭키를 만들기 위해 필요한 재료입니다. 뒤에서 다시 살펴보겠습니다. 클라이언트가 지원하는 TLS 버전 클라이언트가 지원하는 암호화 방식들(chiper suite) 2. Sever Hello 서버(웹사이트)에서 클라이언트에 응답하는 단계입니다. 서버는 다음의 데이터를 클라이언트로 보냅니다: 인증서(SSL certificate): 서버의 신뢰성을 검증 받기 위해 CA에게 발급 받은 인증서를 건냅니다. 인증서에는 서버의 공개키가 포함되어 있습니다. 따라서 서버의 공개키도 클라이언트측에 넘어갑니다. 서버 랜덤 데이터(server random data): 대칭키를 만들기 위해 필요한 재료입니다. 뒤에서 다시 살펴보겠습니다. 서버가 선택한 암호화 방식: client hello 단계에서 전달받은 암호화 방식 중에서 가장 보안 수준이 높은 암호화 방식을 선정합니다. 이를 통해 암호화 방식에 대한 협상을 종료합니다. 3. 인증(Authentication) 클라이언트가 서버의 신뢰성을 검증하는 단계입니다. 다음의 사항을 검증합니다: 인증서를 발급한 CA가 공인된 CA지를 확인하기 위해 브라우저에 내장된 CA 리스트에서 찾아봅니다. 만일 공인된 CA가 발급한 인증서가 아니라면 브라우저에 신뢰 할수 없는 인증서라는 경고 메시지를 띄웁니다. 브라우저에 내장된 CA의 공개키로 인증서의 내용을 복호화 합니다. 그리고 인증서에 적힌 도메인 주소 등의 서버와 관련된 정보를 확인하여 연결을 수립하려는 서버의 진위 여부를 검증합니다. 4. 세션키(session key) 생성 클라이언트는 서버를 신뢰할 수 있게 되었습니다. 이제 데이터를 암호화 하여 주고 받기 위해 세션키를 생성를 합니다. 다음의 과정을 거칩니다: 클라이언트는 클라이언트 랜덤 데이터와 서버 랜덤 데이터를 알고 있습니다. 이 둘을 조합하여 pre master secret이라는 비밀키를 생성합니다. 그리고 이를 서버측에 공유해야 합니다. 이때 드디어 인증서에 포함된 서버의 공개키를 활용합니다. 서버의 공개키로 pre master secret을 암호화 하여 서버에 전달합니다. 서버는 개인키로 암호화된 pre master secret을 복호화 합니다. 이제 클라이언트와 서버는 client random data, sever random data, pre master secret를 모두 공유하고 있는 상태입니다. 각자는 이 세가지 데이터를 조합하여 master secret이라는 키를 만들고 이를 통해 최종적으로 session key를 생성합니다. 이 session key는 서로 동일하게 가지고 있는 대칭키입니다. 5. SSL Handshake 종료 서버와 클라이언트가 SSL handshake가 종료 되었음을 서로에게 알립니다.6. session key를 이용한 통신 4단계에서 만들어진 session key를 통해 서로간에 데이터를 주고 받을 때 암호화 및 복호화를 수행합니다. session key는 대칭키이므로 암호화 및 복호화 두가지 모두 수행할 수 있습니다.최종 한장 정리지금까지 정말 많은 내용을 학습 했습니다. 대칭키, 비대칭키(공개키, 개인키), 인증기관(CA), 인증서, SSL/TLS Handshake 등이요. 그리고 이러한 구성요소들위에서 HTTP 통신을 하는 것이 결국 HTTPS를 의미하는 것임을 알 수 있었습니다.이 과정을 한눈에 알기 쉽게 정리해주신 자료(미닉스 김인성님 블로그)가 있어서 가져와 보았습니다.SSL 한장에 정리!References What is SSL? - SSL definition What is an SSL certificate? What is a session key? - Session keys and TLS handshakes How does SSL work? - SSL certificates and TLS How does public key encryption work? - Public key cryptography and SSL What happens in a TLS handshake? - SSL handshake 위키백과 - HTTPS 위키백과 - RSA 암호 정보 통신 기술 용어 해설 - SSL/TLS 대칭키 암호 알고리즘 공개키, 비공개 키 원리 웹툰 SSL이란 무엇인가 1/2 웹툰 SSL이란 무엇인가 2/2 HTTPS 통신과정 쉽게 이해하기 #1(HTTPS)의 개요 HTTPS 통신과정 쉽게 이해하기 #2(Key가 있어야 문을 열 수 있다) HTTPS 통신과정 쉽게 이해하기 #3(SSL Handshake, 협상) HTTPS 통신과정 쉽게 이해하기 #4(Cipher Suite, 암호문의 집합) HTTPS 통신과정 쉽게 이해하기 #5(CA, 인증기관)" }, { "title": "AkNN 시리즈 1 - 서론", "url": "/posts/aknn_series_1/", "categories": "CS, AkNN", "tags": "aknn, vector search, quantization", "date": "2022-05-22 16:21:00 +0900", "snippet": "일반적으로 추천 알고리즘을 서빙하는 과정을 매우 단순화 하여 표현하면 다음과 같습니다. 데이터를 모아서 추천 알고리즘을 학습 시킵니다. 추천 알고리즘에 어떤 오브젝트(유저, 아이템 등)의 정보를 인풋하여 각 오브젝트의 벡터값을 찾습니다. 벡터값들의 유사도를 비교하여 가장 가까운 \\(k\\)개의 오브젝트를 찾고, 이를 추천 결과로 내보냅니다.벡터들간의 유사도를 효율적으로 계산하여 최종 추천 결과를 뽑아내는 과정이 중요하다는 것을 알 수 있습니다. 따라서 이번 AkNN 시리즈 글에서는 벡터간의 유사도를 빠르게 비교하는 방안에 대한 연구 방향을 개략적으로 정리합니다. 특히 다음 글부터는 quantization과 관련된 내용을 심화로 다룰 예정입니다. 저도 공부를 하며 정리하고 있기 때문에 잘못된 부분이 있을 수도 있습니다. 지적 부탁드리고, 이 주제에 관심 있으신 분들은 함께 시작해 보시죠! 👋Vector Search란? vector search는 데이터가 임베딩된 벡터 공간 상에서 질의(query) 벡터와 가장 가까운 \\(k\\)의 벡터를 찾는 행위를 말합니다.우리는 살아가면서 정말 많은 ‘검색’ 행위를 합니다. 일반적인 회사원 분들이라면 네이버나 구글에서 맛집을 검색하거나 엑셀 단축키 등을 검색하실 것이구요. 개발자 분들께서는 원하는 데이터를 찾기 위해 사내 데이터 베이스에 수많은 검색을 하실 겁니다. 그리고 대부분의 검색은 그 의도가 매우 명확할 겁니다. 예를 들어서 “최근 한달동안 가장 많이 팔린 제품의 개수는?” 또는 “저번 달에 신규 가입한 유저들 중 이번 달에 잔존한 비율은?” 등을 들 수 있겠네요.그러나 “에어팟과 가장 유사한 제품 3개를 찾아줘”라는 질의는 어떤가요? 위에서 언급한 질의보다는 모호한 것은 사실입니다. 그러나 우리는 일상 생활에서 이러한 표현을 많이 사용합니다. 그리고 사람은 그 문장이 내포하는 의미를 자연스럽게 해석하고, 이에 대한 해답을 제시 할 수 있습니다. 예를 들어 맥북, 아이패드, 애플워치를 들 수 있겠네요.그렇다면 어떻게 컴퓨터는 추상적인 질문에 적절한 답을 줄 수 있을까요? 이를 위해서 머신러닝 기술이 활용됩니다. 특히 RNN, CNN, BERT 등 유명한 알고리즘들은 어떻게 데이터를 벡터로 잘 표현할 수 있을까에 대한 뉴럴넷 기반의 대안이라고 할 수 있습니다. 좋은 알고리즘은 데이터의 추상적이고 내재적인 의미를 잘 임베딩 벡터로 표현할 수 있습니다.이렇게 벡터 공간에 하나의 점으로 임베딩된 데이터들은 유사한 의미를 가진 데이터일수록 서로 가까운 위치에 존재하게 되고, 이질적인 의미를 가질 수록 서로 멀리 위치하게 됩니다. 특히 데이터를 벡터로 표현하면 여러가지 거리 또는 유사도 함수를 사용하여 벡터들 간의 유사도를 대수적으로 계산할 수 있게 됩니다.특히 서두에서 언급한 벡터간의 유사도를 비교하여 가장 가까운 벡터를 찾는 행위, 즉 vector search는 추천 시스템을 구성하는 핵심 컴포넌트라고 할 수 있습니다. 좀 더 강하게 말하면, 추천 알고리즘의 성능은 위와 같은 질문에 적절한 벡터를 얼마나 정확하고 빠르게 제공할 수 있느냐에 달려 있다고 할 수 있습니다.vector search는 생각보다 어렵다vector search는 특정 distance/similarity 함수에 따라서 질의(query) 벡터와 가장 가까운 \\(k\\) 개의 벡터를 찾는 행위입니다. 그런데 vector search가 말 처럼 쉽지는 않습니다. 100만 개의 벡터에서 질의 벡터와 가장 가까운 10개의 벡터를 찾는다고 해봅시다. 가장 가까운 벡터를 찾기 위해서는 어쩔 수 없이 질의 벡터와 나머지 100만 개의 벡터와의 distance/similarity를 구해야 합니다. 모든 벡터에 대해 비교를 해봐야 가장 가까운 벡터를 찾을 수 있으니까요. 만일 이 행위가 0.1초가 소요 된다고 해봅시다. 0.1초 자체만 보면 엄청 짧은 시간이죠.그러나 100만개 모두에 대해 가장 유사한 10개의 벡터를 찾는다고 해봅시다. 단순히 산술적으로 계산하면 100,000초가 소요됩니다. 이를 시간으로 환산하면 무려 27시간입니다. 보통 추천 시스템을 운용할 때는 특정 주기마다 추천으로 나갈 제품 셋을 미리 연산해 놓고 데이터 베이스에 쌓아 놓는 방식을 많이 활용합니다. 만약 배치 주기가 24시간(하루)이라면… 27시간이나 소요되는 연산은 도저히 운용이 불가능합니다.vector search를 실무에서 활용할 수 있으려면 어떤 방법론을 고민해보아야 할까요? 검색 속도를 빠르게 할 수 있다면 검색의 정확도를 조금 희생해도 괜찮지 않을까요? 물론 그 정확도의 희생은 용인 가능한 수준이어야 하겠지만요. 이러한 관점에서 탄생한 알고리즘을 통칭 AkNN(Approximate k Neareast Neighbor)이라고 합니다.Approximate K Neareast Neighbor(AkNN)AkNN 알고리즘을 다시 정의해봅시다. AkNN은 정확도는 손해를 보더라도 빠르게 vector search를 할 수 있는 알고리즘을 통칭합니다. 요즘 빅데이터 시대라고 하죠. 제가 몸 담고 있는 현업에서도 제품수가 200만개를 훌쩍 뛰어 넘습니다. 회사가 성숙할수록 데이터는 계속해서 증가할 것으므로 reasonable 시간 안에서 유사한 데이터를 발견하는 일은 점점 더 중요해질 것입니다.AkNN 알고리즘의 연구 방향은 크게 2가지로 나눌 수 있습니다: Vector Encoding Tree LSH(Locality Sensitive Hashing) Quantization None Exhaustive Search Component: 완전 탐색을 피하기 위한 방법 Inverted Files HNSW(Hierarchical Navigable Small World Graphs) AkNN과 관련된 내용을 모두 다루면 좋으나… 시간의 한계로 그럴 수는 없겠습니다. 따라서 이번 시리즈 글에서는 FAISS나 ScaNN과 같은 유명한 AkNN 오픈 소스 패키지에서 반드시 언급되는 quantization 기법 중 VQ(Vector Quantization)와 PQ(Product Quantization)을 자세히 다루고자합니다. 참고로 quantization 기법은 이렇게 다양합니다. 관심 있으신 분은 아래의 키워드를 참고해서 학습해보세요! Vector quantization Product quantization Binary quantization Additive quantization Tenary quantization Learing quantizationReference What is Similarity Search? Facebook AI Similarity Search (Faiss): The Missing Manual Comprehensive Guide To Approximate Nearest Neighbors Algorithms" }, { "title": "2021년 회고", "url": "/posts/2021_retrospective/", "categories": "ETC, Retrospective", "tags": "retrospective", "date": "2022-01-01 17:30:00 +0900", "snippet": "올 한해를 간략히 정리해 보면…2021년 한해도 정말 금방 가버렸습니다. 올해를 간단히 돌아보면, 연초에는 엔지니어링을 담당하시던 팀원이 퇴사하면서 ML 학습과 배포 파이프라인을 유지보수하는 업무를 새로 맡게 되었습니다. 정말 이상하게도 팀원분이 퇴사하신 이후에 파이프라인이 고장나거나 문제점이 보이기 시작하더라구요. 그래서 올해는 ML 모델을 어떻게 잘 배포 할지, API 서버는 어떻게 관리할지, 컨테이너를 어떻게 관리할지 등을 고민하고 업무에 적용해 보았습니다.그리고 팀원이 두 명이나 퇴사하게 되면서 기존 작업들을 유지보수하거나 새로운 프로젝트를 진행하기가 버거워졌습니다. 따라서 신규 직원을 새로 채용 하였습니다. 팀내에 연차가 높으신 분이 계시지 않아서 팀원들끼리 똘똘 뭉쳐서 직무 기술서도 새로 작성하고, 직접 면접관으로서 면접에 참여해보는 귀중한 경험도 하게 되었습니다.마지막으로 연말에는 성장이 정체 되어가고 있다는 느낌과 더 좋은 환경에서 일을 해보고 싶은 마음이 커져서 이직 준비를 하게 되었고 최종적으로 B2C 커머스 회사로 이직을 확정 짓게 되었습니다. 이직 준비를 하는데 많은 도움을 주신 회사 동료분들과 묵묵하게 응원해준 가족들에게도 감사인사를 드리니다.스스로에 대한 당근과 채찍2021년은 담당 업무가 급격하게 전환되었던 시기였습니다. 2020년은 추천 시스템 모델링을 주로 담당 했었다면, 2021년은 추천 모델을 어떻게 잘 배포하고 관리할지에 대한 아키텍처를 구상하고 이를 구현하는 업무를 주로 담당했습니다. 급격하게 업무가 전환되면서 새로 배워야하는 지식이 늘어났습니다. 도커, 네트워크, AWS 등을 공부해야 했습니다.칭찬할 점 DS에 필요한 이론을 공부하겠다는 목표를 이룸 2020년 회고글에서 선형대수 이론을 공부하고 보완하겠다고 다짐 했었음 글또 5기 활동을 하며 PCA, 고유값 분해, 고유값과 고유벡터 등 선형 대수 이론을 보완함 특히 이를 언제든 참고할 수 있도록 글로 열심히 정리하였음 회사에서 담당해야할 업무가 급격하게 변했지만, 나름대로 잘 적응함 모델 학습, 배포, API 관리 등의 MLOps와 관련된 부분을 담당함 기존의 업무와 많이 달라졌지만 나름대로 리서치를 성실히 해서 개인적으로는 괜찮은 수준의 아키텍처를 구축했다고 생각함 MLOps Engineer 또는 ML Engineer로 커리어를 발전시키기로 정함 데이터 분석, 모델링, MLOps 등 DS와 관련된 모든 파트를 잘 하고 싶다는 생각을 가짐 그러나 현실적으로 현재 연차에서 모든 파트를 잘하기는 힘들다고 판단 DS 분야에 처음 입문 했을 때 가슴 뛰었던 일, 현재 회사에서 가장 재밌게 했던 일, 현재의 주된 관심사를 종합적으로 고려해보았을 때 MLOps 쪽 업무를 가장 하고 싶다고 결론 내림 보완할 점 MLOps 쪽으로 커리어를 발전 시키기 위해서 이론 공부 필요 운영체제, 네트워크, 자료구조, 알고리즘 도커, 쿠버네티스 파이썬 대용량 트래픽을 다루는 방법에 대한 고민 아직까지 대용량 트래픽을 처리하는 아키텍처를 다뤄보진 못했음 이직하는 회사는 현재 회사보다 대용량의 트래픽을 다루게 되기 때문에 이에 대한 학습이 필요 끝으로…올해도 코로나가 잠잠해지지는 못했네요. 그렇지만 성장을 위한 공부를 게을리 할 수 없겠죠. 2022년도 2021년 만큼 열심히 정진해보겠습니다. 새로운 회사에서 맡게될 역할이 기대가 되는 2022년입니다. 이 글을 보시는 모든 분들 2022년도 힘냅시다!" }, { "title": "2년차 데이터사이언티스트의 이직 도전기", "url": "/posts/challenge_for_chaning_job/", "categories": "ETC, Jobs", "tags": "jobs", "date": "2021-11-14 16:50:00 +0900", "snippet": "2년차 데이터사이언티스트로서 이직을 준비하고 있습니다. 유용우님의 개발자 이직 대탐험이라는 글을 보고 저도 이직 도전기의 과정을 글로 남기고 싶었습니다. 과연 결과는 어떻게 되었을까요?이직 지원 당시 상황2019년 3월에 현재 회사에 데이터사이언티스트 포지션으로 입사하였습니다. 이직 시도 당시에는 햇수로 치면 2년차(정확히는 1년 9개월) 였습니다. 이직을 결심하게 된 계기는 회사의 재정난 등의 외부적인 요인은 아니었고, 우물안 개구리라는 생각이 많이 들어서 더 넓은 세상으로 나가고 싶다는 마음이 커지고 있던 시점이었습니다. 퇴사를 하진 않았고, 회사 업무를 진행하면서 틈틈이 이직 준비를 했습니다.원하는 회사약 2여년간 데이터사이언티스트로서 일하면서 ML에서 특히 제가 좋아하는 직무가 무엇이고 어떤 도메인에서 일하고 싶은지, 같이 일 하는 동료는 어땠으면 좋은지에 대한 원칙이 세워졌습니다. 추천 ML 업무가 가능한 회사를 위주로 알아보았습니다 모델 개발부터 서빙까지 할 수 있었으면 좋겠습니다. ML 엔지니어로서 업무를 할 때 가장 즐거웠기 때문입니다. 이커머스 도메인에 있는 회사였으면 좋겠습니다. 성장하고 있는 단계의 회사였으면 좋겠습니다. 클라우드(AWS, GCP, …)에서 서비스가 이루어지는 회사였으면 좋겠습니다. 데이터에 기반하여 의사결정하고, 데이터에 기반한 실험이 당연하다고 생각하는 문화가 있었으면 좋겠습니다. 업무를 배울 수 있는 시니어 분들이 있었으면 좋겠습니다. 인생에 한번쯤은 능력자들 사이에서 치여보고 싶습니다 !! 이 모든게 충족된다면 스타트업도 상관 없습니다.지원 회사위에서 제가 세운 원칙에 따라서 하루 날잡고 원티드에서 새로고침이 안될 때까지 스크롤을 내려서 여러 회사들을 살펴보았습니다. 지원 해보고 싶은 공고를 북마크 해두었는데, 거의 40개 정도(😛)의 공고에 북마크를 눌렀더라구요.A사(1차 면접 합격) 서류 지원 원티드에서 이력서 작성 후 지원 지원 하루만에 코딩테스트 진행 여부를 확인하는 문자를 주심 코딩 테스트 진행 의사 전달 코딩 테스트 총 4문제, 120분 전체적인 난이도는 쉬웠음. 경력직 코테라서 그런지 기본적인 컴퓨팅 사고가 가능한지 확인한지 여부 정도만 확인 하는 듯함 코딩 테스트를 통과하고 1차 면접 진행 1차 면접 대면면접 이었습니다. 면접은 무난하게 진행되었음. 추천에 이제 막 관심을 가지고 있는 상황이라 그런지 추천 모델링과 관련해서 궁금한 점들을 질문을 주셨음. 딱히 압박 면접은 없었고 편안한 분위기에서 웃으면서 진행 회사와 관련된 여러가지 수치 정보를 제공해 주셨는데, 성장하고 있는 회사란 것을 알 수 있었음 2차 면접 2차 면접날 당일 점심쯤… 충격적인 소식을 듣게 됩니다. 갑자기 회의를 통해서 데이터 사이언스 포지션 채용 계획을 전면 취소한다는… 매우 당황스러웠습니다… 할말하않… 좋았던 점 라운지에서 대기중에 현업에 계신 분들이 어떻게 일을 하고 계신지 곁눈질로 보았는데, 상당히 활기차게 의견을 나누는 것을 보고 인상 깊었음 특히 회의 내용을 어쩌다보니 엿듣게 되었는데, 실험과 관련된 이야기를 하고 계셔서 상당히 첫인상이 좋았음 추천 서비스를 배포할 때 반드시 실험 기반으로 진행된다는 것이 좋았음 아쉬웠던 점 면접이 저에 대한 질문 보다는 회사 설명 및 회사의 내부적인 상황에 대한 질문 위주로 진행되어서 저를 점검하기에 부족해 보였음 데이터 사이언스 포지션을 이제 막 채용하고 있는 상황이었고, 2~3년차 보다는 5년차 이상의 미들급 인재를 채용을 원하는 듯 해보였음. 딱 하나, ML 쪽 시니어가 없다는 것이 마음에 걸렸음. 만약 입사하게 된다면 기술 스택부터 밑바닥부터 정해야하는 상황임. 채용 절차가 갑자기 중단된다는 것은 너무 어처구니 없었습니다. B사(최종 합격) 서류 지원 팀원이 괜찮은 회사인 것 같다고 추천해주어서 지원을 하게 되었습니다. 원티드 양식으로 서류를 넣고 2일 뒤 1차 면접 날짜가 잡혔습니다. 1차 면접 화상 면접으로 진행되었습니다. 이력서 기반의 질문이었는데, 이론적 내용보다는 서비스 운용 및 협업 경험을 많이 물어보셨습니다. 프로젝트의 내용과 관련 이론 내용을 공부했던 터라 조금 당황은 했지만 어쨌든 실제 사례를 녹여내서 최대한 답변을 했습니다. 생각보다 질문이 날카롭게 들어와서 조금 당황했지만 웃으면서 끝났고 분위기는 좋았다고 생각합니다. 1차 합격을 어느 정도 예상 했습니다. 2차 면접 대면 면접으로 진행되었습니다. 서로가 하고 싶은 것과 이쪽에서 하고 싶은 일에 대해서 허심탄회하게 이야기를 나누었고, 방향이 잘 맞을 수 있겠다는 생각이 들었습니다. 좋았던 점 인사팀에서 지원자를 최대한 배려하는 모습이 느껴졌습니다. 화상 면접 10분전에 스피커나 음성 상태를 체크해주시고 면접 진행 내용이나 앞으로의 일정을 잘 알려주셨습니다. 면접 날짜도 최대한 지원자에 맞춰서 선택할 수 있게 도와주셨습니다. 면접 질문이 생각 외로 날카로웠고, 질문 내용을 미루어 보았을 때 제가 관심이 가는 분야의 일을 맡아서 할 수 있을 것 같았습니다. 현재 회사와 비슷한 도메인에 있는 회사고, 현재 급속하게 성장하는 회사인 것이 매력적이었습니다. 복지 혜택이 너무 좋았습니다. 아쉬웠던 점 아직까지 ML 쪽 시니어가 많이 없어 보였습니다. 하지만 ML 쪽 시니어는 시장에서 너무 귀하니… 큰 문제가 되진 않을 것 같았습니다. 합격하게 된다면 무지하게 고생할게 눈에 보였습니다. C사(1차 면접 합격) 서류 지원 해당 회사의 홈페이지에 원티드 양식으로 PDF 파일을 제출했습니다. 서류 제출 후 약 2일 뒤에 서류 합격 통보를 받았습니다. 1차 면접 화상 면접으로 약 30분간 진행되었습니다. 추천 모델과 모델 파이프라인과 관련된 내용에 꼬리에 꼬리를 무는 질문이 계속이어졌습니다. 평소에 고민을 해봤던 문제들이라서 나름 열심히 제 생각을 답변 했습니다. 2차 면접 상당히 강한 질문이 많이 들어왔습니다. 모델링을 하는 과정에서 병목 현상을 어떻게 해결 하였는지, 현재 C사가 겪고 있는 특수한 상황하에서 어떻게 추천을 줄 수 있을지 등… 전혀 예상하지 못한 질문이 많이 들어왔습니다. 최대한 아는 만큼 답변을 하였으나 만족스러워 하시진 않는 듯 하였고, 면접 후반부로 가서는 저도 너무 힘들어서 점점 질 좋은 답변을 못 하였습니다. 예상 대로 2차 면접에서 탈락 하였습니다. 좋았던 점 매우 성장하는 회사고, 훌륭하신 분들이 많이 재직중이라는 것을 알고 있어서 매력적이었습니다. 질문 수준이 엄청 날카로운 것으로 보아서 재직하시는 분들의 실력이 정말 대단할 것이라는 생각이 들었습니다. 아쉬운 점 채용 절차상 아쉬운 점은 없었습니다. 질문이 회사에서 겪고 있는 특수한 상황에 입각한 것이라서 이쪽 도메인을 겪어 보지 않았으면 누구든 쉽게 대답하긴 힘들었을 것 같습니다. 다만 제가 많이 부족했다는 점이 팩트이고, 좀더 이론을 탄탄하게 다지고 다양한 실무 경험이 필요한 것 같다는 생각이 들었습니다. 최종 결정!최종 합격을 받은 B사로 입사를 결정하게 되었습니다. 생애 처음으로 이직 준비를 하였고, 그 과정에서 정말 많은 준비를 했습니다. 이력서도 거의 10번 넘게 수정 하였고, 내가 가진 이력서가 시장에서 좋은 반응이 올지에 대한 확신이 전혀 없어서 불안 했던 것도 사실입니다. 그런데 돌이켜 보면 결국엔 자신감 있게 지르는 것이 가장 현명한 선택이었습니다. 어짜피 저 혼자 고민해 봤자 달라지는 것은 없고 그냥 부딪혀 보는게 제일 좋은 방법이었다고 생각합니다. 특히 서류가 떨어지면 마음은 아프지만 이력서의 어느 포인트가 마음에 안 들었을지 계속 고민하고, 면접 기회가 주어지면 성실하게 준비하고 면접 때 제대로 대답하지 못했던 질문은 바로바로 정리하곤 하였습니다.이직 준비 과정에서이력서를 주변 동료들에게 보여주고 솔직한 피드백을 요청 하였던 것이 도움이 많이 되었습니다. 동료들이 아쉬운 부분도 지적해주고, 때로는 응원도 해주시니 점점 자신감이 생겼습니다. 이 글을 보시는 처음으로 이직 준비를 하시는 분이라면 주변에 신뢰할만한 동료들에게 이력서를 보여주고 솔직한 피드백을 요청하시면 엄청 도움이 될 것 이라고 생각합니다.또 많이 도움되었던 일은 프로젝트별로 ‘무엇을’, ‘왜’, ‘어떻게’, ‘그래서’를 꼭지로 하여 문서로 정리하고 이를 반복 숙달 했던 일입니다. 이 프로젝트는 무슨 비즈니스 문제를 해결하기 위한 프로젝트이며(프로젝트의 목적 등), 왜 그 문제를 해결하는 해야만 했는지(기존 알고리즘에 어떤 문제점이 있었는지 등), 어떤 방법론을 적용 해서 해결 했는지(비교한 방법론, 방법론별 장단점 등), 그래서 결과는 어떻게 되었는지(성과, 실패 경험, 트러블 슈팅 사례 등)를 정리하는 것입니다. 이를 통해 면접장에서 질문에 답변을 할 때 좀 더 구조화된 틀에서 답변을 할 수 있었던 것 같습니다. 정리하는데 시간은 오래 걸리지만 개인적으로 큰 효과를 본 방법이므로 꼭 실천 해보시기를 권해드립니다." }, { "title": "오픈 소스 패키지 분석을 위한 __init__.py 알아보기", "url": "/posts/python_package_init/", "categories": "Python, Basic", "tags": "python, packages, module, init", "date": "2021-10-31 17:09:00 +0900", "snippet": "오픈 소스 툴을 사내에 도입하기 위해 분석하던 중에 알게된 파이썬의 __init__.py 파일을 역할을 정리합니다. 먼저 왜 __init__.py의 역할과 기능을 정리하게 되었는지를 말씀드리고, 이를 이해하기 위한 배경지식을 말씀드리겠습니다. 그리고 __init__.py의 다양한 역할에 대해 정리합니다. 마지막으로 여러분들께 친숙한 pandas 패키지를 기준으로 __init__.py의 기능을 정리하겠습니다.서론없네…?오픈 소스 패키지의 소스 코드를 분석해보신 경험이 있으신가요? 혹시 없으시다면, 최소한 pd.DataFrame() 이라는 메서드는 써보신 적이 있을 것이라고 생각합니다. 저 역시도 정말 많이 사용 하는 메서드인데요. 저 코드가 어떻게 오류 없이 실행되는지 궁금해졌습니다. pandas를 설치하고, 설치된 경로를 따라가면 pandas의 패키지의 구조를 볼 수 있습니다.그런데 정말 신기합니다. pd.DataFrame() 이라는 함수가 정상적으로 동작하려면 루트 디렉터리에 최소한 DataFrame.py 같은 모듈 파일이 있어야 하는데, 눈을 씻고 찾아봐도 그런 파일은 찾아볼 수 없습니다. 어떻게 pd.DataFrame() 이라는 코드가 오류 없이 작동하는 걸까요? 다음의 코드에서 힌트를 찾을 수 있습니다.&amp;gt;&amp;gt;&amp;gt; import pandas as pd&amp;gt;&amp;gt;&amp;gt; print(pd.DataFrame)pandas.core.frame.DataFramepandas/core/frame.py 파일에 DataFrame이라는 객체가 존재한다고 하네요. 그리고 실제로 해당 파일의 내용을 보면 아래와 같이 DataFrame 클래스를 찾을 수 있습니다.# pandas/core/frame.pyclass DataFrame(NDFrame): def __init__( self, data=None, index: Optional[Axes] = None, columns: Optional[Axes] = None, dtype: Optional[Dtype] = None, copy: bool = False, ):그렇다면 pd.core.frame.DataFrame는 우리가 자주 쓰는 pd.DataFrame 와 같은 의미일까요? 맞습니다. pd.DataFrame과 pd.core.frame.DataFrame은 완벽하게 같은 클래스를 가르킵니다.&amp;gt;&amp;gt;&amp;gt; print(pd.DataFrame)pandas.core.frame.DataFrame&amp;gt;&amp;gt;&amp;gt; print(pd.core.frame.DataFrame)pandas.core.frame.DataFrame마치 pandas 패키지 제작자들께서 정~말 자주 쓸 것 같은 pd.DataFrame 클래스를 쉽게 사용하라고 배려해주신 것 같은 느낌이 들어서 참 감사합니다. 하지만 궁금해집니다. 이게 어떻게 가능하지? 그 비밀은 __init__.py 모듈에 있었습니다. 지금부터 그 비밀을 같이 파헤쳐 보시죠!배경지식모듈(module) An object that serves as an organizational unit of Python code. Modules have a namespace containing arbitrary Python objects. Modules are loaded into Python by the process of importing.모듈이란 간단히 말해서 다른 파이썬 스크립트에서 import 하는 .py 파일입니다. caller1에서 모듈을 임포트하면 해당 모듈 파일이 실행 되면서 해당 모듈 내부의 object(함수, 클래스, 변수 등)가 모듈의 네임스페이스에 할당됩니다.물론 모듈 임포트를 어떻게 하냐에 따라서 caller의 네임스페이스에 할당될 수도 있습니다. 네임스페이스에 관련해서는 밑에서 더 자세히 다루겠습니다.패키지(package) A Python module which can contain submodules or recursively, subpackages. Technically, a package is a Python module with an __path__ attribute.패키지란 여러 모듈들이나 패키지들을 모아 놓은 디렉터리를 말합니다. 디렉터리를 파이썬의 패키지로 인식시키려면 디렉터리 내부에 패키지를 초기화하는 __init__.py 파일이 필요합니다 (파이썬 3.3 이후 버전부터는 __init__.py 파일이 없어도 자동으로 패키지로 인식하도록 바뀌었습니다).앞서 언급하였지만 패키지는 모듈뿐만 아니라 또 다른 패키지를 포함할 수 있습니다. 패키지를 도입함으로써 프로젝트에서 여러가지 모듈을 계층화 시켜서 관리할 수 있는 이점을 얻을 수 있습니다.특히 패키지를 이야기 할 때 __init__.py을 언급하지 않을 수 없는데요. __init__.py 파일은 생각보다 다양한 기능이 있습니다. 또한 여러분들이 아시는 대부분의 오프 소스 패키지를 분석할 때 헷갈리는 부분이 바로 이 __init__.py 내부의 코드 때문에 발생합니다. 따라서 __init__.py은 밑에서 더 자세히 다루도록 하겠습니다.네임스페이스(namespace) The place where a variable is stored. Namespaces support modularity by preventing naming conflicts. Namespaces also aid readability and maintainability by making it clear which module implements a function.네임스페이스란 프로그래밍 언어에서 이름(name)에 따라 특정 객체(object)를 구분할 수 있는 범위(scope)를 뜻합니다. 파이썬의 모든 것은 객체입니다. 이 객체를 특정 이름을 가진 범위마다 따로 구분해서 관리하는 것입니다.예를 들어 보죠. 다음과 같이 sub.py 파일에 func() 함수를 선언했습니다.# sub.pydef func(): return &quot;This is func() in sub.py&quot;그리고 main.py 파일에서는 sub.py를 모듈로 임포트하고, 같은 이름을 가진 func() 함수를 선언했습니다.# main.pyimport subdef func(): return &quot;This is func() in main.py&quot;자, 그럼 main.py에서 자기 자신에서 선언한 func()과 sub.py에 선언된 func()를 둘다 사용할 수 있을까요? 가능합니다. 바로 두 함수의 네임스페이스가 다르기 때문이죠.# main.py&amp;gt;&amp;gt;&amp;gt; print(func())This is func() in main.py&amp;gt;&amp;gt;&amp;gt; print(sub.func())This is func() in sub.py먼저, main.py 함수에 선언된 func()는 main.py 모듈의 네임스페이스에 존재하는 함수입니다. 반면에 sub.py에 선언된 func()는 sub.py 모듈의 네임스페이스에 존재합니다. 이처럼 서로 같은 이름을 가진 객체가 서로 다른 네임스페이스에서 관리되므로 변수 이름의 충돌로 발생할 수 있는 문제가 방지되는 효과가 있습니다.python 네임스페이스__init__.py여러 오픈 소스 코드들을 보다보면 디렉터리에 __init__.py 라는 파일을 보신적이 있을실 것입니다. 이 요상한 __init__.py 파일은 패키지가 임포트 될 때 초기화(initialize)되어 실행됩니다. 이것은 파이썬의 내부 메커니즘으로서 패키지를 임포트하면 자동으로 해당 패키지의 __init__.py 파일이 실행됩니다.이렇게 자동으로 초기화 되는 매커니즘으로 인해 여러가지 재미있는 일들이 가능해지는데요. 다음과 같은 일들을 할 수 있습니다. 이에 대해서 살펴보도록 하겠습니다. 파이썬의 디렉터리를 패키지로 인식 from &amp;lt;package_name&amp;gt; import * 구문의 작동 방식 지정 가능 패키지의 네임스페이스에 객체를 할당디렉터리를 패키지로 인식가장 기본적인 기능은 디렉터리를 파이썬의 패키지로 인식시키는 것입니다. 이는 파이썬 모듈의 __name__ 변수와 밀접한 관련이 있는데요. 이와 관련해서는 여기를 참조해주세요. 결론적으로 말씀드리면, 상대 경로 임포트 방식으로 모듈을 import 하려면 모듈의 __name__ 변수에 해당 모듈의 패키지 구조가 정의 되어 있어야 합니다. 그리고 이때 활용되는 __init__.py은 아무런 내용이 없어도 됩니다.다만 파이썬 3.3 이후 버전부터는 __init__.py 파일이 없어도 디렉터리를 패키지로 인식한다고 합니다 (PEP420). 그럼에도 불구하고 이전 버전과의 호환성을 위해서는 웬만하면 __init__.py 파일을 작성해 두는 것이 좋을 것 같습니다.from &amp;lt;package_name&amp;gt; import * 구문의 작동 방식예시를 보면서 설명 해볼게요. 어떤 프로젝트의 구조가 다음과 같습니다..├── main.py└── sub/ ├── __init__.py ├── first.py └── second.py그리고 각각의 모듈은 다음과 같이 구성 되어 있습니다.# main.pyfrom sub import *print(first.first())print(second.second())# sub/__init__.py# sub/first.pydef first(): return &quot;***** first!!! *****&quot; # sub/second.pydef second(): return &quot;***** second!!! *****&quot;이때 main.py 파일을 실행해보면(python main.py) 예상과는 다르게 에러가 출력됩니다. first 모듈을 찾을 수가 없다고 하네요.Traceback (most recent call last): File &quot;main.py&quot;, line 2, in &amp;lt;module&amp;gt; print(first.first())NameError: name &#39;first&#39; is not defined어떻게 된 일이죠? 분명히 패키지의 모든 것을 import 했는데(*) 왜 first 모듈을 찾을 수 없는 걸까요. 비밀은 __init__.py 파일에 있습니다. __init__.py에는 __all__ 이라는 리스트를 선언할 수 있습니다. 그리고 이 __all__ 변수에 담긴 모듈만 임포트됩니다.예를 들어 first 모듈만 임포트 되도록 하려면 다음과 같이 __init__.py 모듈을 수정하면 됩니다.# sub/__init__.py__all__ = [&quot;first&quot;]그리고 나서 main.py를 다시 실행하면(python main.py) 다음과 같이 first 모듈에 있는 함수에는 접근할 수 있지만 second 모듈에 있는 함수에는 접근 할 수 없다는 것을 알 수 있습니다.***** first!! *****Traceback (most recent call last): File &quot;main.py&quot;, line 3, in &amp;lt;module&amp;gt; print(second.second())NameError: name &#39;second&#39; is not defined패키지의 네임스페이스에 객체를 할당오픈 소스 패키지의 구조를 이해하기 위해서는 이 원리를 이해하는 것이 가장 중요합니다. 다음과 같은 프로젝트가 있다고 가정해 봅시다..├── main.py└── sub/ └── __init__.py그리고 각 모듈은 다음과 같이 작성 되어 있습니다.# main.pyimport subprint(sub.sub_value)# sub/__init__.pysub_value = &quot;sub_value&quot;main.py 파일을 실행(python main.py) 하면 어떻게 될까요? “sub_value”라는 값을 정상적으로 출력할 것입니다. 이게 어떻게 가능할까요? main.py 파일을 실행하면 내부적으로 다음의 과정을 거칠 것입니다. main.py에서 sub 패키지를 임포트 한다 sub 패키지를 초기화 하면서 __init__.py을 실행한다. __init__.py 내에 선언된 객체들은 모두 sub 패키지의 네임스페이스에 소속된다.이제 pandas 패키지를 들여다보고 판다스에서 __init__.py를 어떻게 활용하는지를 살펴보겠습니다.pandas에서 __init__과 네임스페이스를 활용하는 방법pandas에서는 __init__.py과 네임스페이스의 개념을 활용하여 자주 사용하는 메서드를 쉽게 접근 하도록 설계되어 있습니다. 서론에서 살펴본 것처럼 아무래도 pd.DataFrame()로 접근하는 것이 pd.core.frame.DataFrame()로 접근 하는 것 보다 훨씬 편하죠. 정말 자주 사용되는 객체이니까요.pandas 패키지의 구조에서 DafaFrame()과 관련된 핵심적인 부분만 따로 보면 다음과 같습니다..├── __init__.py├── core│   ├── __init__.py│   ├── api.py│   ├── frame.py│   └── ...└── ...각 파일의 내용은 다음과 같습니다.# ./__init__.pyfrom pandas.core.api import DataFrame# ./core/__init__.py# ./core/api.pyfrom pandas.core.frame import DataFrame# ./core/frame.pyclass DataFrame(NDFrame): pass이를 바탕으로 우리가 pd.Dataframe() 이라는 메소드를 사용하기 위한 과정을 따져보면 다음과 같을 것입니다. import pandas as pd pandas/__init__.py 파일 실행 pandas/core 패키지의 api 모듈 로드 api 모듈은 pandas/core 패키지의 frame 모듈에서 DataFrame 클래스(객체) 로드 __init__.py는 pandas 패키지에서 초기화 된 것이므로 DataFrame 클래스는 pandas 패키지의 네임스페이스에 소속 pd.DataFrame() 메소드 사용 가능마무리지금까지 파이썬 패키지를 계층화 할때 중요한 역할을 하는 __init__.py 파일의 역할을 알아 보았습니다. 다시 한번 정리하면… 디렉터리를 패키지로 인식하게 함 from &amp;lt;package_name&amp;gt; import * 구문의 작동 방식 결정 패키지의 네임스페이스에 객체를 할당이러한 역할 이해하면 앞으로 오픈 소스 패키지의 구조를 이해하는데 많은 도움이 될 것이라고 믿습니다. 긴글 읽어 주셔서 감사합니다!Reference Python glossary - module Python glossary - package Python glossary - namespace python 3.7 document - Packages Python import: Advanced Techniques and Tips What’s __init__ for me? Python Modules and Packages - Python packages Python Modules and Packages – Package Initialization Python Modules and Packages - Importing * From a Package [파이썬] 내장 함수 dir 사용법 [Python] 네임스페이스 개념 정리Footnote 모듈을 임포트한 .py 파일을 말합니다. 예를 들어 main.py 파일에서 mymodule.py을 임포트 했다면(import mymodule) main.py가 caller입니다. &amp;#8617; " }, { "title": "CS50 - 파이썬이 소스 코드를 실행하는 과정과 원리", "url": "/posts/how_to_work_python/", "categories": "CS, CS50", "tags": "python, compile, interpreter, bytecode, pvm", "date": "2021-10-27 11:50:00 +0900", "snippet": "우리는 앞선 글들에서 컴퓨터는 0과 1, 즉 2진수만 이해할 수 있다는 사실을 알았습니다. 그런데 코딩을 해보신 분들은 당연히 아시겠지만 우리는 0과 1로 코딩을 하고 있지 않습니다. 쉽진 않지만 영어로 이루어진, 그래도 인간이 보고 어느 정도 해석을 할 수 있는 언어(파이썬, C, 자바 등)를 이용해서 코딩을 하고 있죠.컴퓨터는 분명히 0과 1만 이해할 수 있다고 하였는데, 소스 코드를 컴퓨터가 어떤 과정을 통해서 이해하고 실행을 할까요? 제가 주로 사용하는 언어인 파이썬을 통해서 이 과정을 살펴보겠습니다.배경지식흔히 파이썬은 인터프리터 언어라고 표현합니다. 인터프리터 언어가 무엇일까요? 파이썬이나 C 혹은 java로 짠 소스코드를 결국엔 0과 1로 이루어진 코드로 바꾸어야 합니다. 0과 1로 이루어진 코드를 기계어(machine code)라고 합니다.인터프리터 언어는 파이썬 코드 한줄 한줄을 머신 코드로 번역하고 실행합니다. 하지만 다른 언어, 예를 들어 C언어는 소스 코드 전체를 기계어로 변환을 해 놓고, 그 기계어를 cpu가 바로 실행하는 방식을 취합니다. 이러한 언어를 컴파일 언어라고 합니다. 또한 컴파일 언어와 인터프리터 언어를 절충한 하이브리드 언어도 있습니다.각 방식마다 특징 및 장단점이 존재하는데요. 파이썬의 동작 방식을 이해하기 위한 배경지식으로 컴파일 언어, 인터프리터 언어, 하이브리드 언어의 작동 방식을 살펴보겠습니다.컴파일 언어특징컴파일 언어는 소스 코드를 다음의 과정을 거쳐서 기계어로 변환합니다. 만일 다음과 같이 C언어로 작성된 코드(test.c)가 있다고 가정해 봅시다. 컴파일 과정에 따라 어떻게 변화하는지 살펴 보겠습니다.#include &amp;lt;stdio.h&amp;gt;int main(){ printf(&quot;hello world!\\n&quot;); return 0;} precompile: precompile 단계에서는 본격적인 compile에 앞서 사전 준비를 하는 단계입니다. 예를 들어 C언어에서 #include &amp;lt;stdio.h&amp;gt;와 같은 문법은 소스 코드에서 다른 헤더 파일을 참조하라는 의미인데요. 이러한 파일들은 여전히 C 소스 코드 형태이며 stdio.h 파일 내용을 소스코드에 포함 시키는 행위가 이루어집니다. test.c 소스코드는 아래의 명령어를 통해 전처리를 거친 test.i 파일로 변환 할 수 있습니다. gcc -E test.c -o test.i test.i 파일을 확인해 보면 다음과 같습니다. stdio.h에 있던 모든 소스 코드 파일이 test.c 파일에 합쳐져 있습니다. 중요한 점은 전처리 과정이 끝나도 여전히 소스 코드 형태, 즉 고급 언어로 이루어져 있다는 것입니다. typedef signed char __int8_t;...int printf(const char * restrict, ...) __attribute__((__format__ (__printf__, 1, 2)));...int main(){ printf(&quot;hello world!\\n&quot;); return 0;} compile: compile은 소스코드를 기계어로 변환하는 첫 출발점입니다. compile의 결과, 소스 코드는 어셈블리어로 변환됩니다. 어셈블리어란, 고수준 언어와 기계어의 중간에 존재하는 저수준 언어입니다. 어셈블리어는 C와 같은 고수준 언어에 비해 더욱 기계에게 친숙한 언어입니다. 기계어는 cpu가 읽어서 실행할 수 있는 0과 1로 이루어진 명령어의 조합인데요. 이를 사람이 읽고 해석하기가 어렵습니다. 어셈블리어는 기계어를 사람이 좀더 쉽게 읽을 수 있는 기호로 표현한 언어입니다. 어셈블리어의 각 명령문을 instruction이라고 하는데, 기계어와 1:1로 매칭이 되며 CPU 제조사 마다, 사용하는 컴파일러에 따라 instruction이 다릅니다. 아래 명령어로 전처리된 파일을 컴파일 하여 어셈블리어로 작성된 파일을 얻을 수 있습니다. gcc -S test.i -o test.s test.s 파일을 열어 보면 다음과 같이 어셈블리어로 작성되어 있고, 뭔가 명령어(instruction) 형태(pushq, movb, addq 등)로 이루어졌음을 알 수 있습니다. .section __TEXT,__text,regular,pure_instructions .build_version macos, 10, 15, 4 sdk_version 10, 15, 4 .globl _main ## -- Begin function main .p2align 4, 0x90_main: ## @main .cfi_startproc## %bb.0: pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset %rbp, -16 movq %rsp, %rbp .cfi_def_cfa_register %rbp subq $16, %rsp movl $0, -4(%rbp) leaq L_.str(%rip), %rdi movb $0, %al callq _printf xorl %ecx, %ecx movl %eax, -8(%rbp) ## 4-byte Spill movl %ecx, %eax addq $16, %rsp popq %rbp retq .cfi_endproc ## -- End function .section __TEXT,__cstring,cstring_literalsL_.str: ## @.str .asciz &quot;hello world!\\n&quot; .subsections_via_symbols assembling: 어셈블리어를 0과 1로 이루어진 기계어로 변환하는 과정입니다. assembling 과정을 거친 아웃풋을 오브젝트 코드(object code)라고 합니다. 이 과정을 거쳐야만 cpu가 실제로 명령을 수행할 수 있게 됩니다. 만일 컴파일할 소스 코드가 하나라면 컴파일 과정은 여기까지만 진행됩니다. 혹시 컴파일할 코드가 여러개라면 linking 과정이 필요합니다.다음의 명령어로 어셈블리어를 기계어로 변환할 수 있습니다. gcc test.s -o test.o 생성된 test.o 파일을 확인해 보면 사람이 읽을 수 있는 형태가 아님을 확인할 수 있습니다. ^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^ @^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@ ^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^ @^@^@^@UH&amp;lt;89&amp;gt;åH&amp;lt;83&amp;gt;ì^PÇEü^@^@^@^@H&amp;lt;8d&amp;gt;=4^@^@^@°^@è^M^@^@^@1É&amp;lt;89&amp;gt;Eø&amp;lt;89&amp;gt;ÈH&amp;lt;83&amp;gt;Ä^P]Ãÿ%p^P^@^@L&amp;lt;8d&amp;gt;^]q^P^@^@ASÿ%a^@^@ ^@&amp;lt;90&amp;gt;h^@^@^@^@éæÿÿÿhello world! linking: 여러 오브젝트 코드를 합쳐서 실행 가능한 형태의 파일(.exe, .out 등)으로 만드는 과정입니다. 장점 컴파일이 완료되었을 경우 해당 파일을 바로 실행하면 되기 때문에 시간상 효율적입니다. 그리고 컴파일된 파일은 기계어로 이루어져 있기 때문에 실행 속도가 빠릅니다.단점 소스 코드가 수정된다면 다시 컴파일을 해야 한다는 불편함이 있습니다. 플랫폼에 의존적입니다(플랫폼 의존 및 독립의 개념은 부록에 정리해 두었습니다).인터프리터 언어특징인터프리터 언어는 소스 코드를 한번에 컴파일 한 후 처리하지 않습니다. 소스 코드 한줄 한줄을 바로 기계어로 번역한 후 실행시킵니다.장점 소스 코드를 수정해도 수동으로 컴파일을 할 필요가 없기 때문에 개발 속도를 빠르게 가져갈 수 있습니다.단점 한줄 한줄 기계어로 번역하면서 실행하기 때문에, 컴파일 언어에 비해서는 속도가 느립니다. 플랫폼 독립적입니다(플랫폼 의존 및 독립의 개념은 부록에 정리해 두었습니다).하이브리드 언어특징컴파일 방식은 플랫폼에 의존적이지만 미리 컴파일한 기계어를 바로 실행하기에 속도가 빠릅니다. 반명 인터프리터 방식은 플랫폼에 독립적이지만, 한줄 한줄 기계어로 번역하여 실행하기 때문에 속도가 느립니다. 하이브리드 언어는 이 두 가지 방식을 적절하게 혼합한 언어입니다.하이브리드 언어의 큰 특징은 다음과 같습니다. 바이트 코드(byte code): 일종의 중간 단계에 있는 코드입니다. 하이브리드 언어의 컴파일러는 소스코드를 바이트 코드로 변환합니다. 가상 머신(virtual machine): 프로그래밍 환경을 제공하는 일종의 프로그램입니다. 바이트 코드를 한줄 한줄 번역하여 컴퓨터가 실행할 수 있는 머신 코드로 바꾸는 역할을 합니다.하이브리드 언어는 플랫폼 독립적이라는 것이 큰 특징인데요. 바로 위에서 언급한 바이트 코드와 가상 머신이라는 두 가지 요소가 있기 때문이 가능합니다.소스 코드를 바로 기계어로 번역하지 않고 바이트 코드라는 중간 단계 구현물을 사용했기 때문입니다.장점 플랫폼 독립적입니다.단점 여전히 컴파일 언어에 비해서 빠르지는 않습니다. 컴파일 언어처럼 하드웨어를 직접 제어하는 작업은 어렵습니다.파이썬 작동 방식파이썬은 인터프리트 언어로 자주 언급됩니다. 그러나 파이썬은 정확하게는 하이브리드 언어라고 볼 수 있습니다. 다음과 같은 특징이 있기 때문입니다: CPython은 소스 코드를 바이트 코드로 변환하는 표준 인터프리터입니다. CPython과 Cython은 다릅니다! CPython는 컴파일러고 Cython은 언어입니다. CPython이 컴파일 하는 과정이 궁금하신 분들은 여기를 참고해주세요. PVM(Python Virtual Machine)은 바이트 코드를 한줄 한줄 번역하여 프로그램을 실행시킵니다.이와 같은 특징은 위에서 살펴 보았던 하이브리드 언어의 특징과 닮아 있습니다. 혹시 파이썬 코딩을 하시면서 __pycache__ 라는 폴더를 보신적 있나요? 이 폴더에는 .pyc 라는 파일이 생성되는데요. 이 파일이 바로 CPython이 컴파일한 바이트 코드입니다.파이썬의 작동 방식을 조금 더 자세히 나타내면 다음과 같습니다: Step 1: 파이썬 컴파일러가 소스 코드를 읽습니다. 그리고 나서 소스 코드가 잘 작성되었는지를 판단하기 위해 문법 오류 검사를 진행합니다. 만일 문법 오류가 발견되었다면 그 즉시 컴파일 과정을 멈추고 에러 메시지를 출력합니다. Step 2: 만일 에러가 발생하지 않았다면 컴파일러가 소스 코드를 바이트 코드로 변환합니다. Step 3: 마지막으로 바이트 코드는 PVM(Python Virtual Machine)에 보내집니다. PVM은 바이트 코드를 컴퓨터가 실행할 수 있는 기계어로 한줄 한줄 번역합니다. 만일 이 과정에서 에러가 발생하면 모든 것을 멈추고 에러 메시지를 출력합니다.마무리지금까지 컴파일 언어, 인터프리터 언어, 하이브리드 언어의 대한 기초 지식을 배웠습니다. 이를 통해서 파이썬은 하이브리드 언어의 성격을 가지고 있다는 것을 알 수 있었습니다. 파이썬은 단순히 코드를 한줄 한줄 기계어로 번역하지 않습니다. 먼저 컴파일러(CPython이 표준)가 파이썬 스크립트를 바이트 코드(byte code)로 변환합니다. 그리고 나서 PVM(Python Virtual Machine)이라는 일종의 소프트웨어가 바이트 코드를 한줄 한줄 기계어(machine code)로 번역하고 CPU는 이를 실행합니다. 이면에는 더 엄청난 원리가 숨어 있을 것 같지만, 제가 아직 공부가 부족하기도 하고 분량도 너무 길어지므로 본 글은 여기서 줄이도록 하겠습니다.부록: 플랫폼 의존과 플랫폼 독립여러 아티클에서 언어를 설명할 때 플랫폼 의존과 플랫폼 독립이라는 단어를 사용하며 설명하는데, 정확하게 와닿지 않아서 추가적으로 이에 대해 조사해보았습니다.본질적으로 ‘언어’ 자체가 플랫폼 의존, 독립이라는 이야기는 잘못된 개념이라고 합니다. 흔히 C 언어를 플랫폼 의존적인 언어라고 많이 표현합니다. 그러나 C 언어로 코드를 짤 때, OS(윈도우, 맥, 리눅스 등)에 따라 소스 코드 자체를 다르게 짜지는 않습니다.다만 프로그래밍 언어는 필연적으로 컴파일이라는 과정을 거쳐야 하는데, 이 컴파일이라는 과정이 OS kernel과 깊은 관련이 있다보니, OS에 따라 다른 컴파일러를 써야하는 경우가 생깁니다. 또한 컴파일러에 따라서 executable 파일의 형태가 달라지기도 합니다. 예를 들어서 윈도우에서 C 언어로 코드를 짜면 최종 결과물은 .exe 파일인데 반해, 리눅스에서의 최종 결과물은 .out 파일입니다..exe 파일은 리눅스에서 실행할 수 없고, .out 파일은 윈도우에서 실행할 수 없습니다. 이러한 이유로 C 언어는 플랫폼 의존적이라는 말을 많이 하는 것 같습니다. 하지만 정확히는 C 언어의 컴파일러가 플랫폼 의존적이라고 표현하는 것이 맞겠습니다.한편 플랫폼 독립적인 언어로는 자바가 많이 언급됩니다. 자바는 파이썬과 비슷하게 바이트 코드와 가상 머신으로 이루어진 하이브리드 언어입니다. 자바로 코드를 짤 때도 역시나 OS에 따라 코드를 다르게 짜지는 않습니다. 그러나 자바의 바이트 코드인 .class 파일은 JVM이 설치된 컴퓨터면 윈도우, 맥, 리눅스 어디서나 번역 및 실행이 가능합니다. 이런면에서 자바는 플랫폼 독립적이라는 표현을 사용하는 것 같습니다.Reference Why Python is Slow: Looking Under the Hood 프로그래밍 언어와 빌드 과정 [Build Process] 바이트코드와 바이너리 코드의 차이는 무엇일까? 바이트 코드(ByteCode) 개념. How Python runs? How Python works? Peephole: CPython은 어떻게 코드를 최적화하는가 How does Python work? JIT 컴파일 Python programming for the absolute beginner Which language platform dependent and which language platform independent? Is C platform dependent? Why is the C language platform-dependent, and why is Java platform-independent?" }, { "title": "CS50 - 고정 소수점(fixed point)과 부동 소수점(floating point)", "url": "/posts/fixed_point_and_floating_point/", "categories": "CS, CS50", "tags": "fixed point, floating point", "date": "2021-10-20 21:43:00 +0900", "snippet": "최근 사내에서 CS50 스터디를 시작했습니다. 본 포스팅은 CS50의 두번째 주제인 ‘C언어’ 강의를 듣다가 평소 궁금했던 고정 소수점(fixed point)과 부동 소수점(floating point)에 대해 추가적으로 정리하는 목적입니다. 강의 내용과는 크게 관련은 없습니다!본 포스팅에서는 다음의 내용을 다룹니다. 실수를 2진수로 변환하는 방법 고정 소수점(fixed point) 부동 소수점(floating point) 파이썬에서 부동 소수점 마무리실수를 2진수로 변환하는 방법지난 글에서 정수 10진수를 2진수로 변환하는 방법을 알아보았습니다. 하지만 컴퓨터가 정수만 다루는 것은 아닙니다. \\(123.73\\)과 같은 실수도 당연히 다룰 수 있어야겠죠. 하지만 변함 없는 사실은 정수든 실수든 컴퓨터는 0과 1로만 이루어진 2진수만 다룰 수 있습니다. 그렇다면 실수를 2진수로 어떻게 변환해야 할까요?10진수는 10의 거듭제곱의 합으로 표현할 수 있다는 사실은 쉽게 받아들일 수 있습니다.\\[123_{(10)} = 10^2 \\cdot 1 + 10^1 \\cdot 2 + 10^0 \\cdot 3\\]같은 원리로 2진수는 2의 거듭제곱의 합으로 표현할 수 있습니다.\\[101_{(2)} = 2^2 \\cdot 1 + 2^1 \\cdot 0 + 2^0 \\cdot 1\\]\\(N\\)진법 실수도 정확하게 같은 원리로 \\(N\\)의 거듭제곱의 합으로 표현할 수 있습니다. 10진수 실수 123.73을 10의 거듭제곱의 합으로 표현하면:\\[123.73_{(10)} = 10^2 \\cdot 1 + 10^1 \\cdot 2 + 10^0 \\cdot 3 + 10^{-1} \\cdot 7 + 10^{-2} \\cdot 3\\]2진수로 표현된 실수 \\(1.101_{(2)}\\)를 2의 거듭제곱의 합으로 표현하면:\\[11.101_{(2)} = 2^1 \\cdot 1 + 2^0 \\cdot 1 + 2^{-1} \\cdot 1 + 2^{-2} \\cdot 0 + 2^{-3} \\cdot 1\\]그렇다면 10진수 실수를 2진수 실수로 변환하려면 어떻게 해야할까요? 먼저 정수 10진수 13을 2진수로 변환해보겠습니다. 2진수는 2의 거듭제곱의 합으로 표현할 수 있다는 원칙만 계속 가져가면 됩니다.\\[\\begin{align}13_{(10)} &amp;amp;= 2^3 \\cdot 1 + 2^2 \\cdot 1 + 2^1 \\cdot 0 + 2^0 \\cdot 1 \\\\[1em]&amp;amp;=1101_{(2)}\\end{align}\\]이제 10진수 실수 \\(0.75\\)를 2진수 실수로 표현해보겠습니다. 역시나 2진수는 2의 거듭제곱의 합으로 표현할 수 있다는 사실만 기억하면 됩니다.\\[\\begin{align}0.75_{(10)} &amp;amp;= 2^{-1} \\cdot 1 + 2^{-2} \\cdot 1 \\\\[1em]&amp;amp;= 0.11_{(2)}\\end{align}\\]자 그렇다면~ 10진수 0.3을 2진수 실수로 변환하는 문제 하나만 더 풀어 보겠습니다!\\[\\begin{align}0.3_{(10)} &amp;amp;= 2^{-1} \\cdot 0 + 2^{-2} \\cdot 1 + 2^{-3} \\cdot 0 + 2^{-4} \\cdot 0 + 2^{-5} \\cdot 1 + \\cdots \\\\[1em]&amp;amp;=0.0100110011\\cdots_{(2)}\\end{align}\\]소수점 자리 밑에서 \\(0011\\)이 계속 반복됩니다. 정수를 2진수로 변환하는 것은 전혀 어려운 문제가 아니었지만 실수를 2진수로 변환할 때에는 이처럼 무한히 커지는 비트를 처리하는 문제가 대단히 중요할 것 같습니다. 특히 컴퓨터는 하드웨어(특히 메모리)의 저장용량의 한계로 인해 이처럼 무한히 반복되는 수를 저장할 수가 없습니다.그렇다면 컴퓨터가 실수를 잘 처리할 수 있는 방법이 있어야 할 것 같습니다. 먼저 컴퓨터에서 실수를 표현하기 위해 모든 메모리를 다 사용할 수는 없으므로 실수를 표현할 때 사용할 비트의 수를 정해두어야 하겠습니다. 파이썬에서 넘파이를 활용해 보신 분들은 float16, float32, float64와 같은 수 표현 체계를 보신적이 있을겁니다. 이는 넘파이에서 실수(float)을 표현할 때 몇 비트를 사용할 것인지를 사용자가 임의로 정하게 해둔 것입니다. 예를 들어 float32는 실수를 32비트를 활용해 표현합니다. 그리고 당연하게도 더 많은 비트를 쓸 수록 더 큰 실수를 표현할 수 있지만 그만큼 메모리를 비효율적으로 사용할 가능성이 커집니다.앞으로 글의 전개는 실수를 32비트로 표현하는 것을 기준으로 설명드리겠습니다. 컴퓨터가 실수를 다루는 두 가지 방법은 고정 소수점(fixed point)과 부동 소수점(floating point)입니다.고정 소수점(Fixed Point)원리고정 소수점(fixed point)은 정수를 표현하는 비트와 소수를 표현하는 비트수를 미리 정하고(고정) 해당 비트만을 활용하여 실수를 표현합니다. 처음 1비트는 sign(부호)을 나타냅니다. 양수는 0, 음수는 1입니다. 다음 15비트는 integer part(정수부)를 나타냅니다. 다음 16비트는 fractional part(소수부)를 나타냅니다. 그리고 정수부와 소수부의 경계를 소수점의 위치라고 생각하고 2진수로 변환된 수를 그대로 넣으면 됩니다. 마지막으로 남는 자리는 모두 0으로 채우면 됩니다.fixed point, 고정 소수점예를 들어, 10진수 7.625를 32비트 고정 소수점으로 표현해보겠습니다. 먼저 10진수 7.625를 2진수로 표현하면:\\[\\begin{align}7.625_{(10)} &amp;amp;= 2^2 \\cdot 1 + 2^1 \\cdot 1 + 2^0 \\cdot 1 + 2^{-1} \\cdot 1 + 2^{-2} \\cdot 0 + 2^{-3} \\cdot 1 \\\\[1em]&amp;amp;=111.101_{(2)}\\end{align}\\]이를 32비트 고정 소수점으로 표현 해보면:고정 소수점의 장단점고정 소수점 방식은 밑에서 다룰 부동 소수점 방식에 비해서 실수를 표현하는 방법이 단순하고, 속도가 빠르다고 합니다. 그러나 다음과 같은 단점 때문에 부동 소수점에 비해서 잘 쓰이지 않는 방식이라고 합니다. interger part와 fractional part에 사용할 비트가 고정되어 있기 때문에 큰 실수를 표현하기 어렵습니다. integer part는 딱 15개의 비트, fractional part는 딱 16개의 비트만 사용 가능합니다.부동 소수점(Floating Point)원리부동 소수점 표현 방식은 ‘움직이지 않는다’라는 부동(不動)으로 오해하기 쉽습니다. 그러나 여기서 부동은 움직이지 않는다는 뜻이 아니라 떠다닌다, 부유하다의 의미를 가지는 부동(浮動)입니다. 단어에서 유추를 해보면, 소수점이 옮겨다니는 방식의 실수 표현법이라고 이해하면 쉽습니다.부동 소수점 표현 방식은 고정 소수점 표현 방식과 비트를 사용하는 체계가 다릅니다. 그리고 부동 소수점은 이를 표현하는 다양한 체계가 있는데, 일반적으로 가장 널리 쓰이는 표준은 IEEE 754라고 합니다. IEEE 754에 따르면 실수를 다음과 같이 부동 소수점 방식으로 표현할 수 있습니다. 2진수를 정규화(normalize) 합니다. 처음 1비트는 sign(부호)를 나타냅니다 (0은 양수, 1은 음수). 다음 8비트는 exponent(지수부)를 나타냅니다. 정규화 과정에서 얻어낸 지수에 bias를 더한 값으로 채웁니다. 다음 23비트는 mantissa(가수부)를 나타냅니다. 소수 부분의 값으로 채웁니다.floating point, 부동 소수점정규화먼저 컴퓨터 공학에서 말하는 정규화란 2진수를 \\(1.\\)xxx\\(\\cdots \\times 2^n\\) 형태로 나타내는 것입니다. 10진수 \\(7.625\\)을 정규화 해보겠습니다. 먼저 이를 2진수로 변환하면 \\(111.101_{(2)}\\)입니다. 그리고 나서 정규화 하면:\\[1.11101_{(2)} \\cdot 2^2\\]여기서 exponent는 \\(2\\)라는 값을 얻어 냈습니다.Exponent그렇다면 이 \\(2\\)를 바로 exponent 부분에 채우면 될까요? 안타깝게도 그렇지 않습니다. IEEE 754 표준에서는 32비트로 실수를 표현할 때는 \\(127_{(10)}\\)이라는 bias를 더한 값으로 채우라고 명시하고 있습니다. 즉 \\(129(2+127)\\)을 2진수로 변환한 값인 \\(10000001_{(2)}\\)를 채웁니다.왜 bias라는 값을 따로 두었을까요? 그 이유는 지수가 음수일 경우에 대처하기 위함입니다. 예를 들어 \\(0.000101_{(2)}\\)라는 2진수를 정규화 하면 \\(1.01_{(2)} \\times 2^{-4}\\)라는 값을 얻게 됩니다. 위의 예시와 다르게 지수가 음수(\\(-4\\))로 나왔습니다. 그렇다면 지수가 음수인 것을 어떻게 나타내야 할까요?가장 간단한 아이디어는 전체 수가 양수인지 음수인지를 나타내는 sign 값에 1 비트를 할당하는 것과 같은 원리로 지수가 음수인 것을 나타내기 위해 1 비트를 사용하는 것입니다. 그러나 이경우 표현할 수 있는 수의 범위가 작아진다는 아주 큰 단점이 있습니다.따라서 IEEE 754 표준에서는 8 비트로 음수와 양수 모두를 표현하기 위한 하나의 장치로 bias 라는 값을 두었습니다. 이를 통해 exponent 부분은 항상 unsigned(0과 양수) 값만 가지게 셋팅을 하는데요. 8bit는 256개의 숫자를 표현 할 수 있으므로 unsinged 값의 범위는 10진수 0~255가 되겠습니다.127은 0~255 구간의 딱 절반에 해당하는 숫자입니다. 10진수 기준으로 0~127 구간은 음수 (실제 exponent는 -127~0) 128~255 구간은 양수 (실제 exponent는 1~128)참고로 \\(0(00000000_{(2)})\\)과 \\(255(11111111_{(2)})\\)는 각각 0과 무한대 등을 나타내기 위해 특별히 할당된 숫자이기 때문에 앞서 설명드린 정규화 방법이 적용되지 않는다고 합니다.Mantissamantassia는 고정 소수점에서의 fractional part와 같은 역할입니다. 정규화 결과의 소수 부분을 mantassia 자리에 그대로 넣고, 남는 자리는 0으로 채우면 되겠습니다.실제 예시지금까지 정리한 내용을 바탕으로 \\(7.625_{(10)}\\)를 부동 소수점으로 표현해보겠습니다. 2진수 변환: \\(111.101_{(2)}\\) 정규화: \\(1.11101_{(2)} \\times 2^2\\) Exponent: \\(2_{(10)}+127_{(10)}\\)(bias) \\(= 129_{(10)} = 10000001_{(2)}\\) Mantassia: \\(11101_{(2)}\\)부동 소수점의 장단점부동 소수점은 고정 소수점에 비해서 더 큰 실수를 표현할 수 있습니다. 예를 들어 고정 소수점은 정수 부분에 15개의 비트를 사용한다고 말씀드렸는데요. 이는 총 \\(2^{15} =\\)개의 정수를 표현할 수 있다는 것입니다. 생각 보다 큰 숫자라고 생각이 들 수 있습니다.그렇다면 부동 소수점은 총 얼마나 큰 정수를 표현할 수 있을까요? 부동 소수점은 exponent에 8 비트를 사용합니다. 8 비트를 채울 수 있는 가장 큰 숫자는 \\(11111111_{(2)}\\) 이지만, 부동 소수점 표현에서 이는 무한대의 숫자를 나타내는 특별한 수이므로 실질적으로 가장 큰 숫자는 \\(1111110_{(2)}\\)입니다. 이를 10진수로 바꾸면 254입니다. 254에는 bias 127이 더해져 있죠. 따라서 정규화 결과로 가질 수 있는 가장 큰 지수는 \\(127(254-127)\\)입니다. 다시 말해 32비트 부동 소수점에서 가질 수 있는 가장 큰 수의 정규화 결과는 \\(1.\\)xxx\\(\\times 2^{127}\\)와 같은 형태입니다. 정규화 이전의 값을 떠올려 보면 고정 소수점에 비해서 정수 자리에 훨씬 더 많은 비트를 할당할 수 있음을 알 수 있습니다.그렇다면 부동 소수점의 단점은 없을까요? 실수 연산이 부정확할 수 있다는 것이 부동 소수점 표현 방식의 가장 큰 단점입니다. 이는 컴퓨터 하드웨어가 가지는 본질적인 한계점 때문에 완벽하게 극복할 수는 없습니다. 예를 들어 십진수 0.3을 2진수로 변환하면 \\(0.0100110011\\cdots_{(2)}\\) 처럼 특성 수가 무한이 반복됩니다. 따라서 컴퓨터가 실수 부분을 표현할 수 있는 비트수를 다 써버리게 되어 근사치로 표현되는 것입니다.파이썬에서 부동 소수점실제로 제가 주로 사용하는 언어인 파이썬에서도 부동소수점을 활용해서 실수를 표현하고 있는데요. 정말로 실수값이 근사치로 나타나는지 알아보려고 합니다. 먼저 간단하게 0.1을 출력해볼게요&amp;gt;&amp;gt;&amp;gt; print(0.1)0.10.1을 우리가 알던 그 0.1로 잘 표현하고 있는 것처럼 보이는데요…. 과연 그럴까요? 0.1을 소수점 50번째 자리까지 출력해보겠습니다. 예상되는 결과는 \\(0.10000\\cdots000\\)이겠죠?&amp;gt;&amp;gt;&amp;gt; print(&quot;{:.50f}&quot;.format(0.1))0.10000000000000000555111512312578270211815834045410그러나 파이썬에서 말해주는 결과는 달랐습니다. 왜 이런 결과가 나타날까요? 0.1은 \\((1/2)^n\\)의 합으로 딱 맞게 나타낼 수 없기 때문입니다. 우리는 십진수로 숫자를 보고 있지만 컴퓨터는 내부적으로 부동소수점 방식을 이용해 2진수로 실수를 나타내고 있는데, 소수 부분을 \\((1/2)^n\\)의 합으로 딱 맞게 나타낼 수 없습니다. 파이썬에서는 특정 부분에서 반올림을 하여 실수를 출력합니다. 따라서 실제값과 근사값의 오차가 존재하게 되는데 이를 부동 소수점 반올림 오차(rounding error)라고 합니다.그렇다면 실수 부분을 \\((1/2)^n\\)의 합으로 딱 맞게 나타낼 수 있는 수는 우리가 생각하는 값을 도출할까요? 0.625를 소수점 50번째자리까지 출력해겠습니다.&amp;gt;&amp;gt;&amp;gt; print(&quot;{:.50f}&quot;.format(0.625))0.62500000000000000000000000000000000000000000000000\\(0.625 = 2^{-1} \\cdot 1 + 2^{-2} \\cdot 0 + 2^{-3} \\cdot 1\\) 처럼 \\((1/2)^{n}\\)의 합으로 딱 나누어 떨어집니다. 따라서 어느 순간까지만 실수 부분을 2진수로 변환하면 되기 때문에 쓰이는 비트의 수가 딱 정해져 있습니다.이처럼 파이썬에서도 부동소수점으로 실수를 표현하기 때문에 실수를 근사치로 표현한다는 문제점이 여전히 있습니다. 따라서 실수에 대한 비교 연산자를 사용할 때 주의를 기울여야 합니다.&amp;gt;&amp;gt;&amp;gt; print(0.1 + 0.2 == 0.3)False인간은 0.1과 0.2의 합이 0.3과 같다(True)라는 것을 알고 있습니다. 그러나 컴퓨터는 부동 소수점 연산의 근본적인 오차로 False를 출력하고 있습니다. 왜냐하면 컴퓨터는 0.1, 0.2, 0.3을 각각 다음과 같이 근사치로 표현하고 있기 때문입니다.&amp;gt;&amp;gt;&amp;gt; print(&quot;{:.50f}&quot;.format(0.1))0.10000000000000000555111512312578270211815834045410&amp;gt;&amp;gt;&amp;gt; print(&quot;{:.50f}&quot;.format(0.2))0.20000000000000001110223024625156540423631668090820&amp;gt;&amp;gt;&amp;gt; print(&quot;{:.50f}&quot;.format(0.3))0.29999999999999998889776975374843459576368331909180만일 파이썬에서 실수끼리의 비교연산을 정확하게 하고 싶다면 decimal 모듈의 Decimal을 사용하면 됩니다. Decimal은 10진수로 처리하여 정확한 소수점 자리를 나타내도록 합니다.&amp;gt;&amp;gt;&amp;gt; from decimal import Decimal&amp;gt;&amp;gt;&amp;gt; print(Decimal(&#39;0.1&#39;) + Decimal(&#39;0.2&#39;) == Decimal(&#39;0.3&#39;))True마무리지금까지 컴퓨터가 숫자, 특히 실수를 표현하는 방법에 대해 알아보았습니다. 컴퓨터가 실수를 표현하는 가장 대표적인 방법은 고정 소수점(fixed point)과 부동 소수점(floating point)입니다. 고정 소수점은 interger part와 fractional part에 정해진 비트수를 할당하여 실수를 표현하는 방식입니다. 반면 부동 소수점 방식은 exponent의 개념을 도입하여 소수점을 이리저리 옮겨 다닐 수 있습니다. 결과적으로 부동소수점 방식은 고정 소수점 방식에 비해 더 큰 수를 표현할 수 있다는 측면에서 대부분의 컴퓨터 시스템에서 실수를 부동 소수점 방식으로 표현하고 있습니다.그러나 고정 소수점이든 부동 소수점이든 컴퓨터가 가진 하드웨어의 한계로인해 정확하게 표현할수 있는 실수는 그리 많지 않습니다. 왜냐하면 고정소수점이든 부동 소수점이든 결국 소수를 표현하는 부분에 특정 개수의 비트를 할당하는데, 이 부분을 2진수로 변환하였을 때 \\((1/2)^{n}\\)의 합으로 정확하게 표현할 수 있는 실수가 그리 많지 않기 때문입니다.특히나 제가 주로 사용하는 언어인 파이썬에서도 실수를 부동 소수점 방식으로 표현하고 있는데, 필연적으로 실수값을 계산할 때 오차가 발생합니다. 따라서 우리는 각자 사용하는 언어에서 실수에 대한 어떤 연산(비교 연산 등)을 할 때 항상 직관과 다른 결과가 발생할 수 있다는 사실을 인지하고 하여야 하겠습니다.Reference CS50 - C언어 부동 소수점(Floating Point)란 무엇인가? 컴퓨터에서의 실수 표현: 고정소수점 vs 부동소수점 고정소수점과 부동소수점 IEEE 754 [python] int8? float32? bool?, numpy 자료형 정리.txt (번역) 고정소수점 표현에 대한 이해 [오늘의 배움] 014 컴퓨터구조 부동소수점 부동 소수점 산술: 문제점 및 한계 [CS] 부동 소수점 오차 부동소수점처리" }, { "title": "MLOps - Continuous delivery and automation pipelines in machine learing 번역 및 요약 정리", "url": "/posts/MLOps/", "categories": "MLOps, Basic", "tags": "mlops, ci, cd, ct", "date": "2021-10-17 16:17:00 +0900", "snippet": " MLOps에 대한 레퍼런스를 찾아 보던 중 개념을 잡기에 좋은 글을 발견하여 번역 및 요약 정리합니다. 원문은 MLOps: Continuous delivery and automation pipelines in machine learing를 참조해주세요. 한글로 번역할 경우에 뜻이 모호해지는 경우에는 영어 그대로 쓰거나 한글과 영문을 병기하였습니다.본 글은 MLOps는 ML system 개발과 운영을 통합하기 위한 ML engineering의 문화와 관행(practice)에 대해서 이야기 합니다. 업무에 MLOps를 적용한다는 것은 ML system의 전 과정을 자동화하고 모니터링한다는 것을 의미합니다.ML system에서 좋은 퍼포먼스를 가진 모델을 만드는 것은 중요합니다. 그러나 그러한 일은 ML system 전체의 관점에서 보자면 매우 일부분입니다. 오히려 ML 모델을 잘 굴러가게 해주는 복잡하고 다양한 컴포넌트들을 잘 구성하는 것이 훨씬 중요한 일입니다.Elements for ML systems, Hidden Technical Debt in Machine Learning Systems이런 컴포넌트들을 통합하는 시스템을 개발하고 운영하기 위해서는 DevOps의 원칙을 ML system에 적용할 필요가 있습니다 (MLOps). 본 글에서는 다음의 주제들을 다룰 계획입니다. DevOps versus MLOps Steps for developing ML models MLOps maturity levelsDevOps versus MLOpsDevOps란 large-scale의 소프트웨어 시스템을 개발하고 운영하는 가장 인기 있는 practice입니다. DevOps를 떠 받치는 가장 중요한 두 가지 개념이 있습니다. Continuous Integration (CI) Continuous Deliver (CD)ML system도 필연적으로 소프트웨어 시스템이기 때문에 DevOps의 원칙을 똑같이 적용할 수 있습니다. 그러나 ML systems은 전통적인 소프트웨어 시스템과 다른 부분이 있습니다. Team skills: ML 프로젝트에 참여하는 데이터 사이언티스트들은 보통 숙련된 소프트웨어 엔지니어가 아닙니다. 이들은 보통 EDA, 모델 개발, 실험 업무에 집중하고 있으므로 소프트웨어 개발 프로세스를 잘 이해하지 못하고 있을 가능성이 높습니다. Development: ML은 실험의 영역입니다. 데이터 사이언티스트들은 새로운 모델을 실험하고, 피쳐 엔지니어링을 진행하는 등의 실험을 반복적으로 진행합니다. 문제는 이러한 실험을 추적하거나 코드의 재사용성 등의 품질을 관리하기가 어렵다는 것입니다. Testing: ML 시스템은 전통적인 소프트웨어 시스템보다 테스트가 필요한 영역이 많습니다. 전통적인 단위 테스트(unit test)와 더불어서 데이터 및 모델 검증 등이 추가로 필요합니다. Deployment: ML 시스템의 배포는 생각보다 간단하지 않습니다. ML 시스템은 여러 단계의 자동화된 파이프라인으로 이루어져 있으며, 이러한 파이프라인은 배포의 복잡성을 증대시킵니다. Production: ML 모델의 퍼포먼스는 코드의 품질에 따라서도 결정되지만 데이터의 변화에도 큰 영향을 받습니다. 다시 말하면, 모델의 성능이 하락하는 요인이 전통적인 소프트웨어 영역보다 다양하다는 것입니다. 따라서 데이터의 통계량을 추적 및 모니터링 해야하며 기대와 다른 경우에는 알람을 보내거나 roll back 하는 등의 추가적인 작업이 필요합니다.ML 시스템은 전통적인 소프트웨어 시스템과 같이 소스 코드 형상 관리, 단위 테스트, CI, CD 등의 개념이 필요합니다. 그러나 ML 시스템은 전통 소프트웨어 시스템과 매우 주목할만한 차이점이 존재합니다. CI(Continuous Integration): code를 테스트하거나 검증하는데 그치지 않습니다. data value와 data schema, model을 검증하는 것도 고려해야 합니다. CD(Continuous Delivery): 하나의 소프트웨어 패키지나 서비스를 배포하는데 그치지 않습니다. ML model을 서빙하는 서비스를 자동으로 배포하는 system(ML training puipeline) 자체를 배포하는 것도 고려해야합니다. CT(Continuous Training): 기존 소프트웨어 개발에 없던 새로운 개념입니다. CT는 자동으로 모델을 재학습하고 모델을 서빙하는 프로세스를 의미합니다.Steps for developing ML modelsArchitecture for MLOps using TFX, Kubeflow Pipelines, and Cloud BuildML 프로젝트를 작업을 크게 나누어 본다면 다음의 단계들로 이루어져 있습니다. 각 단계는 수동으로 진행되거나 자동화된 방식으로 진행됩니다. Data extraction: 모델 학습에 필요한 데이터를 data source에서 선별하고 가져옵니다. Data analysis: data의 특성과 schema를 탐색하고 피쳐 엔지니어링을 위한 EDA를 진행합니다. Data preparation: 피쳐 엔지니어링을 하거나 데이터를 학습, 검증, 테스트 셋으로 구분합니다. 이 단계의 산출물은 학습에 쓸 수는 format으로 변환된 데이터입니다. Model training: 준비된 데이터로 학습을 진행합니다. 또한 이 단계에서 hyperprameter 튜닝을 진행할 수 있습니다. 이 단계의 산출물은 학습된 ML 모델입니다. Model evaluation: 학습된 모델에 테스트 셋을 적용하여 모델의 퀄리티를 평가하는 단계입니다. 이 단계의 산출물은 모델의 퀄리티를 평가할 수 있는 metrics(e.g., acc, precision, recall, …)입니다. Model validation: 모델이 production 환경에 배포되어도 괜찮은지 검증하는 단계입니다. 특정 기준보다 더 나은 퍼포먼스를 보이는지 검증합니다. Model serving: validation 단계를 통과한 모델이 production 환경에 배포되는 단계입니다. (REST API 등) Model monitoring: 배포된 모델의 퍼포먼스를 지속적으로 모니터링 하여 모델의 성능 이슈를 지속적으로 점검 하는 단계입니다.MLOps maturity levels앞서 ML 시스템이 수행하는 작업을 여러 단계로 나누어 살펴보았습니다. 각 단계는 자동화 수준에 따라 0~2단계로 구분할 수 있습니다. 이를 ML 시스템의 성숙도(maturity)로 정의하겠습니다. 이제부터 ML 시스템의 성숙도별로 특징을 살펴보도록 하겠습니다.MLOps level 0: Manual processManual ML steps to serve the model as a prediction serviceML 시스템의 전 단계가 수동으로(manual) 이루어집니다. level 0 단계의 특징은 다음과 같습니다. Manual, script-driven, and interactive process: 모든 단계(데이터 분석, 준비, 학습, 검증 등)가 수동으로 이루어집니다. Disconnection between ML and operations: 모델링과 서빙이 분리되어 있습니다. 데이터 사이언티스트는 ML 모델을 만들고 그 결과물을 모델 배포를 담당하는 엔지니어링 팀에 넘겨줍니다. Infrequent release iterations: 데이터 사이언스팀이 담당하는 모델이 개수가 적어서 모델 배포가 자주 일어나지 않습니다. No CI: CI 단계가 없습니다. 코드의 테스트 및 검증은 노트북 파일이나 스크립트를 수동으로 실행하면서 일어납니다. No CD: 모델 배포가 자주 일어나지 않기 대문에 CD가 고려되지 않습니다. Deployment refers to the prediction service: 배포는 학습된 모델을 서빙하는 것만 고려됩니다. 자동화를 위한 전체 ML 시스템 파이프라인에 대한 배포는 고려되지 않습니다. Lack of active performance monitoring: 모델의 예측 결과 등이 추적되거나 로깅되지 않습니다.MLOps level 1: ML pipeline automationML pipeline automation for CTlevel 1의 목적은 ML 파이프라인을 자동화 하여 CT(continuous training)을 성공적으로 수행하는 것입니다. 이는 모델의 CD(continuous delivery)를 가능하게 합니다. level 1은 다음과 같은 특징이 있습니다. Rapid experiment: ML 실험 과정이 구조화(orchestrated)되어 있습니다. ML 실험의 각 단계가 자동화 되어 있어 실험을 빠르게 반복할 수 있습니다. CT of the model in production: 새로운 데이터로 모델을 학습시키는 과정이 자동화되어 있습니다. Experimental-operational symmetry: 개발 또는 실험 환경에서 사용하는 ML pipeline을 운영 환경에서도 동일하게 활용합니다. 이는 MLOps의 중요한 특징 중 하나입니다. Modularized code for components and pipelines: ML pipeline을 구축하기 위해 사용되는 components(검증, 학습 등)은 재사용성을 높이기 위해 모듈화(modularized) 되거나 컨테이너화(containerized) 되어야 합니다. Continuous delivery of models: ML pipeline은 새로운 데이터로 학습된 모델을 지속적으로 배포(CD) 합니다. 모든 과정이 자동화 되어 있습니다. Pipeline deployment: 모델 학습과 관련된 전체 ML pipeline(e.g., kubeflow pipeline, airflow 등)이 배포됩니다.level 1의 가장 큰 특징은 CT가 도입되었다는 것입니다. CT를 위해서는 다음의 component들이 추가적으로 필요합니다.Data and Model validation Data validation: 이 단계는 모델을 retrain 시켜야할지 아니면 training 파이프라인의 동작을 멈춰야할지 결정하기 위해 필요합니다. 그 의사결정은 다음의 세부 사항들을 보고 결정할 수 있습니다. Data schema skews: data schema skew는 downstream 작업에 영향을 미치는 이상치(anomalies)를 말합니다. 만일 ML 파이프라인에 기대했던 스키마에 맞는 데이터가 들어오지 않는다면 ML 파이프라인의 동작을 멈추고 이를 디버깅 해야합니다. Data values skews: daga value skew는 유의한 수준의 데이터 통계량의 변화를 듯합니다. 만일 데이터의 패턴이 급격하게 변화되었다면 모델 재학습을 진행해서 변화된 패턴을 capture해야 합니다. Model validation: 이 단계는 모델 학습이 성공적으로 이루어진 뒤에 이루어집니다. 학습된 모델은 metric을 평가(evaluate) 받아야 하고, 운영 환경에 배포하기 전에 검증(validate) 하는 단계를 거쳐야 합니다. 이 과정은 offline model validation에 가깝습니다. Producing evaluation metric values: 테스트 셋으로 학습된 모델의 metric을 평가합니다. Comparing the evaluation metric values: 새로 학습된 모델과 현재 버전의 모델의 metric을 비교하여 배포 여부를 결정합니다. Feature storefeature store란 학습과 서빙에 사용되는 공통적인 feature들은 모아 놓은 저장소(repository)를 의미합니다. feature stores를 구축하면 다음과 같은 이점을 얻을 수 있습니다. 각 모델별에서 공통적으로 사용하는 feature를 관리하므로 비효율성을 방지하고 재사용성을 향상 사람에 따라 서로 다르게 feature를 정의하는 혼돈을 방지 training-serving skew를 방지 training에 사용했던 feature를 서빙 타임에도 동일하게 사용하여 training과 서빙이 서로 다른 feature를 사용하여 발생할 수 있는 skew를 방지 Metadata managementML pipeline의 실행과 관련된 정보 (버전, 시작 및 종료 시간, 파라미터 등)을 기록하여 재현성을 높이고 버그 발생 가능성을 낮춥니다.ML pipeline trigger다음과 같은 use case에 맞춰서 ML 파이프라인 실행을 자동화 할 수 있습니다. On demand On a schedule On availabiltiy of new trainig data On model performance degradation On concept drift(significant changes in the data distributions)MLOps level2: CI/CD pipeline automationCI/CD and automated ML pipelineMLOps level 2에서는 자동화된 학습(CT)가 큰 특징이었습니다. ML은 태생적으로 실험의 영역이므로 새로운 아이디어를 자유롭게 실험하고 ML pipeline의 각 component (e.g. 모델 아키텍처 변경, 피쳐 엔지니어링, 하이퍼파라미터 변경 등)를 빠르게 배포할 수 있어야 합니다. 이를 위해서는 ML 파이프라인에 CI/CD가 셋팅되어야 합니다.MLOps level 2는 다음의 구성 요소들을 포함하게 됩니다. Source code control Test and build services Deployment services Model registry Feature store Ml metadata store ML pipeline orchestratorContinuous integration (CI)CI는 새로운 코드가 commit 되었을 때 ML 파이프라인의 구성 요소들을 빌드, 테스트, 패키징하는 과정을 의미합니다. 예를 들어 CI는 다음의 테스트들을 포함할 수 있습니다. 피쳐 엔지니어링 로직에 대한 단위 테스트(unit test) 모델에 dummy 데이터를 넣어서 학습이 수렴되는지 (오버피팅이 되는지)를 확인 모델 학습 과정에서 NaN 값이 발생하지 않는지 확인 ML 파이프라인의 각 컴포넌트들의 artifacts가 기대되는 것처럼 산출되는지 확인 ML 파이프라인의 각 컴포넌트들이 서로간에 잘 연결되는지 확인Continuous delivery (CD)CI를 통과하면 새로운 ML pipeline의 구성요소들이 target environment(개발 또는 운영 환경)에 자동으로 배포되도록 만들어야 합니다. 이를 CD라고 하며 다음의 작업들이 고려되어야 합니다. 학습된 모델을 배포하기 전에 해당 모델의 target infastructure와의 호환성(compatibility)를 검증합니다. 예를 들어 메모리나 CPU 스펙이 해당 모델을 서빙하기에 적합한지 검증합니다. 기대하는 input 값과 함께 API를 호출하여 적절한 reponse가 오는지 확인합니다. 이 테스트는 모델을 업데이트하거나 input 값을 변경하였을 때 발생할 수 있는 문제를 발견할 수 있습니다. 서빙 API의 퍼포먼스를 테스트합니다. 여기에는 부하 테스트(load testing)를 통한 QPS(queries epr seconds)나 latency에 대한 체크가 포합됩니다. development branch에 코드가 commit 되었을 때 test 환경에 배포가 자동적으로 이루어지도록 합니다. main branch에 동료의 review를 통해 코드가 merge 되었을 때, pre-production 환경에 semi-automated 배포가 이루어집니다. pre-production 환경에서 ML pipeline이 수차례 성공하고 나서 production 환경에 수동으로 배포가 이루어집니다.SummaryML 모델을 production 환경에 배포하는 일은 단순히 서빙 API를 배포하는 것에 그치지 않습니다. ML의 실험 정신을 잘 살리기 위해서는 ML 파이프라인의 전 과정이 자동화 되어야 합니다. 이를 위해서는 CI, CD, CT가 고려된 ML 파이프라인을 설계하는 것이 중요합니다. 잘 설계된 ML 파이프라인은 데이터의 변화나 이상치에 긴밀하게 대처할 수 있으며, 적절한 시기에 모델을 다시 학습 시킬 수도 있습니다. 물론 한번에 level 0에서 level 2로 점프할 수는 없습니다. 점진적으로 개선해 나가세요!Reference MLOps: Continuous delivery and automation pipelines in machine learning Architecture for MLOps using TFX, Kubeflow Pipelines, and Cloud Build MLOps: What It Is, Why it Matters, and How To Implement It" }, { "title": "ASCII, Unicode, 파이썬 한글 인코딩", "url": "/posts/korean_encoding/", "categories": "CS, CS50", "tags": "ascii, unicode, encoding", "date": "2021-10-11 16:12:00 +0900", "snippet": "한글 인코딩 때문에 고생한 경험, 다들 있으시죠?소위 말하는 인코딩이 깨진 경험을 하신적이 있지 않으신가요? 특히 맥을 처음 다루어 보신 분들께서 한글 인코딩이 깨진 경험을 많이 하셨을 것 같습니다. 분명히 윈도우에서 제대로 보이는 csv 파일이, 맥에서 열면 깨져버리죠. 이는 윈도우와 맥의 기본적인 한글 인코딩 방식이 달라서 발생하는 문제입니다. 쉽게 말해서 두 운영체제가 문자를 이해하는 시스템이 다르다는 이야기입니다.문자 인코딩은 깊게 파보면 정말 어려운 주제 중에 하나인데요. 본 글에서는 여러가지 문자 인코딩 방식 중에서 가장 대표적인 ASCII, Unicode에 대해서 살펴보고 파이썬의 한글 인코딩 방식을 통해 실용적인 관점에서 인코딩 내용을 정리 해보려고합니다. 더욱 이론적이고 자세한 내용의 글들은 얼마든지 많으니 자세한 설명을 원하시는 분들께서는 레퍼런스를 참고해주세요.본격적으로 글을 시작 하기 앞서, 문자 인코딩은 무엇이며 왜 필요한지에 대한 글은 여기를 참조해주세요.ASCII(American Standard Code for Information Interchange)ASCII는 문자를 7bit로 표현하는 표준문자체계입니다. 따라서 ASCII는 \\(2^7=128\\)개의 문자만 표현할 수 있는데, 이는 영문 키보드에서 사용할 수 있는 모든 문자를 표현할 수 있는 수준에 그칩니다. 그러나 표현해야하는 문자가 점차 증가함에 따라 7bit로 문자를 표현하는 것에 한계가 드러났습니다. 이후에 8bit(1byte)를 쓰는 확장 ASCII(Extended ASCII)가 등장했습니다. 확장 ASCII는 기존 ASCII에 비해 2배 많은 문자를 표현할 수 있습니다. 이를 통해 기존 ASCII로 정의하지 못했던 프랑스어, 독일어 등의 유럽어를 표현할 수 있게 되었습니다.ASCII Code Table, ASCII Table: Printable Reference &amp;amp; Guide위의 ASCII 코드 표를 참조해서 ‘A’가 인코딩된 값을 찾아볼까요? 대문자 A는 16진수(hex)로 표현하면 41로 인코딩할 수 있네요. 이처럼 문자 인코딩은 특별한 알고리즘을 쓰는 것이 아니라 생각 보다 단순하게(?) 룰 기반인 것을 알 수 있습니다.그러나 확장 ASCII로도 표현하지 못하는 문자들은 (당연하게도) 여전히 존재합니다. ASCII 코드 표를 보면 영어 알파벳 외의 문자는 찾아 볼 수 없죠. 그렇다면 한국어, 중국어, 일본어 등의 문자를 표현하려면 어떻게 해야할까요? 전 세계의 문자를 모두 표현할 수 있는 표준화 된 체계가 필요한 시점입니다.UnicodeASCII 섹션에서 살펴 보았듯이 ASCII는 전 세계의 다양한 문자를 담지 못합니다. 물론 이전부터 각 언어마다 해당 언어를 표현할 수 있는 독자적인 문자 집합(character set)은 있어 왔습니다 (EUC-KR 등). 그러나 문제는 이 독자적인 문자 집합을 어떻게 통합해서 관리하느냐 였습니다. 이 문제를 해결 하기 위해 다양한 문자 집합을 담을 표준으로 유니코드(Unicode)가 등장하게 되었습니다.유니코드는 전 세계의 모든 문자를 일관되게 표현할 수 있는 표준문자체계입니다. 유니코드는 문자를 2~4btye의 16진수 숫자로 1:1 맵핑을 해 놓은 문자 집합(character set)입니다. 유니코드의 값을 코드 포인트(code point)라고 하는데 유니코드 문자는 보통 접두어 U+나 \\u로 시작합니다. 예를 들어 A의 유니코드 코드 포인트는 U+0041로 표현됩니다(전체 표는 여기를 참조해주세요). U+ 0 1 2 3 4 5 6 7 … 0000 NUL SOH STX ETX EOT ENQ ACK BEL … 0010 DLE DC1 DC2 DC3 DC4 NAK SYN ETB … 0020   ! ” # $ % &amp;amp; ’ … 0030 0 1 2 3 4 5 6 7 … 0040 @ A B C D E F G … 0050 P Q R S T U V W … 0060 ` a b c d e f g … 0070 p q r s t u v w … 여기서 하나 중요하게 짚고 넘어가야하는 포인트가 있습니다. 유니코드는 특정 인코딩 방식을 가르키는 것이 아닙니다. 다양한 문자를 16진수로 표현된 특정 숫자로 맵핑하는 표에 지나지 않습니다. 아주 다양한 문자 각각을 숫자에 1:1 대응 시켜 놓은 표인 것이죠. 그런데 컴퓨터는 무조건 0과 1로 이루어진 binary format만 이해할 수 있습니다. 예를 들어 여러분이 메모장에 ‘A’이라는 글자를 적고 이를 저장한다면 하드디스크에는 ‘A’가 0과 1로 이루어진 2진수로 변환되어 저장된다는 이야기 입니다.A의 코드 포인트 U+0041을 2진수로 변환해봅시다. 1000001 이군요. 이걸 그대로 인코딩된 값으로 활용하면 되겠네요! 문자 code point binary A U+0041 1000001 그런데 정말 이렇게 단순하게 16진수를 2진수로 변환해서 저장하면 될까요? 다음의 예시를 보시죠. 이번엔 메모장에 ÀÈ라는 글자를 적고 텍스트 파일로 저장해 봅시다. 문자 code point binary À U+00C0 11000000 È U+00C8 11001000 그렇다면 하드디스크에는 1100000011001000과 같이 2진수 형태로 저장될겁니다. 자 이제 그 텍스트 파일을 실행해 봅시다. 그렇다면 컴퓨터는 2진수 데이터를 인간이 읽을 수 있는 문자로 디코딩하는데, 코드 포인트 C0C8 복원합니다. 자, 여기서 문제가 발생합니다. C0C8은 한 글자일까요 두 글자일까요? 당연히 두 글자입니다. 방금 예시를 두 글자로 들었기 때문이죠. 그런데 컴퓨터는 C0C8를 두 글자로 표현해야 한다는 것을 알 수 있을까요? 참고로 코드 포인트 C0C8은 ‘새’에 대응 됩니다. U+ 0 1 2 3 4 5 6 7 8 C0C0 샀 상 샂 샃 샄 샅 샆 샇 새 C0D0 샐 샑 샒 샓 샔 샕 샖 샗 샘 유니코드 코드 포인트를 단순히 2진수로 변환해서 활용하면 될 것 같았는데… 생각보다 크리티컬한 문제에 봉착하게 됩니다. 이 시점에 유니코드를 인코딩하는 시스템이 필요하게 됩니다. 유니코드 기반의 인코딩 방식으로 UTF-8, UTF-16 등이 존재합니다. 그 가운데 사실상의 표준으로 자리 잡은 UTF-8을 살펴보겠습니다.UTF-8UTF-8의 UTF는 ‘Unicode Transformation Format’의 약자입니다. 이름만 봐도 Unicode에 기반한 인코딩 방식임을 알 수 있습니다. 8은 문자 하나를 8bit(1byte)로 처리한다는 뜻입니다. UTF-8은 가변 길이 문자 인코딩 방식으로서 코드 포인트의 범위에 따라 문자를 1~4byte로 가변적으로 처리합니다. UTF-8은 다음과 같은 장점이 있습니다. 자주 사용되는 문자는 적은 비트를 할당하고 자주 사용되지 않는 문자에는 많은 비트를 할당하여 효율적으로 인코딩 모든 알파벳은 1byte 한글은 무조건 3byte ASCII는 UTF-8의 부분 집합임 즉 ASCII의 인코딩 값과 UTF-8의 인코딩 값은 정확하게 일치함 따라서 하위 호환성이 보장됨 UTF-16과 간단히 비교하자면, UTF-16은 문자를 2~4byte로 할당합니다. UTF-8은 1~4byte로 할당하므로 한중일 언어를 제외한 대부분의 문자는 UTF-8 방식이 더 작은 크기로 표현할 수 있습니다. 자세한 장단점에 대한 비교는 여기를 참조해주세요.이제 UTF-8이 문자를 실제로 어떻게 인코딩 하는지 살펴봅시다. UTF-8은 아래의 테이블에 서술된 규칙에 따라 유니코드 문자를 인코딩을 합니다. 먼저 유니코드 코드 포인트를 2진수로 변환 합니다. 그리고 해당 문자의 코드 포인트의 범위를 찾아서 그 범위에 해당하는 UTF-8의 인코딩 규칙을 적용합니다. 마지막으로 xxx로 되어 있는 부분을 뒤에서부터 2진수로 채우며, 모자라는 부분은 0으로 채웁니다. 코드 포인트 범위(hex) UTF-8 000000-00007F 0xxxxxxx 000080-0007FF 110xxxxx 10xxxxxx 000800-00FFFF 1110xxxx 10xxxxxx 10xxxxxx 010000-10FFFF 11110zzz 10zzxxxx 10xxxxxx 10xxxxxx À와 È는 모두 코드 포인트의 범위가 000080-0007FF에 속합니다. 그리고 이를 2진수로 변환하면 각각 11000000, 11001000입니다. 이를 UTF-8로 인코딩 하면 각각 11000011 10000000과 11000011 10001000으로 변환됩니다. 이를 나중에 디코딩할 때는 UTF-8의 인코딩 규칙을 알고 있으므로 binary 데이터가 결국에 몇개의 문자로 이루어져있는지, 인간이 이해할 수 있는 형태의 문자는 무엇인지를 정확하게 찾아서 표현할 수 있게 되는 것입니다.파이썬 한글 인코딩파이썬3의 모든 문자열은 유니코드입니다. 파이썬 3.0부터는 언어의 str 형은 유니코드 문자를 포함하고, 이는 어떤 문자열이든 &quot;unicode rocks!&quot;, &#39;unicode rocks!&#39; 또는 삼중 따옴표로 묶인 문자열 문법을 사용한다면 유니코드로 저장됨을 뜻합니다.파이썬에서 인코딩과 디코딩을 담당하는 내장함수는 각각 encode()와 decode()입니다. encode()는 유니코드 문자열을 bytes로 변환하고, decode()는 이와 반대로 bytes를 유니코드로 변환합니다. 참고로 파이썬에서 bytes는 binary 데이터를 다루는 type입니다. 계속 말씀드렸던 2진수 데이터를 파이썬에서는 bytes라는 type으로 표현한다고 보시면 되겠습니다.인코딩파이썬에서는 str의 encode() 메소드로 유니코드를 바이트로 변환할 수 있습니다. str.encode()는 bytes.decode()에 반대되는 메서드로서, 요청된 encoding으로 인코딩 된 유니코드 문자열의 bytes를 반환하는 메서드입니다.한글 ‘가’를 파이썬에서 utf-8로 인코딩해서 이론대로 변환이 되는지 확인 해 봅시다.&amp;gt;&amp;gt;&amp;gt; string = &#39;가&#39;&amp;gt;&amp;gt;&amp;gt; print(string.encode(&#39;utf-8&#39;))b&#39;\\xea\\xb0\\x80&#39;&amp;gt;&amp;gt;&amp;gt; print(type(string.encode(&#39;utf-8&#39;)))&amp;lt;class bytes&amp;gt;파이썬에서 ‘가’를 UTF-8로 인코딩하니 EA B0 80 이렇게 3byte의 숫자로 변환되었습니다. 일단 한글 1글자가 3byte인 것은 UTF-8의 규칙에 맞습니다. 그렇다면 우리가 배운 이론을 적용해서 실제로 EA B0 80가 나오는지 살펴보죠.한글 ‘가’의 유니코드 코드 포인트는 U+AC00 입니다. 이를 2진수로 변환하면 1010 1100 0000 0000 입니다. 이제 위에서 배운 UTF-8 인코딩 규칙에 따라 2진수를 변환해봅시다. U+AC00은 000800-00FFFF 범위에 속하니까… 1110xxxx 10xxxxxx 10xxxxxx 이 패턴에 맞게 2진수를 뒤에서부터 채워주면 되겠네요. 그럼 11101010 10110000 10000000를 얻을 수 있습니다. 파이썬에서는 인코딩된 값을 16진수(\\x)로 나타내고 있으니까 우리도 16진수로 변환해보면… EA B0 80를 얻을 수 있습니다. 직접 손으로 계산한 인코딩 값과 파이썬이 출력한 인코딩 값이 일치합니다! 문자 유니코드 코드 포인트 2진수 UTF-8(Bin) UTF-8(Hex) 가 U+AC00 1010 1100 0000 0000 11101010 10110000 10000000 EA B0 80 디코딩파이썬에서 bytes의 decode() 메서드를 통해서 bytes 문자열을 유니코드 문자열로 되돌릴 수 있습니다. bytes.decode()는 주어진 바이트열로부터 디코딩된 문자열을 돌려줍니다. 기본 인코딩은 &#39;utf-8&#39; 입니다.위에서 얻어낸 한글 ‘가’의 UTF-8 인코딩 값인 b&#39;\\xea\\xb0\\x80&#39;를 다시 유니코드 문자열로 되돌려 보겠습니다.&amp;gt;&amp;gt;&amp;gt; bytes_string = b&#39;\\xea\\xb0\\x80&#39;&amp;gt;&amp;gt;&amp;gt; print(bytes_string.decode(&quot;utf-8&quot;))&#39;가&#39;&amp;gt;&amp;gt;&amp;gt; print(type(bytes_string.decode(&quot;utf-8&quot;)))&amp;lt;class str&amp;gt;처음에 ‘가’를 UTF-8로 인코딩한 bytes를 알아내었고, 그 bytes를 같은 인코딩 방식인 UTF-8로 디코딩 했으니 어쩌면 당연한 결과입니다. 그렇다면 인코딩과 디코딩 방식이 다르면 어떨까요?인코딩과 디코딩 방식이 다를 때이번에는 인코딩과 디코딩 방식이 다를 때 어떤 일이 일어나는지 살펴보겠습니다. 먼저 한글 ‘가’를 euc-kr 이라는 인코딩 방식으로 인코딩 해줍니다.&amp;gt;&amp;gt;&amp;gt; string = &#39;가&#39;&amp;gt;&amp;gt;&amp;gt; print(string.encode(&#39;euc-kr&#39;))b&#39;\\xb0\\xa1&#39;16진수 B0 A1이라는 인코딩된 값을 얻었습니다. 이 값을 euc-kr이 아니라 UTF-8로 디코딩 해보겠습니다.&amp;gt;&amp;gt;&amp;gt; print(b&#39;\\xb0\\xa1&#39;.decode(&#39;utf-8&#39;))---------------------------------------------------------------------------UnicodeDecodeError Traceback (most recent call last)&amp;lt;ipython-input-23-d8ceaefe020b&amp;gt; in &amp;lt;module&amp;gt;----&amp;gt; 1 print(b&#39;\\xb0\\xa1&#39;.decode(&#39;utf-8&#39;))UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xb0 in position 0: invalid start byteUnicodeDecodeError가 발생합니다. 이는 문자가 인코딩된 방식과 디코딩된 방식의 차이에서 기인합니다. 각 인코딩 방식마다 숫자의 범위나 체계가 다르기 때문에 발생하는 일이겠죠.마무리지금까지 ASCII, 유니코드, UTF-8 기반의 문자 인코딩 방식에 대해서 살펴보았습니다. 컴퓨터는 0과 1로만 이루어진 2진법의 언어만 이해할 수 있습니다. 따라서 문자도 숫자로 변환해야만 우리는 서로 다른 컴퓨터 간에 문자 데이터를 주고 받을 수 있습니다. 문자를 특정 숫자로 변환하는 행위를 문자 인코딩(encoding)이라고 하고 그 반대의 행위를 문자 디코딩(decoding)이라고 합니다.문자를 인코딩 방식은 매우 다양한데요. 각 방식마다 다룰 수 있는 문자의 개수도 다르고 변환되는 숫자도 다릅니다. 그리고 우리는 여러가지 문자 인코딩 방식에서 가장 대표적인 방식인 ASCII, Unicode, UTF-8에 대해서 살펴보았습니다. 각각의 아주 세부적인 내용까지는 정리하진 않았지만, 코딩을 하면서 만날 수 있는 여러가지 문자 인코딩 에러를 이해하고 대처할 수 있는 기초 체력을 기르다는 관점으로 접근해 보았습니다.Reference 유니코드 한글 인코딩의 이해 1편: 한글 인코딩의 역사와 유니코드 한글 인코딩의 이해 2편: 유니코드와 Java를 이용한 한글 처리 한글 인코딩, EUCKR 과 UTF8 제대로 알기 (1) 파이썬 한글 인코딩(UTF8, Unicode, Euc-Kr) 탐구 ASCII Table: Printable Reference &amp;amp; Guide What is the difference between UTF-8 and Unicode? 파이썬 - 인코딩과 디코딩 유니코드 HOWTO" }, { "title": "CS50 - 컴퓨팅 사고(Computational Thinking)", "url": "/posts/cs50_computational_thinking/", "categories": "CS, CS50", "tags": "bit, algorithm", "date": "2021-10-10 16:21:00 +0900", "snippet": "최근 사내에서 CS50 스터디를 시작했습니다. 본 포스팅은 CS50의 첫번째 주제인 ‘컴퓨팅 사고’의 내용을 정리합니다. 컴퓨터는 정보를 어떤 방식으로 표현할까요? 그리고 컴퓨터는 정보를 어떻게 처리할까요? 오리엔테이션 성격의 강의이기 때문에 가볍게 정리해보려고 합니다.본 포스팅에서는 다음의 내용을 다룹니다. 컴퓨터가 ‘숫자’를 이해하는 방법 컴퓨터가 ‘문자’를 이해하는 방법 알고리즘컴퓨터가 숫자를 이해하는 방법10진법컴퓨터는 0과 1만 이해할 수 있다는 이야기를 많이 들어 보셨을 겁니다. 그런데 우리는 너무나 당연하게도 컴퓨터로 아주 큰 수를 다룰 수도 있고, 문자를 활용하여 문서도 작성하고 유튜브 영상도 보고 음악 감상도 합니다. 겨우 0과 1 두 가지 숫자만 처리할 수 있는데 이렇게 복잡한 정보를 어떻게 처리하는 걸까요?컴퓨터가 숫자를 다루는 방법부터 시작하는게 좋겠습니다. 서두에서 언급했다시피 우리가 일상생활에서 사용하는 컴퓨터는 0과 1, 이 두 가지 숫자만 이해할 수 있습니다. 하지만 0과 1만 있으면 우리가 알고 있고 + 상상할 수 있는 모든 수를 표현할 수 있습니다. 이게 어떻게 가능할까요? 우리는 10진법을 사용하는데 매우 익숙합니다. \\(13\\), \\(535\\), \\(46357\\) 등 일상에서는 거의 모든 수를 십진법으로 표현하고 있죠. 특히 \\(13\\)이라는 숫자를 다음과 같이 표현할 수 있다는 사실도 당연하게 받아들일 수 있습니다.\\[13 = 10^1*1 + 10^0*3\\]\\(13\\)은 \\(10^1\\)자리수와 \\(10^0\\)의 자리수로 분리해서 생각해볼 수 있습니다. 중요한 점은 십진법에서는 숫자를 \\(10\\)의 거듭제곱으로 표현하고 있다는 것입니다. 그리고 \\(10^1\\) 자리수인 1과 \\(10^0\\) 자리수인 3을 이어 붙여서 \\(13\\) 이라는 숫자로 나타냅니다. 이 것이 숫자를 10진법의 시스템에서 표현하는 방법입니다. 10진법은 숫자를 0~9를 활용해서 표현합니다.2진법컴퓨터는 0과 1만을 이용해서 모든 연산을 처리합니다. 다시 말해, 2진법으로 수를 표현하는 것이죠. 10진법은 숫자를 10의 거듭제곱으로 표현하는 것과 같은 원리로 2진법에서는 숫자를 2의 거듭제곱으로 표현합니다. 십진수 13을 2의 거듭제곱으로 표현하면 다음과 같습니다.\\[\\begin{align}13_{(10)} &amp;amp;= 2^3*1 + 2^2*1 + 2^1*0 + 2^0*1 \\\\[1em]&amp;amp;= 1101_{(2)}\\end{align}\\]그리고 \\(2^3\\) 자리수 1, \\(2^2\\) 자리수 1, \\(2^0\\) 자리수 1을 이어 붙이면 \\(111\\)이라는 수가 나타납니다. 즉 십진법 13은 이진법 111로 표현되는 것이죠. 두 수는 수의 시스템이 다를 뿐 완벽하게 같은 숫자입니다. 따라서 우리가 10진법으로 생각하는 모든 수는 2진법으로 표현할 수 있습니다. 따라서 컴퓨터는 0과 1만 이용하더라도 매우 큰 수를 표현할 수 있게 되는 것이죠.왜 하필 2진법을 사용할까?그렇다면 왜 컴퓨터는 왜 2진법을 사용할까요? 컴퓨터에서 연산을 담당하는 CPU는 수많은 트랜지스터로 구성되어 있습니다. 이 트랜지스터는 전기 신호를 받았을 때 일정 기준 이상의 전압이 걸리면 전기 신호를 출력(1)하고 그렇지 않으면 전기 신호를 출력하지 않는(0) 식으로 설계 되어 있습니다. 컴퓨터의 언어가 2진법인 것은 트랜지스터의 작동 원리에 기인한 것이라고 할 수 있습니다.하지만 2진법은 인간의 입장에서 보면 좀 불편한 것이 사실입니다. 일상에서 흔히 접할 수 있는 시스템이 아니기 때문인데요. N진법을 사용하면 하나의 트랜지스터에서 표현할 수 있는 정보의 양이 더 많아지기 때문에 훨씬 좋을 것 같은데, 왜 기술이 발달한 지금까지도 2진법 시스템을 고수하고 있을까요?먼저 2진법 만으로도 인간의 모든 논리 연산을 표현할 수 있기 때문입니다. CPU는 수많은 트랜지스터로 구성되어 있다고 했습니다. 트랜지스터 하나는 0 또는 1, 즉 2가지 정보만 표현이 가능합니다. 하지만 수많은 트랜지스터의 출력값을 조합하면 더 풍성한 정보를 표현할 수 있고 논리 연산(AND, OR, XOR 등), 사칙 연산 등이 충분히 가능합니다. 2진법만으로도 정보의 표현력에 한계는 없는 것이죠.그리고 2진법은 N진법에 비해서 오류가 최소화되고 시간 효율성에서 합리적입니다. 트랜지스터는 특정 전압을 임계값으로 하여 전기 신호를 출력(1) 할지 말지(0)를 결정한다고 하였는데요. 만일 N진법을 사용한다면 전압을 좀더 세밀한 단위로 나누어서 구분해야 할 것입니다. 따라서 전압을 좀 더 정확하게 측정하는데 드는 시간 비용이 발생하게 됩니다. 또한 외부의 노이즈에 영향을 받을 수도 있죠. 결과적으로 0과 1로 단순하게 구분하는 것이 훨씬 효율적인 방법이라고 할 수 있습니다 (Simple Is Best!).컴퓨터가 문자를 이해하는 방법컴퓨터가 2진수를 활용하여 숫자를 표현한다는 사실은 알게 되었습니다. 그런데 숫자보다 훨씬 복잡한 문자는 컴퓨터가 어떻게 표현하고 이해할까요? 결론부터 말하면 컴퓨터에서 다루는 모든 정보는 0과 1로 이루어진 bit로 표현합니다. 이는 문자도 예외가 아닙니다. 문자를 이진수로 변환하는 것을 문자 인코딩(encoding)이라고 하고, 이진수를 인간이 이해할 수 있는 문자로 변환화는 과정을 디코딩(decoding)이라고 합니다.문자열을 인코딩하는 방식은 다양한데요. 대표적으로 ASCII와 Unicode를 들 수 있습니다. 이에 대한 더 자세한 설명은 여기를 참조해주세요.ASCII(American Standard Code for Information Interchange)ASCII는 문자를 7bit로 표현하는 표준문자체계입니다. 따라서 ASCII는 \\(2^7=128\\)개의 문자만 표현할 수 있는데, 이는 영문 키보드에서 사용할 수 있는 모든 문자를 표현할 수 있는 수준입니다. 그러나 표현해야하는 문자가 점차 증가함에 따라 7bit로 문자를 표현하는 것에 한계가 드러났습니다. 이후에 8bit(1byte)를 쓰는 확장 ASCII가 등장했습니다. 확장 ASCII는 기존 ASCII에 비해 2배 많은 문자를 표현할 수 있습니다.Unicode유니코드는 전 세계의 모든 문자를 일관되게 표현할 수 있는 표준문자체계입니다. ASCII는 전 세계의 다양한 문자를 담지 못합니다. 이에 따라 다양한 문자를 담을 표준이 필요해졌는데, 이에 따라 유니코드가 등장하게 되었습니다. 유니코드는 문자를 2~4btye 숫자 (코드 포인트)로 1:1 맵핑을 해 놓은 문자 집합(character set)입니다. 헷갈릴만한 점은 유니코드는 ASCII와 다르게 특정 인코딩 방식을 가르키는 것은 아니라는 것입니다. UTF-8, UTF-16, UTF-32과 같은 용어를 들어 보셨을 텐데요. 이들이 바로 유니코드를 활용한 인코딩 방식입니다.알고리즘알고리즘이란?지금까지 컴퓨터가 정보를 표현하는 방법을 알아보았습니다. 그렇다면 컴퓨터는 정보를 어떻게 가공해서 출력할까요? 컴퓨터가 정보를 처리하는 단계적인 방법을 알고리즘이라고 합니다. 알고리즘이란 멀리 있는 것이 아닙니다. 인간의 사고 과정도 결국엔 알고리즘입니다.전화번호부에서 mike smith를 찾아보자.512 페이지짜리 전화번호부에서 mike smith의 전화번호를 찾는 문제가 주어졌다고 가정해봅시다. 그리고 이 전화번호부는 알파벳 순으로 정렬되어 있습니다. 이 문제를 어떻게 풀어볼까요?먼저 가장 단순하게는 첫페이지부터 차례 차례 mike smith를 찾는 것입니다. 1 페이지 2 페이지 … 최악의 경우에는 512 페이지까지 다 보아야만 mike smith를 발견할 수도 있습니다. 이러한 탐색 방법을 선형 탐색이라고 합니다. 선형 탐색은 매우 정확한 방법이지만 동시에 매우 비효율적인 방법임을 짐작하실 수 있을 겁니다.더 효율적인 방법이 있을까요? 먼저 전체의 절반인 256 페이지를 펴 봅니다. mike smith가 있으면 탐색을 종료해도 됩니다. 그러나 없다면, 우리는 mike smith가 256 페이지보다 앞에 있을지 뒤에 있을지 알 수 있습니다. 만약 mike smith가 256 페이지보다 이전에 있다면 이후의 페이지들은 더 이상 탐색할 필요가 없습니다. 이러한 과정을 반복 진행하면 처음부터 차례로 탐색하는 방법 보다는 훨씬 효율적으로 탐색할 수 있습니다. 물론 정확성도 보장되구요. mike smith가 64 페이지에 있었다면 3번만 탐색해도 정확하게 찾을 수 있습니다. 이러한 탐색 방법을 분할 정복이라고 합니다.컴퓨도로 방금 예시의 알고리즘을 그대로 구현할 수 있습니다. 다음의 구성 요소를 통해서요. function condition boolean expressions loops variables …더 효율적인 알고리즘?전화번호부의 예시에서 처럼 같은 문제를 해결하더라도 더 효율적인 알고리즘이 존재합니다. 같은 양의 데이터가 인풋 되었을 때, 문제를 해결하는데 시간이 덜 걸리는 알고리즘이 더 효율적인 알고리즘입니다. 강의 후반부에 정렬 알고리즘을 배우면서 이 부분은 더 자세히 다룰 기회가 있을 것 같습니다.Reference 모두를 위한 컴퓨터 과학 (CS50 2019) 컴퓨터의 동작원리 컴퓨터의 작동 원리 컴퓨터는 왜 불편한 이진수를 사용할까? 10진수 2진수 변환 공식 원리와 정리" }, { "title": "Pycon 2021 발표 요약", "url": "/posts/pycon_2021/", "categories": "Conference, Pycon", "tags": "pycon, python", "date": "2021-10-03 18:59:00 +0900", "snippet": "파이콘 2021 발표 영상을 보면서 인상 깊었던 발표를 간단하게 요약합니다.기획자가 한 번 추천한 음식은 ‘당분간’ 추천하지 말라고 했다.김다현 인간의 정성적 심리 상태를 정량화 하려는 시도가 돋보임 한번 추천 했던 음식은 언제 다시 먹고 싶을까? 3일 뒤면 다시 100% 먹고 싶어 진다는 가설에서 출발해서 그 심리 상태를 회복하기까지의 변화를 정량적으로 측정 여러가지 그래프(단조증가함수, 지수함수, 시그모이드 함수)를 찾아가는 과정이 재미있었음 기획 -&amp;gt; 리서치 -&amp;gt; 코드 구현 -&amp;gt; 적용의 cycle을 빨리 돌려서 문제점을 개선해 나가는 과정이 인상 깊었음 (연사분께서도 말씀하셨지만) 추천 가중치 조절 이후에 목표 지표가 어떻게 변화 했는지 궁금했음 회사에서 시퀀스 기반 추천에 exponential decay 함수를 통해 최신성에 대한 가중치 조절을 검토해 본 적 있는데 실행에 옮기진 못함. 이번 기회에 실험 해 봐도 좋을듯. A/B 테스트가 가능한 환경이 선행 되어야 의미 있는 작업이 될 수 있을 것 같음파이썬이 빅테이터를 다루기엔 느리다구요?박현우 빅데이터 처리의 사실상의 표준(de facto standard)인 spark 고수준 API인 DataFrame을 쓴다면 pyspark도 scala 만큼의 성능 낼 수 있음. 성능 차이가 작다고 함 pyspark best practice를 알려 줘서 좋았음. 팀원들에게도 전달할 필요성이 있겠음 RDD 대신 DataFrame을 사용: DF를 쓴다면 쿼리 분석 및 실행 계획이 자동으로 최적화 됨 UDF를 최대한 피해라 UDF는 spark 입장에서 블랙박스. 따라서 최적화가 어려움 최대한 내장 함수를 찾아보고 그래도 없을 때만 UDF를 활용하라 UDF를 써야만 한다면 python UDF가 아니라 pandas UDF를 써라 python UDF 대신 pandas UDF 도입시 성능이 3~100배 향상 가능 더욱 pythonic한 spark를 만들기 위한 프로젝트들이 계속 생겨나고 있음 project Zen pyspark를 보다 더 python스럽게 하자 pandas API on Spark 기존에는 koals라는 이름으로 따로 진행된 프로젝트였으나 pyspark 3.2 버전부터 spark 생태계에 포함됨 pandas API를 그대로 pyspark에서 활용 가능함 버전업이 되면서 pandas에 익숙한 분석가나 사이언티스트에게 더욱 친화적으로 변화되고 있다는 사실을 알 수 있었음 데이터 엔지니어 팀원과 함께 기존 아키텍처와 spark 3.2 버전의 호환성 및 안정성 확인 필요 분석용으로 충분히 도입할만 하다면 분석가나 사이언티스트에게 큰 도움이 될 것 같음 (pyspark를 쓰기 위한 러닝 커브가 낮음) 머신러닝 엔지니어 커리어 로드맵송호연 발표내용 요약 커리어를 위한 회사 선택 기준 회사의 핵심 역량이 ML인가?(=회사가 ML로 돈을 벌고 있나?) 핵심 모델을 지속적으로 개선할 데이터가 있나? 회사는 ML 엔지니어링의 가치를 인식하고 있는가? 주니어 ML 엔지니어로 성장하는 방법 주니어 성장의 핵심은 “최고의 동료”. 최고의 동료를 만나려면 내가 최고가 되기 위해 노력 해야함 기본기가 중요 python, linear algebra, probability and statistics, optimization theory, deeplearning framework, linux, cloud computing, docker, model management, model serving, experiment management, … 시니어 ML 엔지니어로 성장하는 방법 생산성(productivity)를 높이자. AI model의 생산 비용을 낮추자. 효율적인 ML 파이프라인을 설계 하자. Model의 지속적인 A/B 테스트를 하자. 만들어낸 모델이 어떤 business value를 뽑아 냈는지 정량적으로 검증할 수 있어야 한다. 개인적인 생각 커리어를 선택할 때 회사의 규모에 신경 쓰지 말자. 내가 좋아하는 ML + 엔지니어링의 중요성을 생각하고, 이게 회사의 전사적 목표인 회사로 가자. 내가 하고 싶은 일을 할 수 있는 회사로 가자! Reference PYCON.KR 2021 Koalas: pandas API on Apache Spark Koalas: 스파크에서 쓰는 Pandas API" }, { "title": "파이썬 이터러블(iterable), 이터레이터(iterator), 제너레이터(generator)의 차이", "url": "/posts/container_iterable_iterator_generator/", "categories": "Python, Basic", "tags": "python, iterable, iterator, generator, container, sequence", "date": "2021-10-02 19:03:00 +0900", "snippet": "본 글은 ‘우리를 위한 프로그래밍 : 파이썬 중급’를 수강 후(내돈내산!!💰) 헷갈렸던 iterable, iterator, generator의 차이를 정리합니다. 파이썬을 중급 이상 수준에서 활용하시는 분들은 자주 들어보셨을 만한 개념인데요.파이썬 활용 수준을 업그레이드 하기 위해서 반드시 짚고 넘어가야 하는 개념이지 않나 싶습니다. 그래서 이번 기회에 매우 헷갈리는 세 친구들의 차이점을 정리해보겠습니다!! 하나하나에 대해 자세히 다루진 않고 차이점 위주로 정리합니다.본 글에서는 아래의 주제를 다룹니다. container(컨테이너) sequence(시퀀스) iterable(이터러블) iterator(이터레이터) generator(제너레이터)Container(컨테이너)컨테이너(container)란 임의의 객체를 담을 수 있는 파이썬 객체를 말합니다. 아시다시피 파이썬의 모든 것은 객체이죠. int, float, str, 심지어 function도 객체입니다. 이러한 객체 중에서 다른 객체들을 담을 수 있는 객체, 즉 컨테이너는 다음 같은 것들이 있습니다. list tuple str set dictionary …좀 더 practical 하게는 membership 테스트를 수행할 수 있는 객체라고 말하기도 합니다. membership 테스트란, x in y1와 같은 operation을 수행하는 것을 말합니다. 말이 좀 어려울 수 있는데, 아래 예시를 보시면 쉽게 이해가 가능합니다.print(&#39;a&#39; in [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]) # Trueprint(&#39;a&#39; in (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) # Trueprint(&#39;a&#39; in {&#39;a&#39;, &#39;b&#39;, &#39;c&#39;}) # Trueprint(&#39;a&#39; in {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3}) # Trueprint(&#39;a&#39; in &#39;abc&#39;) # TrueSequence(시퀀스)시퀀스(sequence)란 다음과 같은 특징을 가지는 컨테이너(container)입니다. 원소의 순서가 유지됨 정수 인덱싱을 통해 원소(element)를 꺼내올 수 있음 길이가 있음시퀀스의 예시는 다음과 같습니다. list tuple str …헷갈릴만한 점은 모든 컨테이너가 시퀀스가 되지는 않는다는 것입니다. 예를 들어서 set은 대표적인 컨테이너지만 원소의 순서가 보장되지 않고, 정수 인덱싱을 지원하지 않습니다.Iterable(이터러블)iterable은 원소를 한번에 하나씩 반환할 수 있는 객체입니다. 모든 sequence와 일부 non-sequence가 해당됩니다. Sequence list tuple str Non-sequence dictionary 일반적으로 iteralble에는 __iter__2와 __getitem__3 매직 메소드가 구현되어 있습니다. iterable과 가장 헷갈리는 개념이 iterator인데요. iterable은 말 그대로 원소를 반환할 수 있는 또는 반환할 능력을 가지고 있는 객체를 뜻합니다. 이 말은 iterable이 실제로 원소를 반환하는 행위를 할 수 있다는 것을 의미하지는 않죠. 미묘하지만 iterator와의 큰 차이점입니다.그렇다면 iterable이라고 해서 반드시 iterator라고 할 수 있을까요 🤔?? 답은 ‘아니오’ 입니다 🙅‍♀️. 가장 대표적인 iterable로 list가 있는데, 여러분들께서 잘 아시다시피 list 자체는 원소를 반환하지 못합니다.li = [1, 2, 3]print(next(li)) # TypeError: &#39;list&#39; object is not an iterator오류 내용을 보면 list는 iterator가 아니라고 합니다. 따라서 list에 담긴 원소를 바로 꺼내오지는 못하는 것이죠. iterable 이라고 해서 iterator라고 할 수 없다는 사실을 확인 할 수 있습니다.이런 의문이 생기실 수도 있을 것 같습니다. for loop에 넣으면 바로 원소를 꺼내올 수 있지 않나요 🙋‍♀️? for loop에 어떤 객체를 태우면 이를 내부적으로 iterator로 변환해서 사용합니다. 결국 원소를 하나씩 꺼내오려면 iterable이 아니라 iterator가 필요한 것이죠.Itertator(이터레이터)iterator란 순차적으로 원소를 하나씩 꺼내올 수 있는 객체를 뜻합니다. 실제로 원소를 꺼내올 때는 next() 메소드를 이용해서 원소를 하나씩 꺼내옵니다. 만약 더이상 꺼내올 데이터가 없다면 StopIteration 에러를 발생시킵니다. iterable 컨테이너는 __iter__() 매직 메소드를 통해 iterator가 될 수 있습니다. iterator가 되었을 때 비로소 원소를 하나씩 꺼내오는 행위를 할 수 있게 됩니다.iterable 객체인 list는 그 자체로는 원소를 하나씩 꺼내오지 못하는데요. iterator로 변환하면 가능합니다.li = [1, 2, 3]iterator = iter(li)print(type(iterator)) # &amp;lt;type &#39;list_iterator&#39;&amp;gt;print(next(iterator)) # 1파이썬의 모든 것은 객체입니다. 그리고 그 객체에 매직메서드를 정의하면 파이썬의 규칙에 따라 잘 작동하는 커스텀 객체를 구현할 수 있는데요. iterator를 클래스를 통해 직접 만들 수 있습니다. __iter__()4 메서드와 __next__() 메서드만 구현되어 있으면 돼요.다음은 start 부터 stop-1까지 숫자를 1씩 증가시키면서 제곱수를 리턴하는 iterator의 예시입니다.class Squares: def __init__(self, start, stop): self.start = start self.stop = stop def __iter__(self): return self def __next__(self): if self.start &amp;gt;= self.stop: raise StopIteration current = self.start * self.start self.start += 1 return currentiterator = Squares(2, 5)print(next(iterator)) # 4print(next(iterator)) # 9print(next(iterator)) # 16print(next(iterator)) # StopIteration간단한 연산을 하는 것인데, 코드가 생각보다 길죠? 좀 더 간단하게 할 수 없을까요?? 미리 정답을 알려드리자면 🤫 generator를 활용하면 됩니다.Generator(제너레이터)generator는 iterator의 특성을 모두 가지고 있으면서, yield statement로 작성된 객체입니다. 따라서 generator는 특수한 형태의 iterator 라고 할 수 있습니다. generator와 iterator 모두 container에 담긴 원소를 하나씩 꺼내올 수 있는 객체라는 점에서는 공통점을 가지고 있습니다. 그러나 generator가 iterator와 구분되는 다음과 같은 특성이 있습니다. 함수 내에 yield statement이 존재합니다. 호출 되면 yield 까지 코드를 실행하고 멈춥니다. 다음 번에 호출될 때는 이전 yield 부터 다음 yield까지 코드를 실행합니다. 이러한 작업을 StopIteration 에러가 발생할 때까지 진행합니다. lazy implementation으로서 generator가 호출되었을 때 리소스를 할당합니다. 생성 되었을 때 리소스를 할당하지 않습니다.generator를 사용하면 iterator 섹션에서 살펴 보았던 제곱수를 리턴하는 함수를 다음과 같이 훨씬 간결하게 만들 수 있습니다.def squares(start, stop): for i in range(start, stop): yield i**2generator = squares(2, 5)print(type(generator)) # &amp;lt;class &#39;generator&#39;&amp;gt;print(next(generator)) # 4print(next(generator)) # 9print(next(generator)) # 16print(next(generator)) # StopIterationgenerator는 iterator의 특성을 모두 가지고 있기 때문에 gerator는 iterator라고 할 수 있습니다. 그러나 그 반대는 성립하지 않습니다.Reference [Document] Python glossary: sequence [Document] Python glossary: iterable [Document] Python glossary: iterator [Document] 파이썬 데이터 모델: __contains__() [Document] 파이썬 데이터 모델: __iter__() [Document] 파이썬 데이터 모델: __getitem__() [Blog] 실용 파이썬 프로그래밍: 프로그래밍 유경험자를 위한 강좌 - 시퀀스 [Blog] python iterable과 iterator의 의미 [Blog] Python - 시퀀스 자료형 [Blog] Iterables vs. Iterators vs. Generators [Blog] Python - Difference between iterable and iterator [Blog] Python Generators: Memory-efficient programming tool [Stackoverflow] What exactly are “containers” in python? (And what are all the python container types?) [Stackoverflow] Difference between Python’s Generators and Iterators [Stackoverflow] Generator function (yield) much faster then iterator class (next) [Stackoverflow] What does the “yield” keyword do?Footnote x in y operation은 객체에 __contains__ 매직 메서드가 구현되어 있기 때문에 가능합니다(참고). &amp;#8617; 원소를 하나씩 호출할 수 있는 iterator를 반환하는 매직 메서드입니다(참고). &amp;#8617; self[key]의 값을 구하기 위해 호출되는 매직 메서드입니다(참고). &amp;#8617; 자기 자신을 return 합니다. for 나 in statement에서 활용됩니다(참고). &amp;#8617; " }, { "title": "파이썬 상대 경로 임포트시 에러", "url": "/posts/Python_relative_import_error/", "categories": "Python, Debug", "tags": "python, relative-import, debug", "date": "2021-09-21 16:49:00 +0900", "snippet": "최근에 딥러닝 코드를 리팩토링 하면서 프로젝트의 폴더 구조를 변경하는 작업을 진행하였습니다. 이 과정에서 모듈을 임포트 할 때 상대 경로를 활용하였는데요. 직관과 다르게 에러가 발생하였습니다. 파이썬에서 모듈 임포트 방법을 정리하면서 문제를 해결한 사례를 공유 합니다.프로젝트 구조먼저 문제가 발생한 프로젝트 구조를 재현해 보겠습니다.폴더 구조/example/ │├── network/ │   └── model.py├── utils/ │   └── serving.py└── train.pynetwork/model.pyfrom ..utils.serving import serve_funcclass Model: def train(self): return &quot;Train Model&quot;utils/serving.pydef serve_func(): return &quot;This is servce func&quot;train.pyfrom network.model import Modelmodel = Model()model.train()문제 상황위와 같은 프로젝트 구조에서 train.py를 실행시키면 다음과 같은 에러가 발생합니다.Attempted relative import beyond top-level package일단 에러의 내용을 해석하기 전에 저의 사고 과정을 보겠습니다. train.py를 실행하게 되면 network/model.py에 있는 클래스를 가져옵니다. 이때 network/model.py에 적힌 코드를 차례대로 실행합니다. network/model.py의 첫줄에 상대 경로를 활용해서 utils/serving.py 모듈에 있는 함수를 불러오는 군요. from ..utils.serving import serve_func network/model.py와 utils/serving.py는 sibling 관계입니다. 따라서 network/model.py 기준으로 부모 패키지로 한 단계 거슬러 올라가면 sibling 모듈인 utils/serving.py를 찾을 수 있을 것 같군요. 그런데 에러 발생!!애석하게도 직관에 반하여 에러가 발생하고 말았습니다. 에러 내용은 상대 경로 임포트를 활용할 때 파이썬 인터프리터가 인지 하고 있는 부모 패키지의 level을 넘어서 더 상위 부모 패키지를 찾으려고 해서 발생 한 것입니다. 자세한 내용을 차차 알아 봅시다.문제 원인이러한 에러가 발생한 이유는 파이썬에서 절대경로/상대경로 모듈 임포트의 동작 원리를 정확히 파악하지 못했기 때문입니다. 파이썬에서는 절대 경로 모듈 임포트와 상대 경로 모듈 임포트의 동작 방식에 큰 차이가 있습니다. 그 차이를 알아보겠습니다.절대 경로 임포트절대 경로로 모듈을 임포트 할 때는 sys.path에 등록된 경로에서 모듈을 찾습니다. sys.path에는 기본적으로 여러가지 경로가 리스트 형식으로 등록되어 있는데요. 중요한 점은 sys.path의 첫번째 경로는 항상 실행된 파이썬 스크립트가 속한 폴더의 절대 경로라는 것입니다. path[0] is the directory containing the script that was used to invoke the Python interpreter.예를들어, train.py에서 print(sys.path) 명령어를 실행하면 다음과 같은 결과를 얻을 수 있습니다.[&quot;/example&quot;, ...]train.py 스크립트가 속한 폴더의 절대 경로가 존재함을 알 수 있습니다.상대 경로 임포트상대 경로로 모듈을 임포트 할 때는 __name__ 변수에 담긴 값을 통해 패키지의 계층 구조를 확인 합니다. 모두 잘 아시다시피 파이썬 스크립트 파일(.py)은 직접 실행할 수도 있고, 모듈로서 다른 파이썬 스크립트에서 실행될 수도 있습니다.__name__은 에 담긴 값은 파이썬 스크립트가 어떻게 실행되느냐에 따라 달라집니다. 예를 들어서 파이썬 스크립트가 직접 실행되면 __name__에는 __main__이라는 값이 할당됩니다. 한편 다른 모듈에서 임포트되어 실행되면 package.module과 같이 모듈이 속한 패키지의 계층 구조를 알려주는 값이 할당 됩니다.예를 들어 network/model.py에 print(__name__)를 넣어서 train.py를 실행시켜 보면, network/model.py은 다음의 결과를 리턴합니다.&#39;network.model&#39;정리해보면, network/model.py는 train.py에서 모듈로서 임포트 되었는데요. 이 때 파이썬은 __name__에 담긴 값을 통해 model.py의 부모 패키지가 network임을 알아 낼 수 있는 것입니다.마지막으로 상대 경로 임포트는 파이썬 스크립트가 모듈로 실행되었을 때만 활용할 수 있다는 사실을 알 수 있습니다. 왜냐하면 직접 실행 되었을 때는 __name__에 __main__이라는 스트링이 할당되는데, 저 값을 통해서는 모듈이 속한 패키지의 계층 구조를 전혀 알 수 없기 때문입니다.원인 파악자, 우리는 이제 모듈이 절대 경로로 임포트 될 때와 상대 경로로 임포트 될 때의 차이를 명확히 알았습니다. 절대 경로 임포트는 sys.path에 할당된 경로에서 모듈을 찾는 다는 점이 중요했습니다. 한편 상대 경로 임포트는 __name__에 담긴 값을 통해 모듈이 속한 패키지의 계층 구조를 알 수 있어야 한다는 점이 중요했습니다.다시 에러 내용을 살펴봅시다.Attempted relative import beyond top-level package모듈을 상대 경로로 임포트 했는데, 파이썬 인터프리터가 인지하고 있는 계층 구조를 넘어서는 top-level로 거슬러 올라갔다는 에러 내용입니다.에러를 일으킨 직접적인 코드는 network/model.py의 from ..utils.serving import serve_func입니다. network/model.py가 모듈로서 실행될 때 __name__에는 network/model이라는 값이 담겨 있습니다. 그런데 저 코드는 network라는 패키지보다 더 상위의 패키지를 찾으려고 시도합니다. 그러나 파이썬 인터프리터는 network보다 더 상위의 패키지가 무엇인지를 __name__ 에 담긴 값으로는 전혀 알 수가 없습니다. 따라서 에러가 발생한 것입니다. 이제 해결책을 알아볼까요?해결 방안해결 방법은 매우 다양한데요. 저는 개인적으로 절대 경로 임포트를 활용하는 방법이 가장 깔끔하다고 생각하였습니다. 이 방법은 파이썬 스크립트에 다른 코드를 덕지덕지 붙일 필요가 없습니다. 또한 가독성 측면에서도 가장 우수하다고 판단했습니다. network/model.py의 내용을 다음과 같이 간단하게 수정하면 됩니다.여기서from ..utils.serving import serve_func이렇게 말이죠.from utils.serving import serve_func왜 정상 실행되는지 알아야겠죠? 계속 말씀 드린 것처럼 절대 경로 임포트시에는 sys.path에 등록된 경로에서 모듈을 찾습니다. train.py 실행하면 sys.path에 train.py가 속한 폴더의 절대경로(/example/)가 등록되어 있습니다. 따라서 파이썬 인터프리터는/example/ 경로에서 utils/serving.py를 충분히 찾을 수 있기 때문에 에러가 나지 않고 정상 실행 되는 것입니다.Reference sys.path, PYTHONPATH: 파이썬 파일 탐색 경로 Relative imports for the billionth time python import from sibling folder 파이썬 자습서 6.4 패키지 [Python] Python 3의 상대경로 import 문제 피해가기 Relative imports in Python 3 PEP 328 – Imports: Multi-Line and Absolute/Relative" }, { "title": "Bastion에서 internet-facing ALB로 요청을 보내고 응답 받기", "url": "/posts/Bastion_ALB/", "categories": "MLOps, AWS ECS", "tags": "mlops, aws, ecs, cpu, meory", "date": "2021-06-20 10:14:00 +0900", "snippet": "Bastion에서 ELB로 요청을 보내고 응답 받기 Keyword security group(보안 그룹), security group chaining, ELB(Elastic Load Balancer)같은 AWS VPC 내부 존재하는 public ip를 가진 bastion에서 internet-facing ALB에 HTTP request를 보내서 응답을 받는 방법을 알아보려고 합니다. 사실 이 부분을 매우 쉽게 생각 했는데 생각 했던대로 요청이 오지 않아서 조금 당황하였습니다. 그래서 여러가지 문서를 찾아보고 security group chaining에 대해 제가 오해하고 있던 부분이 있었다는 것을 알게 되었습니다. 따라서 기본기를 잊지 말자라는 생각에 글을 정리해봅니다.Bastion에서 ELB로 HTTP request를 시도!회사에서 업무를 하면서 개발 환경에서 머신러닝 모델 API에 응답 테스트를 해야할 일이 있었습니다. 개발 환경을 간략화 하면 다음과 같습니다. 같은 VPC 내부에 public ip를 가진 bastion과 public ip를 가진 ELB가 있습니다. 저는 bastion에서 ELB로 특정 형태의 request를 보냈고, 당연히 정상적인 응답이 돌아 올 것을 기대했습니다.어? 왜 time out error가 뜨지? 아… 보안 그룹 설정!그러나 request가 ELB에 도달하지 못하고 time out error가 발생했습니다. 잠깐 생각해보니 ELB 보안 그룹에 bastion이 없었습니다. 잠깐의 실수를 반영하고 얼른 ELB의 보안 그룹을 다음과 같이 수정하였습니다.이때 security group chaining을 활용하였습니다. security group chaining은 보안 그룹의 source로 보안 그룹을 활용하는 방법인데요. 이는 source 보안 그룹이 할당된 instance의 ip를 허용하는 편리한 방법입니다. Allow inbound traffic from network interfaces (and their associated instances) that are assigned to the same security group.Bastion instance의 ip를 허용해 주었으므로 당연히 정상 응답을 받을 수 있을 것이라고 기대했습니다.그런데 또 time out error…분명히 보안 그룹까지 뚫었는데 왜 time out error가 발생할까요? 해결 방법은 생각보다 간단했습니다. security group chaining을 제가 잘못 이해하고 있었습니다. AWS의 security group document의 Security group rules 섹션을 보면 다음과 같은 문장이 등장합니다. When you specify a security group as the source for a rule, traffic is allowed from the network interfaces that are associated with the source security group for the specified protocol and port. Incoming traffic is allowed based on the private IP addresses of the network interfaces that are associated with the source security group (and not the public IP or Elastic IP addresses).정리하면, security group을 source로 사용하는 security group chaing은 해당 security group이 할당된 인스턴스의 private ip의 traffic을 허용하는 것이지 public ip의 traffic을 허용하는 것이 아니라는 것입니다. bastion은 public subnet에 배치되어 있으므로 public ip를 가지게 되는데요. 제가 bastion에서 ELB에 HTTP request를 보내는 것은 출발지의 ip가 bastion의 public ip가 되고, 목적지의 ip는 ELB의 public ip가 되는 것입니다. 따라서 ELB는 bastion의 public ip의 traffic을 허용하도록 보안 그룹을 작성해야 request에 대한 정상적인 응답을 받을 수 있습니다.다음과 같이 ELB의 보안 그룹을 수정하면 됩니다.Reference Security groups for your VPC" }, { "title": "ECS의 task definition에서 soft/hard memory limit의 의미", "url": "/posts/How-Amazon-ECS-manages-CPU-and-memory-resources/", "categories": "MLOps, AWS ECS", "tags": "mlops, aws, ecs, cpu, meory", "date": "2021-06-20 10:14:00 +0900", "snippet": " 본 포스트는 How Amazon ECS manages CPU and memory resources라는 글의 도움을 가장 많이 받았습니다. 본 포스트에 정리된 내용 보다 더 자세한 내용을 알고 싶으시면 해당 글을 참고해주세요.최근 ECS를 다루면서 task definition을 정의할 때 container의 memory resource를 설정해야하는 일이 있었습니다. 이때 아래 그림과 같이의 container의 memory limit 설정을 해야 했는데요. document를 읽어봐도 정확히 어떤 의미인지 이해하기 어려웠습니다. 따라서 관련된 내용을 찾아보았고 task의 lauch type에 따라서 다른 의미를 가지게 된다는 것을 알게 되었습니다. 저희 팀에서는 인프라 관리하는 일에 최대한 신경을 덜 쓰기 위해 container instance로 Fargate를 선택하였는데요. 따라서 본 포스트에서는 Fargate lauch type을 선택했을 때 memory limit 설정에서 soft limit와 hard limit가 가지는 의미를 중점적으로 살펴보겠습니다.참고로 본 포스트는 docker container와 AWS ECS에 대한 기본적인 개념을 알고 있다는 가정에서 작성되었습니다. 틀린 설명이 있다면 지적해 주시면 감사 하겠습니다.ECS Document를 먼저 보자가장 먼저 task definition의 parameter가 설명되어 있는 document를 살펴봅시다. Container Definitions의 memory와 memoryReservation 부분의 설명을 보면 다음과 같이 설명되어 있습니다. memory The amount (in MiB) of memory to present to the container. If your container attempts to exceed the memory specified here, the container is killed. memoryReservation The soft limit (in MiB) of memory to reserve for the container. When system memory is under contention, Docker attempts to keep the container memory to this soft limitmemory 파라미터는 container가 쓸 수 있는 메모리의 총량을 설정하는 것이고, container가 설정된 용량을 넘어서 메모리를 사용하려고 시도하면 컨테이너가 죽는다고 하네요. 음… 이정도면 어느 정도는 이해가 되는 것 같습니다. 컨테이너는 container instance를 기반으로 띄워지는 process인데 해당 process가 활용할 수 있는 메모리의 총량을 제한하는 것이군요.그런데 memoryReservation 파라미터의 설명을 보면 한번에 이해가 가지는 않습니다. 일단 정의를 잃어보면, 컨테이너를 위해 예약된(reserve) 메모리의 soft limit라고 하네요. 이 말도 이해가 잘 안가고… 또 시스템 메모리가 경쟁 상태에 있으면 도커 데몬이 설정된 soft limit 만큼의 메모리를 컨테이너를 위해 keep을 한다고 합니다. 일단 전반적으로 어떤 말인지 잘 이해가 가지 않습니다. 그리고 메모리를 예약(reserve) 한다는 개념도 생소하고, 이 것이 왜 필요한지 모르겠네요. 배경 설명이 필요할 것 같습니다.General rules of thumb with containers먼저 도커 컨테이너가 호스트의 리소스와 어떻게 상호 작용하는 지에 대해 간단히 정리해봅시다. 도커 컨테이너는 프로세스입니다. 다시 말해, 도커 컨테이너는 호스트에 떠 있는 여러 프로세스 중 하나일 뿐입니다. 프로세스들은 호스트의 cpu, memory, 기타 자원을 공유(share)합니다. 특별한 이유가 없다면, 일반적으로 컨테이너는 호스트의 모든 cpu 및 메모리 자원에 접근하고 이를 활용할 수 있습니다. 특별한 이유가 없다면, 같은 호스트에 떠 있는 컨테이너들은 호스트의 CPU, memory, 기타 자원들을 공유합니다. 이는 호스트에 떠 있는 프로세스들이 자원을 공유하고 있는 것과 같은 이치입니다.사실 위의 설명은 컨테이너만이 가지는 특성이라기 보다는 리눅스 프로세스들의 일반적인 특성입니다.ECS resource management optionsECS에서 리소스와 관련된 설정은 크게 두 가지로 구분할 수 있습니다. Task &amp;gt; Host task가 host의 리소스를 얼마나 예약해 둘 수 있으며 활용 가능한 리소스의 최대치를 얼마나 둘지에 대한 설정입니다. launch type이 EC2일 때만 설정할 수 있습니다. 본 포스트에서 다루지 않습니다. Container &amp;gt; Task Task 내부의 container가 Task의 리소스를 얼마나 예약해 둘 수 있으며, 활용 가능한 리소스의 최대치를 얼마나 둘지에 대한 설정입니다. launch type이 EC2일 때와 Fargate일 때 모두 설정할 수 있습니다. 본 포스트에서 다루는 부분입니다. 이와 같은 리소스에 관한 설정은 아래와 같이 task definition에서 정의됩니다.{ &quot;containerDefinitions&quot;: [ { &quot;cpu&quot;: 0, &quot;memory&quot;: null, &quot;memoryReservation&quot;: 1024, } ], &quot;cpu&quot;: &quot;1024&quot;, &quot;memory&quot;: &quot;2048&quot;, &quot;compatibilities&quot;: [ &quot;EC2&quot;, &quot;FARGATE&quot; ],}그렇다면 리소스를 예약하는 것이 무슨 의미를 가지며 왜 필요한 걸까요? General rules of thumb with containers 섹션에서 언급한 것처럼 하나의 호스트에는 여러 개의 프로세스가 떠 있으며 해당 프로세스들은 호스트의 리소스를 공유합니다.리소스를 공유한다는 것은 해당 리소스를 활용하는 대상들(e.g., 컨테이너) 사이에 자원에 대한 경쟁(contend)이 발생할 수 있다는 것을 의미합니다. 만일 ECS에 올려서 배포하려는 어플리케이션이 다른 프로세스들과의 리소스 경쟁에서 밀린다면 해당 어플리케이션 기반의 서비스가 제대로 작동할 수 있을까요? 당연하게도 해당 애플리케이션은 제대로 동작하지 않을 것이고 이러한 서비스는 고객들의 불편함을 초래할 것입니다.만일 서비스를 제공하는 컨테이너만이 활용할 수 있도록 미리 리소스를 예약(reservation) 해두면 어떨까요? 예약된 리소스는 해당 컨테이너만 활용할 수 있기 때문에 리소스 경쟁 때문에 애플리케이션이 실패하는 일을 미연에 방지할 수 있을 것입니다. Reservations are effectively telling ECS that “this specific containers needs this much memory and this much CPU”Soft Memory Limit vs Hard Memory Limitcontainer instance로 Fargate를 선택한 경우, task가 host의 자원을 어떻게 활용할지에 대한 설정은 필요가 없습니다. EC2 launch type은 하나의 EC2에 복수 개의 task를 올릴 수 있고 각 task에는 복수 개의 컨테이너를 올릴 수 있습니다. 따라서 task를 만들 때 EC2 launch type을 선택하면 task가 호스트의 자원을 활용하는 설정와 container가 task의 자원을 활용하는 설정, 두 가지가 모두 필요합니다.그러나 Fargate launch type은 각자가 완벽하게 분리되어 있기 때문에 각 task는 서로 간에 CPU나 메모리 등의 자원을 절대 공유하지 않습니다. 따라서 container가 task의 자원을 활용하는 것과 관련된 설정만 진행하면 됩니다. Each Fargate task has its own isolation boundary and does not share the underlying kernel, CPU resources, memory resources, or elastic network interface with another task.task definition의 containerDefinitions에 memoryReservation 필드가 예약 메모리와 관련된 설정입니다. 그리고 우리가 서두에서 보았던 memory의 soft limit는 사실 memoryReservation 필드에 들어갈 value를 정하는 것이었습니다. 한편 컨테이너가 활용할 수 있는 리소스의 최대치도 정할 수 있습니다. 이것이 바로 memory의 hard limit 설정이며, 해당 컨테이너가 hard limit를 초과하는 메모리를 사용하게 되면 해당 컨테이너는 죽게 됩니다. hard limit는 task definition에서 memory라는 필드명으로 등록됩니다. Hard and soft limits correspond to the memory and memoryReservation parameters, respectively, in task definitions.memory의 soft limit와 hard limit는 둘 다 선택할 수 있거나 둘 중 하나만 선택할 수도 있습니다. 각각의 경우에는 다음과 같은 의미를 가집니다. soft limit만 설정 예약(reservation) 메모리: specified soft limit value 최대(ceiling) 메모리: specified task memory size soft limit와 hard limit 둘 다 설정 예약(reservation): specified soft limit value 최대(ceiling): specified hard limit value hard limit만 설정 예약(reservation): specified hard limit value 최대(ceiling): specified hard limit value 마지막으로 soft limit와 hard limit 둘 다 설정 했을 때의 예시를 통해 soft limit와 hard limit의 동작 원리를 이해해 봅시다. soft limit(memoryReservation): 256MBhard limit(memory): 512MB위와 같은 경우에는 컨테이너에 기본적으로 256MB의 메모리가 할당(예약)됩니다. 물론 예약된 메모리를 100% 다 활용하지 않을 수도 있습니다. 그러나 만일 메모리 사용량이 512MB를 넘어서게 되면 해당 컨테이너는 자동으로 종료됩니다.Summary우리는 AWS document에 memory 및 memoryReservation 파라미터를 이해 해보려고 노력하는 것에서 이야기를 시작해보았습니다. 이해가 가는 부분도 있고, 배경 지식이 없으면 이해되지 않는 부분도 있었죠. 특히 메모리 “예약”이라는 개념을 이해하기 위한 설명이 주를 이루었습니다. 도커 컨테이너에 대한 일반적인 이야기와 ECS에서 리소스를 관리하는 여러가지 설정에 대한 이야기도 했습니다. 이를 통해서 메모리 예약이 왜 필요하고 ECS에서 어떤 파라미터가 이와 관련된 설정을 지정할 수 있는지에 대해서도 배웠습니다. 여기까지 글을 정독 하셨다면 ECS document에 적혀 있는 memory 및 memoryReservation 부분을 무리 없이 이해하실 수 있을 것 같습니다. 혹시 잘못된 설명이 있었다면 지적 부탁드립니다.References How Amazon ECS manages CPU and memory resources Task definition parameters - container definition Amazon ECS on AWS Fargate Amazon ECS CloudWatch metrics Amazon ECS on AWS Fargate Container Instance Memory Management 도커 컨테이너는 가상머신인가요? 프로세스인가요?" }, { "title": "글또 5기 회고글", "url": "/posts/retrospective/", "categories": "ETC, Retrospective", "tags": "retrospective", "date": "2021-04-30 17:31:00 +0900", "snippet": "반년이 정말 후딱 지나가 버렸다..정말 반년이 이렇게 빨리 지나갈 줄은 몰랐습니다. 회사 동료의 추천으로 우연히 글또 5기를 신청하게 되었고 덜컥 참여하게 되었습니다. 나름 열심히 활동을 하며 정말 열심히 사시는 분들과 엄청난 실력을 가지고 계신 분들을 많이 만났고, 제가 쓴 글에 비판도 많이 받았던 것 같습니다. 정말 좋은 경험이었습니다.글을 쓰는 것은 정말 어려운 과정이었습니다. 한 주의 피드백이 끝나면 2주 뒤에 스스로 만족할만한 양질의 글을 쓰기 위해 매일 저녁 시간을 할애해서 노력을 했습니다. 일주일 정도 공부를 해서 어떤 구성으로 글을 작성할지 큰 틀을 잡고, 나머지 일주일 동안은 속을 채우기 위해 좀 더 디테일한 부분에 집중 했습니다. 웬만하면 금요일 정도에 글을 마무리 하려고 노력은 했는데, 아직 많이 부족한 터라 주말까지는 붙잡고 있어야 스스로에게 70% 정도 만족할만한 글을 쓸 수 있었습니다. 돌이켜 보면 결국 스스로에게 100% 만족하는 글을 쓰지는 못했던 것 같습니다.글을 작성하면서 다른 분들이 내가 쓴 글을 볼 수도 있다고 생각하니, 한 문장을 작성하기 위해 정말 많은 레퍼런스를 찾아봤던 글도 있었습니다. 이런 경험들이 데이터 사이언티스트로서 성장에 큰 도움이 될 것이라고 믿어 의심치 않습니다. 특히 지난 반년 동안 스스로에게 부족했었던 수학 이론 공부를 많이 했고 반년 전의 저에 비해서는 성장했다라는 생각이 들어서 나름 뿌듯한 마음이 많이 듭니다. 하지만 100% 소화를 했다고는 생각하지 않습니다. 앞으로도 꾸준한 노력이 필요할 것 같습니다.다짐했던 것들은 얼마나 지켜졌나?글또 5기를 시작하면서 쓴 다짐 글을 다시 한번 보았습니다. 정말 열의 넘치는… 제 자신을 발견 할 수 있었습니다. 그리고 반년 전의 내가 오늘의 나를 보았을 때 과연 만족을 할 수 있을지를 생각해 보았습니다. 개인적으로 평가해본다면 다짐 했던 것에 70% 정도는 이루었다고 생각합니다. 선형대수 이론 공부를 진행 했고, 행렬 분해와 관련된 이론들을 글로 녹여 내었습니다. 특히 고유값과 고유벡터는 제가 계속 명확하게 이해하지 못하고 있었는데, 이번에 글또 활동을 하면서 작성 했던 선형 대수 이론이 모두 고유값과 고유벡터와 관련이 있다보니 반년 전 보다는 이에 대해 감을 잡은 것 같습니다. 다만 머신러닝/딥러닝 관련 논문은 많이 정리하지 못했습니다. 글또 5기 활동을 시작하는 시점부터 현업에서 수행하는 역할이 그 전과는 조금 달라져서… 논문을 읽고 정리하는 글을 ALS 말고는 없었던 것 같네요.요새는 어떻게 살고 있고 앞으로는 어떻게 살까?최근에 현업에서 관심 사항과 요구 사항이 또 많이 달라졌습니다. 이제는 머신러닝/딥러닝 모델의 배포 관리, 실험 관리를 잘 해야할 시점이 왔는데요. 그렇게 때문에 최근에는 오히려 엔지니어링 쪽에 관심을 두고 공부하고 있습니다. 앞으로는 컨테이너 오케스트레이션, 머신러닝 실험 관리, A/B 테스트 환경 구축과 관련된 이론이나 실습을 계속 진행하게 될 것 같습니다. 이런 분야 공부는 처음이라 어떤 이론들이 기반이 되어야 할지는 정확히 모르겠지만, 일단은 AWS나 GCP에서 제공하는 여러가지 서비스들을 잘 활용하는 식으로 진행할 것 같습니다(아직까지 오픈 소스 툴을 이용해서 직접 환경을 구축하는 것은 무리 일 것 같네요). 그래서 최근에는 네트워크 공부를 하고 있었고 컨테이너 오케스트레이션을 위해 AWS ECS 서비스를 공부하고 있습니다.그래도 다행인 것은 새로운 공부를 하는 것이 재미있다는 것입니다. 그래서 앞으로는 지금 공부하는 쪽을 계속해서 발전 시켜서 내 손으로 만든 모델을 지속적으로 실험하고, 배포하고, A/B 테스트 하는 것까지의 모델 라이프 사이클을 모두 관리할 수 있는 데이터 사이언티스트가 되는 것이 목표입니다. 아직까지는 이 것이 얼마나 어려운 일인지 감이 안 잡히는데, 감이 없다는 것은 제가 아직 초보적인 수준이라는 방증이겠죠.아무튼 같이 글또 5기 활동을 하신 모든 분들께 감사드리고 앞으로 계획 하시는 일들이나 하고 계신 일들이 모두 좋은 결과로서 결실을 맺기를 기원하겠습니다." }, { "title": "&#39;Collaborative Filtering for Implicit Feedback Datasets(ALS)&#39; 논문 리뷰", "url": "/posts/ALS/", "categories": "ML, Paper Review", "tags": "als", "date": "2021-03-30 22:31:00 +0900", "snippet": "ALS는 행렬 분해를 활용한 대표적인 추천 알고리즘입니다.추천 시스템을 구축하기 위한 첫 출발점으로는 matrix factorization에 기반을 둔 모델을 많이 활용합니다. 그 이유는 단일 모델로서 성능도 좋고, 무엇보다 데이터 파이프라인이 간단하고 서빙이 편리하기 때문이라고 생각합니다. matrix factorization 기법을 활용한 추천 모델은 매우 다양한데요. 대표적으로 SVD, SGD, ALS 등을 꼽을 수 있을 것 같습니다. 본 글에서는 ALS를 소개한 논문을 정리하고, 본 논문에서는 생략되어 있는 수식 유도 과정을 추가로 정리 하고자 합니다. 논문의 제목은 “Collaborative Filtering for Implicit Feedback Datasets” 입니다. 제목에서도 유추가 가능하지만 implicit data에 matrix factorization 기법을 어떻게 적용할지에 대한 간단한 아이디어를 제안한 논문입니다.본 글에서 행렬과 벡터의 표기는 다음을 따릅니다. 행렬: \\(\\boldsymbol{X}\\) 벡터: \\(\\boldsymbol{x}\\) 벡터의 원소: \\(x\\)IntroductionCharacteristic of implicit data저자는 현실 세계의 문제는 대부분 implicit data로 구성되어 있으므로 implicit data를 활용한 추천 시스템 연구가 반드시 필요하다고 주장합니다. 특히 우리가 implicit data에 주목해야 하는 이유는 implicit data가 다음의 특성을 가지고 있기 때문입니다. No negative feedback explicit data는 유저가 특정 아이템을 좋아하는지(like) 싫어하는지(dislike)를 명확하게 알 수 있고, 이러한 풍부한 정보를 활용하여 추천 시스템을 모델링 할 수 있습니다. 저자의 표현을 빌리면 유저의 선호에 대한 balanced picture를 활용할 수 있다는 것입니다. 그러나 implicit data는 유저가 특정 아이템과 interaction이 있었는지 없었는지 여부만 알 수 있습니다. 예를 들어 어떤 유저가 유튜브에서 무한도전 영상을 보지 않았다면, 무한도전 영상을 싫어해서 보지 않은 것인지 그 영상의 존재 여부를 몰라서 그런 것인지를 추측하기가 어렵다는 것이죠. 또한 explicit data나 implicit data 모두 user-rating 행렬의 대부분의 값들이 missing value로서 존재합니다. 일반적으로 explicit data로 추천 시스템 모델링을 할 때는 missing value를 탈락시키고 관측된 데이터로만 모델링을 진행합니다. explicit data는 관측된 데이터 안에서도 선호 또는 비선호 정보가 모두 있기 때문에 논리적인 비약이 발생하지 않습니다. 그러나 implicit data의 경우 missing value를 탈락 시킨후 모델링을 진행하면 positive feedback 정보만 활용하여 모델링을 진행하게 되는 꼴이 되버립니다. 저자는 이를 ‘misrepresenting the full user profile’이라고 표현하였습니다. Implicit feedback is inherently noisy 우리는 유저의 implicit feedbac을 통해 정확한 유저의 선호를 알 수 없습니다. 제가 인터넷에서 코트 한벌을 구입 했다고 가정해볼게요. 물론 심사숙고 끝에 코트를 구입한 것이므로, 구매 행위는 positive feedback이라고 생각할 수도 있습니다. 그러나 만일 제가 코트를 받아보고 원단 재질에 실망 했다면 구매 행위가 negative feedback이 될 수 있는 여지도 있죠. 비슷하게 어떤 유저의 영상 시청 시간이 길다는 것이 무조건 positive feedback은 아닐 것입니다. 영상을 틀어 놓고 잠이 들었을 수도 있는 것이죠. Numerical value of implicit feedback indicates confidence explicit feedback은 유저의 preference를 나타내지만, implicit feedback은 단순히 frequency of actions를 나타냅니다. 다시 말해, implicit data에서는 특정 행위의 빈도가 높다는 것이 유저가 그 아이템을 선호한다는 것을 의미하지 않는다는 것입니다. 예를 저는 가장 좋아하는 가수가 임창정인데요. 그렇다고 해서 하루에 몇 백번씩 소주 한잔을 듣지는 않습니다. 그러나 implicit feedback의 빈도가 전혀 유용하지 않다는 의미는 아닙니다. 특정 행위가 계속해서 반복 된다는 것은 특정 유저의 opinion을 반영한다는 의미가 될 수 있습니다. 정리하자면, implicit feedback의 빈도가 높다는 것은 유저가 그 아이템을 선호한다고 단정지어 말할 수는 없지만, 적어도 선호할 것이라고 주장하는 것에 대한 신뢰도(confidence)를 높여줄 수 있습니다. Objective이러한 implicit data의 특징을 알아 두시구요. 계속해서 다음의 두가지 논의를 중점적으로 살펴보겠습니다. implicit data에서 confidence를 어떻게 계산할 것인가? \\(C_{ui}\\) 지표 제안 효율적인 추천 시스템을 어떻게 구현할까? ALS(Alternative Least Square) 제안 Latent factor collaborative filtering추천 시스템을 구현하는 방식은 매우 다양합니다. 간단하게는 아이템 자체의 정보(e.g. 상품명)만을 이용하여 유사한 아이템을 추천하는 contents-based 추천 알고리즘이 있습니다. TF-IDF나 word2vec 기반의 추천 시스템이 대표적인 예시입니다.한편 CF(collaborative filtering) 방식으로 추천 시스템을 구현할 수도 있습니다. CF는 유저와 아이템간의 interdependency를 분석하여 새로운 user-item 관계를 발견하기 위한 기법입니다. 쉽게 풀어쓰면 단순히 상품 자체의 정보만을 이용하는 것이 아니라 비슷한 다른 유저의 interaction 정보를 활용하여 유저와 아이템간의 내재된 관계를 발견해보겠다는 것입니다.당연하게도 CF 기반의 추천 시스템을 구현하는 다양한 방법이 존재합니다. 그 중에서 Netflix Prize Competition에서 우수한 성적을 거둔 matrix factorization 기반의 추천 알고리즘이 많이 활용됩니다. 다른 말로 latent factor CF라고도 불립니다. 행렬 분해를 활용한 추천 시스템의 핵심은 유저와 아이템을 특정 차원의 latent factor로 잘 임베딩하는 방법을 찾는 것입니다. 아래의 그림을 통해 조금 더 자세히 설명해볼게요.latent factor CF 알고리즘은 기본적으로 user-item 행렬 \\(\\boldsymbol{R} \\in \\mathbb{R}^{n \\times m}\\)을 유저 행렬 \\(\\boldsymbol{U}\\in \\mathbb{R}^{n \\times k}\\)와 아이템 행렬 \\(\\boldsymbol{V} \\in \\mathbb{R}^{m \\times k}\\)로 분해해서 표현하는 것입니다. 유저 행렬 \\(\\boldsymbol{U}\\)와 아이템 행렬 \\(\\boldsymbol{V}^T\\)를 곱하면 원 행렬과 똑같은 크기의 행렬로 복원할 수 있는데요. 이 행렬을 \\(\\hat{\\boldsymbol{R}} = \\boldsymbol{U}\\boldsymbol{V}^T\\)이라고 한다면 latent factor CF의 핵심은 \\(\\boldsymbol{R}\\)과 \\(\\hat{\\boldsymbol{R}}\\)의 차이를 최대한 줄이는 것이 핵심이겠죠. latent factor CF를 구현하는 대표적인 알고리즘으로 SVD, SGD, ALS 등을 들 수 있는데요. 본 논문에서는 ALS를 다룹니다.Notations앞으로의 논의에는 많은 notation이 등장하는데요. 이에 대해 정리를 하고 가는 것이 좋을 것 같습니다. 특히 논문에 행렬 notation이 매우 헷갈릴만하게 서술 되어 있기 때문에 행렬 형상을 주의해서 살펴주시길 바랍니다. \\(m\\) : 유저의 개수 \\(n\\) : 아이템의 개수 \\(f\\) : 유저와 아이템 latent vector의 차원수 \\(\\boldsymbol{X} \\in \\mathbb{R}^{m \\times f}\\) : \\(m\\)명의 유저의 latent vector \\(\\boldsymbol{x}_u\\)를 행벡터 \\(\\boldsymbol{x}_u^{T}\\)로 쌓은 유저 행렬. \\(\\boldsymbol{Y} \\in \\mathbb{R}^{n \\times f}\\) : \\(n\\)개의 아이템의 latent vector \\(\\boldsymbol{y}_i\\)를 행벡터 \\(\\boldsymbol{y}_i^{T}\\)로 쌓은 아이템 행렬. \\(\\boldsymbol{x}_u \\in \\mathbb{R}^f\\) : 유저 \\(u\\)의 latent vector (열벡터) \\(\\boldsymbol{y}_i \\in \\mathbb{R}^f\\) : 아이템 \\(i\\)의 latent vector (열벡터) \\(\\boldsymbol{p(u)} \\in \\mathbb{R}^n \\): 유저 \\(u\\)의 \\(n\\)개의 아이템에 대한 preference \\(p_{ui}\\)를 나타내는 벡터 \\(\\boldsymbol{C^u} \\in \\mathbb{R}^{n \\times n} \\): 유저 \\(u\\)의 \\(n\\)개의 아이템에 대한 confidence \\(c_{ui}\\)를 나타내는 대각 행렬 \\(r_{ui}\\) : 유저 \\(u\\)의 아이템 \\(i\\)에 대한 observations (e.g. 구매 횟수, 시청 시간) \\(\\hat{r}_{ui}\\) : 유저 \\(u\\)의 아이템 \\(i\\)에 대한 예측 observationsOur model본 논문에서 저자가 주장하는 핵심은 다음의 두가지입니다. 섹션 4에서는 계속해서 두 핵심 주장을 좀더 자세히 살펴보겠습니다. 논문에는 자세한 설명이 생략되어 있어서 저의 개인적인 의견을 덧붙여서 설명드려 보겠습니다. implicit data의 특성에 기반하여 raw observations \\(\\boldsymbol{r_{ui}}\\)를 preference \\(\\boldsymbol{p_{ui}}\\)와 confidence level \\(\\boldsymbol{c_{ui}}\\)로 변환하여 활용 global mininum으로의 수렴이 보장되는 ALS(Alternative Least Square) 알고리즘 제안preference저자는 먼저 유저 \\(u\\)가 아이템 \\(i\\)에 대해 intercation이 한번이라도 있었으면 \\(p_{ui}=1\\)로, interaction이 없었으면 \\(p_{ui}=0\\)으로 binarizing을 합니다.\\[p_{ui} = \\begin{cases} 1 &amp;amp; r_{ui}&amp;gt;0 \\\\ 0 &amp;amp; r_{ui}=0\\end{cases}\\]일단은 interaction이 있었다는 것을 유저가 아이템을 like 한다는 징후(indication)으로 가정합니다. 반대로 말하면 interaction이 없었다는 것은 유저가 해당 아이템을 선호하지 않는다고 가정하는 것이죠. 그러나 이러한 가정은 어딘가 부족해보입니다. 당장 저자가 언급하였던 implicit data의 내재적 문제를 전혀 고려하지 못한 주장이라는 생각이 듭니다. 따라서 저자는 이를 보완하고자 confidence level이라는 지표를 추가적으로 도입합니다.confidence levelconfidence level이란 \\(p_{ui}={0, 1}\\) 값의 신뢰도(confidence level)를 정량화하기 위한 지표입니다. \\(p_{ui}=0\\)인 이유는 정말 여러가지가 있을 수 있습니다. 예를 들어서 실제로 아이템 \\(i\\)가 존재한다는 것을 알고 있으면서도 해당 아이템을 선호하지 않기 때문에 interaction을 하지 않았을 수도 있습니다. 이 경우는 실제로 negative feedback이죠. 그러나 유저가 아이템 \\(i\\)의 존재를 몰랐을 수도 있으며, 아이템 \\(i\\)의 비싼 가격 때문에 선호를 함에도 불구하고 interaction을 하지 않았을 수도 있죠. 따라서 interaction이 없었다는 사실 하나만으로 선호/비선호를 이분법적으로 구분하는 것은 논리적 비약입니다. 따라서 저자는 \\(p_{ui}\\)의 confidence level를 측정하기 위한 지표를 제안합니다.\\[c_{ui} = 1 + \\alpha r_{ui}\\]먼저 이 지표를 설명하기 위한 가정 하나가 있습니다. 바로 \\(r_{ui}\\)값이 증가할수록 유저 \\(u\\)가 아이템 \\(i\\)를 더욱 강하게 선호한다는 것입니다. 단순히 interaction이 있었다면 선호, 없었다면 비선호 한다는 가정보다는 훨씬 납득할만한 가정이라고 생각합니다.이제 신뢰도 지표 \\(c_{ui}\\)를 도입한 저자의 목적을 이해해 봅시다. 신뢰도 지표 \\(c_{ui}\\)는 똑같이 \\(p_{ui}=1\\)를 가지는 user-item 쌍에 대해서도 \\(r_{ui}\\)에 따른 가중치를 달리 줄 수 있다는 점에서 중요한 지표라고 생각합니다. 예를 들어 \\(r_{ui}\\)를 유저 \\(u\\)가 아이템 \\(i\\)를 구매한 횟수라고 한다면, \\(r_{ui}=1\\)인 것에 비해 \\(r_{ui}=10000\\)인 것이 유저 \\(u\\)의 아이템 \\(i\\)에 대한 선호도가 강하다고 상식적으로 생각할 수 있습니다.그러나 \\(c_{ui}\\)를 고려하지 않는다면 \\(r_{ui}=1\\)인 것이나 \\(r_{ui}=10000\\) 모두 \\(p_{ui}=1\\)로 동일한 값을 갖게 되므로 선호의 강도의 차이를 반영하지 못하게 됩니다. 다시 \\(c_{ui}\\)를 계산하는 수식을 살펴봅시다. \\(r_{ui}\\)가 증가할수록 confidence level \\(c_{ui}\\)가 선형적으로 증가하게 됨을 확인하실 수 있습니다. 다시 말해 confidence level \\(c_{ui}\\) 지표를 도입함에 따라 ‘선호의 강도’를 구분할 수 있게 된 것입니다. 참고로 저자는 실험적으로 \\(\\alpha=40\\)이 좋았다고는 하는데, 절대적인 진리는 아니라고 생각합니다. 참고용으로만 알아두시면 될 것 같습니다.ALS이제 저자의 두번째 핵심 주장인 ALS 알고리즘에 대해 살펴보겠습니다. ALS는 matrix factorization 기반의 알고리즘인데요. 따라서 아래의 수식이 ALS 알고리즘의 최적화 목표입니다.\\[\\min_{\\boldsymbol{x}*,\\boldsymbol{y}*}\\sum_{u, i}c_{ui}(p_{ui} - \\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_{i})^{2} + \\lambda \\bigg( \\sum_{u} \\|\\boldsymbol{x}_{u}\\|^{2} + \\sum_{i} \\|\\boldsymbol{y}_{i}\\|^{2} \\bigg) \\tag{1}\\]먼저 \\(\\lambda \\big( \\sum_{u} \\|\\boldsymbol{x}_{u}\\|^{2} + \\sum_{i} \\|\\boldsymbol{y}_{i}\\|^{2} \\big)\\)는 알고리즘의 overfitting을 방지하기 위한 일반적인 regularizing term입니다. 중요한 점은 \\((1)\\) 수식은 모든 유저-아이템 쌍 \\(m \\times n\\)에 대해서 계산된다는 점입니다. 따라서 데이터 셋의 크기가 매우 크다면(\\(m \\times n\\)이 매우 큰 숫자라면) explicit data 최적화에 주로 활용되는 SGD 등의 최적화 테크닉은 잘 작동하지 않는다고 합니다. 따라서 저자는 이러한 현실적인 문제를 극복하기 위해 효율적인 최적화 테크닉인 ALS(alternative least square)를 제안합니다.ALS는 이름에서도 알 수 있듯이 번갈아가며 최적화를 진행한다는 것입니다. 무엇을 번갈아가며 최적화를 한다는 것일까요? 바로 유저 행렬 \\(\\boldsymbol{X}\\)와 아이템 행렬 \\(\\boldsymbol{Y}\\)입니다. 그렇다면 어떻게 최적화를 한다는 것일까요? 다음의 순서에 따라 최적화를 진행합니다. Step1: 아이템 행렬 \\(\\boldsymbol{Y}\\)를 상수로 고정하고, 유저 행렬 \\(\\boldsymbol{X}\\)를 최적화 Step2: 유저 행렬 \\(\\boldsymbol{X}\\)를 상수로 고정하고, 아이템 행렬 \\(\\boldsymbol{Y}\\)를 최적화 Step3: Step1과 Step2를 원하는 횟수만큼 반복이러한 방식의 최적화는 OLS에서 residual이 최소화되는 파라미터를 찾는 방법과 정확히 일치합니다. OLS는 global minum 값이 항상 보장되는 convex function이라고 합니다. 따라서 학습 프로세스가 진행됨에 따라 cost가 지속적으로 감소되는 것이 보장된다고 합니다. 사실 수식 \\((1)\\)을 최소화하는 최적의 \\(\\boldsymbol{x_u}\\)는 다음의 solution으로 결정되어 있습니다. \\(\\boldsymbol{x}_u\\)를 유도하는 수식은 Appendix에 자세히 적어 두겠습니다. 혹시 궁금하신 분들은 참고해주세요.\\[\\boldsymbol{x}_u = (\\boldsymbol{Y}^T\\boldsymbol{C}^{u}\\boldsymbol{Y}+ \\lambda\\boldsymbol{I})^{-1}\\boldsymbol{Y}^T\\boldsymbol{C}^{u}\\boldsymbol{p(u)} \\tag{2}\\]같은 방법으로 최적의 \\(\\boldsymbol{y}_i\\)의 solution을 도출할 수 있습니다.\\[\\boldsymbol{y}_i = (\\boldsymbol{X}^T\\boldsymbol{C}^{i}\\boldsymbol{X}+ \\lambda\\boldsymbol{I})^{-1}\\boldsymbol{X}^T\\boldsymbol{C}^{i}\\boldsymbol{p(i)} \\tag{3}\\]이제 우리는 최적의 \\(\\boldsymbol{x}_u\\)와 \\(\\boldsymbol{y}_i\\)를 원하는 횟수만큼 번갈아서 계산하면 되겠습니다.맺으며본 논문에서 저자의 핵심 주장은 다음의 두가지입니다. implicit data에서 preference 지표와 confidence level 지표를 도입 효율적인 행렬 최적화를 위한 ALS 제안개인적으로는 대표적인 행렬 분해 추천 알고리즘인 ALS가 따로 논문이 존재한다는 것을 처음 알게 되었는데요. 새롭고 혁신적인 주장은 의외로 간단한 아이디어에서 시작하는 것 같습니다. 특히 행렬 분해를 OLS 방식으로 해결하는 시도가 매우 인상 깊었습니다. 그러나 이 방법도 한계가 존재한다고 생각합니다. 저는 일반적인 CF 기법과 마찬가지로 다양한 feature를 반영하지 못한다는 점을 지적하고 싶습니다. 논문을 읽어 보시면 아시겠지만 TV 시청시간, 제품 구매 횟수 등 단편적인 feature만을 예시로 계속 들고 있습니다. 이러한 단점 때문에 최근에는 다양한 feature를 구성할 수 있는 FM(Factorization Machine)이나 딥러닝 기반 추천을 도입하려는 시도가 많이 이루어지는 것 같습니다. 다음 번 추천 시스템 포스팅은 FM이나 딥러닝 기반 추천 알고리즘에 대해 다뤄보려고 합니다. 긴 글 읽어 주셔서 감사합니다.AppendixStep1. \\(L\\)을 \\(\\boldsymbol{x}_u\\)로 편미분한 값을 구해봅시다.\\[\\begin{align}\\cfrac{\\partial L}{\\partial \\boldsymbol{x}_u}&amp;amp;= \\cfrac{\\partial}{\\partial \\boldsymbol{x}_u}\\bigg[\\sum_{i}c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)^2 + \\lambda \\big( \\sum_{u} \\|\\boldsymbol{x}_{u}\\|^{2} + \\sum_{i} \\|\\boldsymbol{y}_{i}\\|^{2} \\big) \\bigg] \\\\[1em]&amp;amp;= \\cfrac{\\partial}{\\partial \\boldsymbol{x}_u}\\bigg[\\sum_{i}c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)^2 \\bigg] + \\cfrac{\\partial}{\\partial \\boldsymbol{x}_u} \\bigg[\\lambda \\big( \\sum_{u} \\|\\boldsymbol{x}_{u}\\|^{2} + \\sum_{i} \\|\\boldsymbol{y}_{i}\\|^{2} \\big) \\bigg] \\\\[1em]&amp;amp;= \\begin{bmatrix}\\cfrac{\\partial}{\\partial x_{u1}}\\bigg[\\sum_{i}c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)^2 \\bigg] \\\\\\vdots\\\\\\cfrac{\\partial}{\\partial x_{uf}}\\bigg[ \\sum_{i}c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)^2 \\bigg]\\end{bmatrix} + \\cfrac{\\partial}{\\partial \\boldsymbol{x}_u} \\bigg(\\lambda \\sum_{u} \\|\\boldsymbol{x}_{u}\\|^{2} \\bigg) + \\cfrac{\\partial}{\\partial x_{u}} \\bigg(\\lambda \\sum_{i} \\|\\boldsymbol{y}_{i}\\|^{2} \\big) \\bigg) \\\\[1em]&amp;amp;= \\begin{bmatrix}\\cfrac{\\partial}{\\partial x_{u1}}\\bigg[\\sum_{i}c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)^2 \\bigg] \\\\\\vdots\\\\\\cfrac{\\partial}{\\partial x_{uf}}\\bigg[ \\sum_{i}c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)^2 \\bigg]\\end{bmatrix} + \\cfrac{\\partial}{\\partial \\boldsymbol{x}_u} \\bigg(\\lambda \\sum_{u} \\|\\boldsymbol{x}_{u}\\|^{2} \\bigg) \\\\[1em]&amp;amp;= \\begin{bmatrix}\\cfrac{\\partial}{\\partial x_{u1}}\\bigg[c_{u1}(p_{u1}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_1)^2 + \\cdots + c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)^2 + \\cdots + c_{un}(p_{un}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_n)^2 \\bigg] \\\\\\vdots\\\\\\cfrac{\\partial}{\\partial x_{uf}}\\bigg[c_{u1}(p_{u1}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_1)^2 + \\cdots + c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)^2 + \\cdots + c_{un}(p_{un}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_n)^2 \\bigg]\\end{bmatrix} + \\begin{bmatrix} \\cfrac{\\partial}{\\partial x_{u1}} \\bigg[ \\lambda(x_{u1}^2 + \\cdots + x_{uf}^2) \\bigg] \\\\\\vdots \\\\\\cfrac{\\partial}{\\partial x_{uf}}\\bigg[ \\lambda(x_{u1}^2 + \\cdots + x_{uf}^2) \\bigg]\\end{bmatrix} \\\\[1em]&amp;amp;= \\begin{bmatrix}-2c_{u1}(p_{u1}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_1)y_{11} - \\cdots -2c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)y_{i1} - \\cdots -2c_{un}(p_{un}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_n)y_{n1}\\\\\\vdots\\\\-2c_{u1}(p_{u1}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_1)y_{1f} - \\cdots -2c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_i)y_{if} - \\cdots -2c_{un}(p_{un}-\\boldsymbol{x}_{u}^{T}\\boldsymbol{y}_n)y_{nf}\\end{bmatrix} + 2\\lambda \\boldsymbol{x}_u \\\\[1em]&amp;amp;= \\begin{bmatrix} -2c_{u1}(p_{u1}-\\boldsymbol{x}_{u}^T\\boldsymbol{y}_{1})y_{11} \\\\ \\vdots \\\\-2c_{u1}(p_{u1}-\\boldsymbol{x}_{u}^T\\boldsymbol{y}_{1})y_{1f} \\end{bmatrix} + \\cdots + \\begin{bmatrix} -2c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^T\\boldsymbol{y}_{i})y_{i1} \\\\ \\vdots \\\\-2c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^T\\boldsymbol{y}_{i})y_{if} \\end{bmatrix} + \\cdots + \\begin{bmatrix} -2c_{un}(p_{un}-\\boldsymbol{x}_{u}^T\\boldsymbol{y}_{n})y_{n1} \\\\ \\vdots \\\\ -2c_{un}(p_{un}-\\boldsymbol{x}_{u}^T\\boldsymbol{y}_{n})y_{nf} \\end{bmatrix} + 2\\lambda\\boldsymbol{x}_u \\\\[1em]&amp;amp;= -2c_{u1}(p_{u1}-\\boldsymbol{x}_{u}^T \\boldsymbol{y}_{1}) \\boldsymbol{y}_{1} + \\cdots + -2c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^T \\boldsymbol{y}_{i})\\boldsymbol{y}_{i} + \\cdots + -2c_{un}(p_{un}-\\boldsymbol{x}_{u}^T \\boldsymbol{y}_{n})\\boldsymbol{y}_{n}\\\\[1em]&amp;amp;= -2\\sum_{i}c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^T\\boldsymbol{y}_i)\\boldsymbol{y}_i + 2\\lambda \\boldsymbol{x}_u\\end{align}\\]Step2. 편미분 값을 0으로 놓고 수식을 전개먼저 편미분 값 = 0으로 놓은 수식을 적어볼게요.\\[-2\\sum_{i}c_{ui}(p_{ui}-\\boldsymbol{x}_{u}^T\\boldsymbol{y}_i)\\boldsymbol{y}_i + 2\\lambda \\boldsymbol{x}_u = 0\\]\\(c_{ui}\\)를 전개해 줍니다.\\[-2\\sum_{i}(c_{ui}p_{ui}-c_{ui}\\boldsymbol{x}_{u}^T\\boldsymbol{y}_i)\\boldsymbol{y}_i + 2\\lambda \\boldsymbol{x}_u = 0\\]\\(\\boldsymbol{y_i}\\)를 전개해 줍니다.\\[-2\\sum_{i}c_{ui}p_{ui}\\boldsymbol{y}_i+2\\sum_{i}c_{ui}\\boldsymbol{x}_{u}^T\\boldsymbol{y}_i\\boldsymbol{y}_i + 2\\lambda \\boldsymbol{x}_u = 0\\]상수 \\(2\\)를 소거하고 식을 정리해 줍니다.\\[\\sum_{i}c_{ui}(\\boldsymbol{x}_{u}^T\\boldsymbol{y}_i)\\boldsymbol{y}_i +\\lambda \\boldsymbol{x}_u = \\sum_{i}c_{ui}p_{ui}\\boldsymbol{y}_i\\]\\(\\boldsymbol{x}_u^T\\boldsymbol{y}_i\\)는 상수이므로 \\(\\boldsymbol{x}_u^T\\boldsymbol{y}_i = \\boldsymbol{y}_i^T\\boldsymbol{x}_u\\)입니다.\\[\\sum_{i}c_{ui}(\\boldsymbol{y}_i^T\\boldsymbol{x}_{u})\\boldsymbol{y}_i +\\lambda \\boldsymbol{x}_u = \\sum_{i}c_{ui}p_{ui}\\boldsymbol{y}_i\\]\\(\\boldsymbol{y}_i^T\\boldsymbol{x}_u\\)는 상수이므로 \\(\\boldsymbol{y}_i\\)와 자리를 바꿔도 무방합니다.\\[\\sum_{i}c_{ui}\\boldsymbol{y}_i\\boldsymbol{y}_i^T\\boldsymbol{x}_{u} +\\lambda \\boldsymbol{x}_u = \\sum_{i}c_{ui}p_{ui}\\boldsymbol{y}_i\\]\\(\\boldsymbol{x}_u\\)를 \\(\\sum\\) 밖으로 꺼냅니다.\\[\\boldsymbol{x}_{u}\\sum_{i}c_{ui}\\boldsymbol{y}_i\\boldsymbol{y}_i^T +\\lambda \\boldsymbol{x}_u = \\sum_{i}c_{ui}p_{ui}\\boldsymbol{y}_i\\]좌항을 \\(\\boldsymbol{x}_u\\)로 묶습니다.\\[(\\sum_{i}c_{ui}\\boldsymbol{y}_i\\boldsymbol{y}_i^T +\\lambda I) \\boldsymbol{x}_u = \\sum_{i}c_{ui}p_{ui}\\boldsymbol{y}_i\\]해당 수식을 행렬 notation으로 표현하면,\\[(\\boldsymbol{Y}\\boldsymbol{C}^u\\boldsymbol{Y}+\\lambda I)\\boldsymbol{x}_u = \\boldsymbol{Y}^T\\boldsymbol{C}^u\\boldsymbol{P}(u)\\]이제 마지막으로 양변에 \\((\\boldsymbol{Y}^T\\boldsymbol{C}^u\\boldsymbol{Y} + \\lambda I)^{-1}\\)을 곱해주면 solution을 얻을 수 있습니다.\\[\\boldsymbol{x}_u = (\\boldsymbol{Y}^T\\boldsymbol{C}^u\\boldsymbol{Y} + \\lambda I)^{-1} \\boldsymbol{Y}^T \\boldsymbol{C}^u \\boldsymbol{P}(u)\\]Reference 인터넷 속의 수학 - How Does Netflix Recommend Movies? Machine Learning 스터디 (17) Recommendation System (Matrix Completion) Matrix Factorization에 대해 이해, Alternating Least Square (ALS) 이해 모두를 위한 컨벡스 최적화 Low-rank approximation Collaborative filtering for implicit feedback datasets Alternating Least Square for Implicit Dataset with code" }, { "title": "특이값 분해(Singular Value Decompostion)", "url": "/posts/SVD/", "categories": "Math, Linear algebra", "tags": "svd", "date": "2021-03-07 22:19:00 +0900", "snippet": "행렬을 직교행렬 두개와 대각행렬 하나로 분해할 수 있습니다.3줄 요약 특이값 분해(SVD)는 \\(m \\times n\\) 직사각 행렬 \\(M\\)을 직교행렬 \\(U\\), \\(V^T\\)와 고유값 행렬 \\(\\Sigma\\)로 대갹화 하는 방법입니다. 고유값 분해(EVD)는 정방 행렬에만 적용 가능한데 반해, 특이값 분해(SVD)는 직사각 행렬에도 적용가능 합니다. 데이터 압축, 노이즈 제거, 추천 시스템 등 머신러닝과 관련된 다양한 분야에서 응용되는 중요한 개념입니다.\\(m \\times n\\) 직사각 행렬을 직교 행렬 두개와 고유값 행렬로 대각화 할 수 있는 특이값 분해에 대해 알아보겠습니다. 특이값 분해는 직사각 행렬도 적용할 수 있다는 점에서 정방 행렬만을 대상으로 하는 고유값 분해에 비해 그 활용 범위가 넓다고 할 수 있습니다. 머신러닝을 공부하시는 분들이라면 한번쯤은 들어보셨을 것이라고 생각합니다. 머신러닝과 관련된 정말 여러 분야에서 활용되는 개념이므로 반드시 이해가 필요하다고 생각합니다. 특이값 분해를 이해하기 위해서는 아래의 선수 지식이 요구됩니다. 고유값과 고유벡터 대칭 행렬(symmetric matrix) 직교 행렬(orthogonal matrix)본 글에서 행렬과 벡터의 표기는 다음을 따릅니다. 행렬: \\(\\boldsymbol{X}\\) 벡터: \\(\\boldsymbol{x}\\) 벡터의 원소: \\(x\\)1   SVD(특이값 분해)란?특이값 분해(singular value decomposition)란 \\(m \\times n\\) 직사각 행렬을 아래와 같이 직교 행렬 두 개와 대각 행렬 하나로 대각화 분해하는 기법입니다.\\[\\boldsymbol{A} = \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{T} \\tag{1}\\] \\(\\boldsymbol{U}\\) : \\(m \\times m\\) 정방 행렬 \\(\\boldsymbol{\\Sigma}\\): \\(m \\times n\\) 직사각 대각 행렬 \\(\\boldsymbol{V}\\): \\(n \\times n\\) 정방 행렬 2   \\(\\boldsymbol{U}\\) 행렬\\(\\boldsymbol{U}\\)는 \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)를 고유값 분해(EVD)1하여 얻을 수 있는 고유 벡터(eigen vector)2들을 열벡터로 가지는 직교 행렬(orthogonal matrix)3입니다. \\(\\boldsymbol{U}\\)의 열벡터들은 직사각 행렬 \\(\\boldsymbol{A}\\)의 left singular vector라고 불립니다. 그렇다면 \\(\\boldsymbol{U}\\)가 어떻게 유도되는지 궁금하지 않으신가요? 대칭 행렬의 고유값 분해의 성질을 활용하면 됩니다.대칭 행렬의 고유값 분해의 성질을 안다는 가정하에, \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)를 통해서 \\(\\boldsymbol{U}\\)를 유도해 보도록 하겠습니다. \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)는 대칭 행렬이므로 항상 고유값 분해가 가능합니다 (심지어 직교 행렬로 분해가 가능). 따라서 \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)를 고유값 분해하면, 아래와 같은 형태를 가질 것이라고 생각 할 수 있습니다.\\[\\boldsymbol{A}\\boldsymbol{A}^T=\\boldsymbol{MDM}^T \\tag{2}\\] \\(\\boldsymbol{M}\\), \\(\\boldsymbol{M}^T\\): \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)의 고유벡터들을 열벡터로 가지는 직교 행렬 \\(\\boldsymbol{D}\\): \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)의 고유값들을 대각 원소로 가지는 대각 행렬그리고 위에서 언급한 \\((1)\\) 식을 활용해서 \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)를 구해 보면 다음과 같이 수식을 전개할 수 있습니다.\\[\\begin{align}\\boldsymbol{A}\\boldsymbol{A}^T&amp;amp;=\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{T}(\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{T})^T \\\\[1em]&amp;amp;=\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{T} \\boldsymbol{V} \\boldsymbol{\\Sigma}^T \\boldsymbol{U}^T \\\\[1em]&amp;amp;=\\boldsymbol{U} (\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^T) \\boldsymbol{U}^T \\tag{3}\\end{align}\\]그렇다면, \\((2)\\) 식과 \\((3)\\) 식이 매우 비슷한 꼴이라는 것을 발견하셨나요? 이를 통해 처음에 유도하려고 했던 \\(\\boldsymbol{U}\\)는 \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)의 고유벡터들을 열벡터로 가지는 행렬이라는 것을 알 수 있네요!3   \\(\\boldsymbol{V}\\) 행렬\\(\\boldsymbol{V}^T\\)는 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)를 고유값 분해(EVD)하여 얻을 수 있는 고유 벡터(eigen vector)들을 행벡터로 가지는 직교 행렬(orthogonal matrix)입니다. \\(\\boldsymbol{V}^T\\)의 행벡터들은 직사각 행렬 \\(\\boldsymbol{A}\\)의 right singular vector라고 불립니다.\\(\\boldsymbol{V}^T\\)를 유도하는 것은 \\(\\boldsymbol{U}\\)를 유도하는 과정과 사실상 거의 동일합니다. \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)에 대해 고유값 분해를 한다는 점만 다릅니다(\\(\\boldsymbol{U}\\)는 \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)에 대한 고유값 분해였죠). 결과만 보면, \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)를 고유값 분해하면 다음과 같은 식을 얻을 수 있습니다.\\[\\boldsymbol{A}^T\\boldsymbol{A} = \\boldsymbol{V}(\\boldsymbol{\\Sigma}^T\\boldsymbol{\\Sigma})\\boldsymbol{V}^T \\tag{4}\\]다시 말해 \\(\\boldsymbol{V}^T\\)는 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)의 고유벡터들을 행벡터로 가지는 행렬이라는 것을 알 수 있습니다.4   \\(\\boldsymbol{\\Sigma}\\) 행렬\\(m \\gt n\\) 일 때의 \\(\\Sigma\\) 행렬의 형상. AskPython\\(\\boldsymbol{\\Sigma}\\)는 \\(\\boldsymbol{A}\\boldsymbol{A}^T\\) 또는 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\) 행렬의 고유값(eigen value)들의 제곱근(square root)으로 이루어진 \\(m \\times n\\) 직사각 대각 행렬입니다. \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)와 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)는 공통의 고유값 \\(\\sigma^2_{1} \\ge \\sigma^{2}_2 \\ge \\cdots \\ge \\sigma^2_{r} \\ge 0\\) \\((\\)단, \\(r = \\text{min}(m, n)\\)\\()\\)을 가집니다 (이유는 잠시 뒤에 나옵니다). 이들의 값에 루트를 씌워 얻은 \\(\\sigma \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_r \\ge 0\\)을 대각 원소로 가지는 \\(m \\times n\\) 행렬이 바로 SVD에 찾으려는 \\(\\Sigma\\) 행렬입니다. 그리고 이 행렬의 원소들을 singular value라고 합니다.왜 제곱근을 씌울까요? 먼저 대각 행렬 거듭제곱의 성질을 알아야 하겠습니다. 대각 행렬 자체를 \\(n\\) 제곱하는 것은 단순히 대각 성분들을 \\(n\\) 제곱한 것과 같은 결과입니다.\\[D = \\left[\\begin{matrix} \\sigma_{11} &amp;amp; \\cdots &amp;amp; 0 \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ 0 &amp;amp; \\cdots &amp;amp; \\sigma_{mn} \\end{matrix} \\right] \\text{일 때,}\\]\\[D^{n} = \\left[\\begin{matrix} \\sigma_{11} &amp;amp; \\cdots &amp;amp; 0 \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ 0 &amp;amp; \\cdots &amp;amp; \\sigma_{mn} \\end{matrix} \\right]^{n} = \\left[\\begin{matrix} \\sigma_{11}^{n} &amp;amp; \\cdots &amp;amp; 0 \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ 0 &amp;amp; \\cdots &amp;amp; \\sigma_{mn}^{n} \\end{matrix} \\right]\\]다시 제곱근을 씌우는 이유를 설명해볼게요. \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)와 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\) 의 고유값으로 이루어진 행렬은 식 \\((3)\\)과 \\((4)\\)에서 보았듯이, 각각 \\(\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^T\\)와 \\(\\boldsymbol{\\Sigma}^T\\boldsymbol{\\Sigma}\\)입니다. 또한 특이값 분해의 정의에서 언급 했듯이, \\(\\boldsymbol{\\Sigma}\\)는 직사각 대각 행렬이므로 대각 행렬의 거듭 제곱 성질을 당연히 따르게 됩니다.최종적으로 \\(\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^T\\)와 \\(\\boldsymbol{\\Sigma}^T\\boldsymbol{\\Sigma}\\)는 \\(\\boldsymbol{\\Sigma}^2\\)과 같은 표현이라는 점을 알고 계시다면 (간단한 예시를 들어 계산 해보시면 쉽게 이해할 수 있어요), 우리가 알고 싶은 \\(\\boldsymbol{\\Sigma}\\) 행렬은 \\(\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^T\\) 또는 \\(\\boldsymbol{\\Sigma}^T\\boldsymbol{\\Sigma}\\)의 원소들의 제곱근(square root)임을 도출할 수 있겠습니다.4.1   \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)와 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)의 고유값은 동일합니다.\\(\\boldsymbol{A}\\boldsymbol{A}^T\\)의 고유값을 \\(\\lambda\\)라고 하고 고유벡터를 \\(\\boldsymbol{v}(\\neq \\boldsymbol{0})\\)라고 하면, 고유값과 고유벡터의 정의에 따라 아래 수식이 성립합니다.\\[(\\boldsymbol{A}\\boldsymbol{A}^T)\\boldsymbol{v} = \\lambda \\boldsymbol{v}\\]양변에 \\(\\boldsymbol{A}^T\\)를 곱하면 아래의 수식을 유도할 수 있습니다.\\[(\\boldsymbol{A}^T\\boldsymbol{A})(\\boldsymbol{A}^T\\boldsymbol{v}) = \\lambda(\\boldsymbol{A}^T \\boldsymbol{v})\\]위 수식을 볼때, \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)과 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)의 고유값은 동일하다는 사실을 이끌어 낼 수 있습니다.4.2   \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)와 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)의 고유값은 항상 0 이상의 값을 가집니다.이는 두가지 방식으로 증명할 수 있습니다. 그리 어렵지 않으니 꼭 천천히 읽어 봐주세요.방법1. \\(\\boldsymbol{A}\\boldsymbol{A}^T\\)의 고유값을 \\(\\lambda\\)라고 하고 고유벡터를 \\(\\boldsymbol{v}(\\neq \\boldsymbol{0})\\)라고 하면, 고유값과 고유벡터의 정의에 따라 아래 수식이 성립합니다.\\[\\boldsymbol{A}\\boldsymbol{A}^T\\boldsymbol{v} = \\lambda \\boldsymbol{v}\\]양변에 \\(\\boldsymbol{v}^T\\)를 곱하면 아래의 수식을 유도할 수 있습니다.\\[\\begin{align} \\boldsymbol{v}^T\\boldsymbol{A}\\boldsymbol{A}^T\\boldsymbol{v} &amp;amp;= \\lambda \\boldsymbol{v}^T \\boldsymbol{v} \\\\[1em](\\boldsymbol{A}^T\\boldsymbol{v})^T\\boldsymbol{A}^T\\boldsymbol{v} &amp;amp;= \\lambda \\boldsymbol{v}^T \\boldsymbol{v} \\\\[1em]\\Vert \\boldsymbol{A}^T\\boldsymbol{v} \\Vert^{2} &amp;amp;= \\lambda \\Vert \\boldsymbol{v} \\Vert^{2}\\end{align}\\]\\(\\Vert \\boldsymbol{A}^T\\boldsymbol{v} \\Vert^{2} \\ge 0\\) 이고, \\(\\Vert \\boldsymbol{v} \\Vert^{2} \\gt 0\\) \\((\\because \\boldsymbol{v}\\neq \\boldsymbol{0})\\)이므로 항상 \\(\\lambda \\ge 0\\) 임을 알 수 있습니다. 같은 과정을 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\) 행렬에 적용해도 결국 고유값은 항상 0 이상이라는 동일한 결과를 얻을 수 있습니다.방법 2. positive semi-definite matrix 행렬은 항상 0이상의 고유값을 가진다는 성질을 활용하여 증명 가능합니다. positive semi definite matrix는 대칭 행렬(symmetric matrix)에서만 정의 되는 개념인데요. 다음의 수식을 만족하는 대칭 행렬 \\(\\boldsymbol{A}\\)를 positive semi-definite matrix라고 하며, positive semi-definite matrix는 항상 0 이상의 고유값을 가지는 성질이 있습니다.\\[\\forall \\boldsymbol{x} \\neq0, \\space \\boldsymbol{x}^T\\boldsymbol{A}\\boldsymbol{x} \\ge0\\]먼저 \\(\\boldsymbol{AA}^T\\)와 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)가 대칭 행렬인지 알아보죠.\\[(\\boldsymbol{AA}^T)^T = \\boldsymbol{A}\\boldsymbol{A}^T\\]\\[(\\boldsymbol{A}^T\\boldsymbol{A})^T = \\boldsymbol{A}^T\\boldsymbol{A}\\]대칭 행렬의 정의에 따라, 두 행렬은 대칭 행렬임을 알 수 있습니다. 그렇다면 positive semi-definite matrix 인지만 확인하면 고유값이 항상 0 이상이라는 사실을 알 수 있겠습니다.\\[\\boldsymbol{x}^T\\boldsymbol{AA}^T\\boldsymbol{x} = (\\boldsymbol{A}^T\\boldsymbol{x})^T(\\boldsymbol{A}^T\\boldsymbol{x}) \\ge 0\\]\\[\\boldsymbol{x}^T\\boldsymbol{A}^T\\boldsymbol{A}\\boldsymbol{x} = (\\boldsymbol{Ax})^T(\\boldsymbol{Ax}) \\ge 0\\]따라서 \\(\\boldsymbol{AA}^T\\)와 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)는 positive semi-definite 행렬임을 쉽게 알 수 있습니다. 이는 곧 \\(\\boldsymbol{AA}^T\\)와 \\(\\boldsymbol{A}^T\\boldsymbol{A}\\)가 항상 0 이상의 고유값을 가진다는 사실을 증명한 것입니다.5   Reduced SVD일부의 고유값만 취하여 원 행렬을 근사하는 행렬을 계산할 수 있습니다.사실 SVD는 행렬을 분해하는 과정 보다는 부분 정보만 활용하여 복원하는 과정에서 그 활용성이 빛나는 것 같습니다. 이와 같은 방법을 통해 데이터 압축, 노이즈 제거 등의 기법을 구현할 수 있게 됩니다. 특히 추천 시스템은 원 행렬의 크기가 커질수록 연산량이 기하급수적으로 증가하게 되는데, 일부의 정보 (일부의 고유값)만을 활용한다면 연산량을 획기적으로 낮춰서 원 행렬을 근사할 수 있게 됩니다. 물론 일부의 정보를 활용한다는 사실 때문에 원 행렬과 근사 행렬 간의 오차가 발생할 수는 있습니다.행렬을 복원은 일부의 값만 활용하여 다음과 같이 layer를 쌓는 것과 동일하게 생각해볼 수 있습니다. 먼저 행렬 \\(\\boldsymbol{A}(m \\gt n)\\)가 SVD를 거쳐 아래와 같이 분해 되었다고 생각해보죠. 지금까지는 위에서 언급한 일반적인 SVD와 관련된 내용입니다.\\[\\boldsymbol{A} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^T = \\left[\\begin{matrix} \\vert &amp;amp; &amp;amp; \\vert \\\\ \\boldsymbol{u}_1 &amp;amp; \\cdots &amp;amp; \\boldsymbol{u}_{m} \\\\ \\vert &amp;amp; &amp;amp; \\vert \\end{matrix} \\right] \\left[\\begin{matrix} \\sigma_{1} &amp;amp; \\cdots &amp;amp; 0 \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ 0 &amp;amp; \\cdots &amp;amp; \\sigma_{n} \\\\ 0 &amp;amp; \\cdots &amp;amp; 0 \\end{matrix} \\right] \\left[\\begin{matrix} - &amp;amp; \\boldsymbol{v}_{1}^{T} &amp;amp;- \\\\ &amp;amp; \\vdots &amp;amp; \\\\ - &amp;amp; \\boldsymbol{v}_{n}^{T} &amp;amp;- \\end{matrix} \\right]\\]그렇다면 어떻게 해야 원 행렬 \\(\\boldsymbol{A}\\)와 같은 크기를 유지하면서도 ‘일부’의 정보만을 활용해서 연산량을 줄이는 방향으로 행렬 근사를 할 수 있을까요? \\(\\boldsymbol{U}\\) 행렬과 \\(\\boldsymbol{V}^T\\) 행렬을 건들면 원 행렬 \\(\\boldsymbol{A}\\)와 크기가 달라져 버릴 것만 같습니다. 해결책은 \\(\\boldsymbol{\\Sigma}\\) 행렬의 크기를 조작하는 것입니다. 현재 \\(\\boldsymbol{\\Sigma}\\) 행렬에는 크기의 내림 차순으로 \\(n\\)개의 고유값이 대각 성분에 정렬되어 있는 상태입니다. 여기서 \\(k(&amp;lt;n)\\)개의 고유값만 취해보는 것이죠. 이는 정보량이 큰 상위 \\(k\\)개의 값만 활용하는 것으로 해석 할 수 있습니다.본론으로 돌아와서 \\(k\\)개의 고유값만 활용하게 된다면 행렬 연산이 어떻게 변하는지 살펴봅시다.\\[\\boldsymbol{A}_k = \\boldsymbol{U}_k\\boldsymbol{\\Sigma}_k\\boldsymbol{V}^T_k = \\left[\\begin{matrix} \\vert &amp;amp; &amp;amp; \\vert \\\\ \\boldsymbol{u}_1 &amp;amp; \\cdots &amp;amp; \\boldsymbol{u}_{k} \\\\ \\vert &amp;amp; &amp;amp; \\vert \\end{matrix} \\right] \\left[\\begin{matrix} \\sigma_{1} &amp;amp; \\cdots &amp;amp; 0 \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ 0 &amp;amp; \\cdots &amp;amp; \\sigma_{k} \\end{matrix} \\right] \\left[\\begin{matrix} - &amp;amp; \\boldsymbol{v}_{1}^{T} &amp;amp;- \\\\ &amp;amp; \\vdots &amp;amp; \\\\ - &amp;amp; \\boldsymbol{v}_{k}^{T} &amp;amp;- \\end{matrix} \\right]\\]\\[\\boldsymbol{A}_k \\in \\mathbb{R}^{m \\times n}\\]\\[\\boldsymbol{U}_k \\in \\mathbb{R}^{m \\times k}\\]\\[\\boldsymbol{\\Sigma}_k \\in \\mathbb{R}^{k \\times k}\\]\\[\\boldsymbol{U}_k \\in \\mathbb{R}^{k \\times n}\\]이렇게 큰 정보량을 가지는 고유값 \\(k\\)개를 선택하여 근사 복원한 행렬 \\(\\boldsymbol{A}_k\\)는 원 행렬 \\(\\boldsymbol{A}\\)와 같은 크기를 유지하면서도, 연산량을 줄일 수 있는 이점이 있습니다. 물론 그 만큼의 정보의 손실을 발생한다는 단점이 있겠네요.마지막으로 SVD를 통해 분해된 행렬과 reduced SVD의 행렬 notation은 다음과 같이 덧셈 notation으로도 나타낼 수 있습니다.\\[\\boldsymbol{A} = \\sigma_{1}\\boldsymbol{u}_{1}\\boldsymbol{v}^T_1 + \\cdots + \\sigma_{n}\\boldsymbol{u}_{n}\\boldsymbol{v}^T_{n}\\]\\[\\boldsymbol{A}_k = \\sigma_{1}\\boldsymbol{u}_{1}\\boldsymbol{v}^T_1 + \\cdots + \\sigma_{k}\\boldsymbol{u}_{k}\\boldsymbol{v}^T_{k}\\]Reference Singular-value decomposition, Orelly 특잇값 분해, 위키피디아 한국어판 Singular value decomposition, wikipedia 특이값 분해(SVD), 공돌이의 수학정리노트 특이값 분해(Singular Value Decomposition, SVD)의 활용, 다크 프로그래머 특이값 분해 (SVD, Singular Value Decomposition), R Friend 선형대수학 - 특이값 분해 SVD(Singular Value Decomposition), 하루하루 SVD (특이값 분해), 하고 싶은 일을 하자 특이값 분해(SVD)의 증명, Deep Campus Notes on singular value decomposition for Math 54 Non-zero eigenvalues of \\(\\boldsymbol{AA}^T\\) and \\(\\boldsymbol{A}^T \\boldsymbol{A}\\) SVD 를 활용한 협업필터링 Vozalis, M. G., &amp;amp; Margaritis, K. G. (2005, September). Applying SVD on item-based filtering. In 5th International Conference on Intelligent Systems Design and Applications (ISDA’05) (pp. 464-469). IEEEfootnote 고유값 분해(EVD, eigen value decomposition) 정방 행렬을 자신의 고유벡터로 이루어진 행렬과 고유값으로 이루어진 대각행렬로 대각화 분해하는 기법입니다. &amp;#8617; 고유 벡터(eigen vector)란 행렬에 대해 크기(scale)은 변하지만 방향은 변하지 않는 영벡터가 아닌 벡터를 말합니다. &amp;#8617; 열벡터끼리, 행벡터끼리 정규 직교(orthonormal) 하는 정방 행렬을 뜻합니다. 정의에 의해서 \\(\\boldsymbol{A}\\boldsymbol{A}^T = \\boldsymbol{I}\\)의 성질을 가집니다. &amp;#8617; " }, { "title": "tf.keras 커스텀 하기", "url": "/posts/custom_tensorflow_2/", "categories": "ML, TF", "tags": "tensorflow", "date": "2021-02-17 21:26:00 +0900", "snippet": "최근에 python2 + tensorflow 1.x로 작성된 추천 시스템 레거시 코드를 유지 보수 및 개선하는 업무를 진행하고 있습니다. 기존 코드는 tensorflow 1.x 버전으로 짜여져 있어서 API의 통일성이 부족했고, 오픈 소스 코드에 기반하여 상황 마다 필요한 컴포넌트를 추가 하다보니 코드의 일관성도 많이 저해된 상태였습니다. 따라서 유지 보수의 용이성을 확보하기 위해 tensorflow를 2.0 버전으로 코드를 변환해야겠다는 결심을 하게 되었습니다. tensorflow 공식 문서에서는 tensorflow 2.0 버전의 특징이 다음의 네 가지로 요약되어 있습니다. 가독성이 향상되고, 디버깅도 편해질 것 같군요! API Cleanup Eager execution No more globals Functions, not session특히 저는 깔끔하면서도 정형화된 형태로 tf 코드를 작성하고, 필요하다면 low-level로 layer를 커스터마이징할 수 있어야 했으므로 tensorflow 2.0 + keras layer 조합으로 코드를 작성하였습니다. 본 글에서는 이와 관련된 내용을 공부하면서 얻은 지식을 다음의 내용을 중심으로 정리해보겠습니다. custom layer class custom loss class custom model class custom training loopLayer Classkeras layer를 만들 때, subclassing1을 활용하여 클래스 형태로 만들 수 있습니다. 이와 같은 방식에는 두가지 장점이 있다고 생각하는데요. 메서드 이름이나 메서드가 받는 argument 등에 대한 정형화된 형태가 존재하고, 이에 맞춰 코드를 작성해야 하기 때문에 가독성이 향상됩니다. 한편으로 layer에서 이루어지는 computation 로직은 직접 low-level로 작성할 수 있기 때문에 커스터마이징이 가능합니다.layer class는 weight와 computation의 결합으로 표현할 수 있는데요. 텐서플로우 공식 문서에서는 layer class에 대해 다음과 같이 설명하고 있습니다. 한마디로 정리하면 weight와 computation 과정이 결합된 object라고 말할 수 있겠습니다. One of the central abstraction in Keras is the Layer class. A layer encapsulates both a state (the layer’s “weights”) and a transformation from inputs to outputs (a “call”, the layer’s forward pass).이 문서에서는 custom layer class를 작성하는 best practice를 다음과 같이 제안하고 있습니다.class Linear(tf.keras.layers.Layer): def __init__(self, units=32): super(Linear, self).__init__() self.units = units def build(self, input_shape): self.w = self.add_weight( shape=(input_shape[-1], self.units), initializer=&quot;random_normal&quot;, trainable=True, ) self.b = self.add_weight( shape=(self.units,), initializer=&quot;random_normal&quot;, trainable=True ) def call(self, inputs): return tf.matmul(inputs, self.w) + self.b __init__() 해당 layer에서 활용하는 hyperparameter 등을 선언합니다. build() 해당 layer에서 활용하는 trainable/non-trainable weights와 관련된 로직을 작성합니다. 특히 build 메서드에 weights 초기화 로직을 구현하면 해당 레이어의 인풋의 차원을 정확하게 알지 못하더라도 lazy 하게 작동하게 할 수 있다는 장점이 있습니다. build 메서드에 선언된 weights는 call 메서드가 처음 호출될 때 생성됩니다. call() 해당 layer의 computation과 관련된 로직을 작성합니다. 인풋을 받아 원하는 형태의 아웃풋을 리턴하도록 하면 되겠습니다. 그러나 딥러닝 코드를 짜다보면 같은 computation 로직을 반복 사용해야할 경우가 많죠. 예를 들어 위 예시처럼 Linear(Dense) layer는 정말 많이 사용하는데요. 내가 만든 custom layer class 혹은 keras layer class 여러 개를 묶어서 다시 레이어 클래스를 만드려면 어떻게 해야할까요? 공식 문서에서는 아래와 같은 방법을 제안합니다.class MLPBlock(tf.keras.layers.Layer): def __init__(self): super(MLPBlock, self).__init__() self.linear_1 = Linear(32) self.linear_2 = Linear(32) self.linear_3 = Linear(1) def call(self, inputs): x = self.linear_1(inputs) x = tf.nn.relu(x) x = self.linear_2(x) x = tf.nn.relu(x) return self.linear_3(x)첫번째 예시와 거의 비슷한 형태인데요. 공통점은 computation 로직이 call() 메서드로 처리된다는 점입니다. 그러나 build() 메서드에 weight를 직접 선언하지 않고, layer class를 __init__() 메서드에 선언한다는 것이 차이점이네요. 이는 공식적으로 권장하는 방법입니다. 그 이유는 outer layer (e.g. MLPBlock)는 inner layer (e.g. Linear)의 weight를 자동으로 추적할수 있기 때문이라고 합니다. 이 부분은 공식 문서의 설명이 조금 부실한데요. outer layer class에서 call() 메서드가 처음으로 호출되면, computation 과정에 참여하는 inner layer들의 call() 메서드도 역시 처음으로 호출되게 됩니다. 이때 inner layer의 build() 메서드에 선언된 weight들이 lazy하게 생성됩니다. outer layer는 inner layer의 weight를 추적할 수 있도록 디자인 되어 있기 때문에 이와 같은 로직 작성이 가능한 것입니다.Loss Classcustom loss function을 만드는 방법은 크게 세 가지로 나눌 수 있습니다. simple loss function nested loss function loss class먼저 세가지 방식은 공통적으로 loss를 계산하는 메서드가 y_true, y_pred라는 단 두가지 인자만 받을 수 있다는 단점이 존재합니다. 물론 각 방법의 특징에 따라 추가적인 인자들을 활용할 수 있는 방안이 마련되어 있지만, 실제로 loss를 계산하는 메서드는 무조건 위의 두가지 인자만 전달받을 수 있습니다.사실 케라스 built-in function인 model.fit()를 활용하실 계획이 없으시다면, low-level로 loss 함수를 작성하셔도 관계없습니다. 그러나 model.fit()을 사용하실 계획이시라면 반드시 정해진 형태에 맞춰 코드를 작성해주셔야 합니다. model.fit() 메서드 내부에 loss와 관련된 부분은 y_true, y_pred 두 가지 인자만을 활용하도록 디자인 되어 있기 때문입니다.2.1   Simple Loss Function공식 문서에서 제안하는 가장 기본적인 custom keras loss 함수 작성 방법입니다.def my_loss_fn(y_true, y_pred): squared_difference = tf.square(y_true - y_pred) return tf.reduce_mean(squared_difference, axis=-1) # Note the `axis=-1` y_true: ground_truth 값을 전달합니다. y_pred: 모델의 예측 값을 전달합니다.이 방식의 가장 큰 문제는 y_true나 y_pred 이외의 값을 전혀 활용할 수 없다는 것입니다. 만일 loss 함수에 추가적인 파라미터가 요구된다면 이러한 방식의 loss 함수는 사용할 수 없습니다. 다음에 설명드릴 nested loss function이나 loss class 방식을 참고해주세요.2.2   Nested Loss Function기본적인 loss 함수의 단점을 보완하고 추가적인 파라미터를 전달하기 위해서 다음과 같은 방법으로 custom loss 함수를 작성할 수 있습니다.def my_loss_fn(threshold): def inner_fn(y_true, y_pred): squared_difference = tf.square(y_true - y_pred) * threshold return tf.reduce_mean(squared_difference, axis=-1) return inner_fnnested loss function에는 파이썬 클로저(closure)2의 개념이 활용 되었습니다. 클로저에 대한 자세한 내용은 이 곳을 참고해주세요. 결론적으로 말씀드리면, threshold라는 변수는 inner_fn의 입장에서는 nonlocal 변수인데요. 클로저는 nonlocal 변수인 threshold에 담긴 값을 기억하고 참조할 수 있습니다. 따라서 squared_difference를 계산할 때, inner_fn 함수의 네임 스페이스 바깥 영역에서 선언된 threshold 변수를 참조할 수 있는 것입니다. nested loss 함수는 기본적인 loss 함수에 비해 조금 더 자유롭지만, 저는 개인적으로 클래스를 이용해서 조금 더 깔끔하게 함수를 작성하실 것을 추천드립니다.2.3   Loss Class개인적으로 custom loss를 작성할 때 가장 선호하는 방식입니다. 가장 가독성이 좋으면서도 외부 파라미터도 활용할 수 있기 때문입니다. 생성자 __init__()에 필요한 외부 파라미터를 선언해두고 call() 메서드에 실제 loss를 계산하는 로직을 작성하시면 됩니다.class CustomLoss(tf.keras.losses.Loss): def __init__(self, param1, param2, ...): super(CustomLoss, self).__init__() self.param1 = param1 self.param2 = param2 def call(self, y_true, y_pred): loss = ... return lossloss class 방식은 아래와 같은 keras high-level api와 쉽게 결합 가능합니다.loss_fn = CustomLoss(param1, param2)...model.compile(optimizer=..., loss=loss_fn)model.fit()그러나 세 가지 방법 모두 여전히 call() 메서드에 y_true, y_pred 두 가지 인자만 전달할 수 있다는 단점은 존재하는데요. y_true 값이 여러 개일 경우에 문제가 될 수 있습니다. 예를 들어 negative sampling loss를 계산하는 상황을 가정해보겠습니다. 이 경우 call() 메서드에 y_true_positive, y_true_negative, y_pred 와 같이 인자를 3개를 전달해야 할겁니다.인자를 3개를 전달하기 위한 여러 방법을 찾아보았는데, 제가 내린 결론은 model.fit() 메서드를 사용할 것이라면 인자를 3개 이상 전달할 수 있는 방법은 없다는 것입니다. 그래서 저는 우회적으로 y_true_positive와 y_true_negative를 reshape 및 concat 하여 y_true 인자로 전달한 후 call() method 내부에서 slice 및 reshape를 통해 negative sampling loss를 계산하는 식으로 로직을 작성했습니다. 혹시 더 좋은 방안이 있다면 제보 부탁드립니다!Model Classtf.keras에서 커스텀 모델을 만드는 방법은 크게 3가지입니다. Sequential API Functional API Model Class (via subclassing)세가지 방법 중 가장 low-level로 custom 할 수 있는 model class를 위주로 설명드리려고 합니다. 공식 문서에서 제안한 예시를 통해 설명드리겠습니다.3.1   Simple Model Classclass ResNet(tf.keras.Model): def __init__(self, num_classes=1000): super(ResNet, self).__init__() self.block_1 = ResNetBlock() self.block_2 = ResNetBlock() self.global_pool = layers.GlobalAveragePooling2D() self.classifier = Dense(num_classes) def call(self, inputs): x = self.block_1(inputs) x = self.block_2(x) x = self.global_pool(x) return self.classifier(x) tf.keras.Model 상속 tf.keras.Model의 상속을 통해서 model.fit(), model.compile(), model.predict() 등의 keras built-in 함수를 자연스럽게 사용할 수 있게 되는데요. 여기을 참고 하시면 tf.keras.Model 클래스가 fit(), compile() 등의 메서드를 가지고 있는 것을 볼 수 있습니다. __init__() hyperparameter나 layer class를 정의하는 메서드입니다. call() model의 computation이 일어나는 부분입니다. argument로 inputs를 받아서 custom 원하는 output을 계산하도록 로직을 작성하면 되겠습니다. 3.2   End-to-End Modelmodel class 방식의 가장 큰 장점은 여러 layer class를 조합하여 하나의 큰 모델로 만들 수 있다는 점입니다. 많은 분들께서 결국에는 이와 비슷한 형태로 model class를 만드실 것으로 생각합니다. 공식 문서의 예제를 조금 간소화하여 설명드릴게요. 아래의 예시는 encode layer class와 decoder layer class를 선언한 뒤에 VariationalAutoEncoder model class로 두 레이어를 조합하는 예시를 보여줍니다. 이와 같이 직접 만드신 layer class나 케라서 built-in layer class를 활용하여 원하시는 모델을 레고 조립하듯이 쌓아 나가시면 되겠습니다.class Encoder(tf.keras.layers.Layer): def __init__(self, latent_dim=32, ...): super(Encoder, self).__init__(...) ... def call(self, inputs): z_mean = ... z_log_var = ... z = ... return z_mean, z_log_var, zclass Decoder(tf.keras.layers.Layer): def __init__(self, intermediate_dim=64, ...): super(Decoder, self).__init__(...) ... def call(self, inputs): x = ... y = ... return yclass VariationalAutoEncoder(tf.keras.Model): def __init__(self, original_dim, ...): super(VariationalAutoEncoder, self).__init__(...) self.encoder = Encoder(...) self.decoder = Decoder(...) def call(self, inputs): x = self.encoder(...) y = self.decoder(...) ... return outputCustom Training Looptraining loop를 작성하는 방법은 크게 두가지입니다. for loop를 활용한 low-level 수준의 코드 작성 model class에 train_step() 함수를 오버라이딩3하여 작성첫번째 방식은 코드를 작성하는 사람의 입맛에 맞게 매우 자유롭게 코드를 작성할 수 있다는 장점이 있지만, 그에 비례해서 코드 작성 과정에서 human error가 발생할 가능성이 높아집니다. 저는 자유롭게 코드를 작성할 수 있으면서도 model.fit()의 편리한 장점을 취하여 human error를 최소화 할 수 있는 두번째 방식으로 custom training loop를 작성하는 방법을 설명해드리고자 합니다.섹션3에서 언급한 model class에 train_step() 메서드를 활용하면 됩니다. 코드는 다음과 같은 방식으로 작성하시면 됩니다. 보다 자세한 내용은 공식 문서를 참조해주세요. tf.keras.Model을 상속 받아 model class를 만듭니다. model class에 train_step() 메서드를 작성합니다. model.fit()는 이 메서드를 활용하여 학습이 진행되도록 디자인 되어 있습니다. tf.GradientTape API는 자동 미분(automatic differentiation) 기능을 제공합니다. 따라서 우리는 train_step() 메서드의 로직 작성 순서만 고려하면 됩니다.class CustomModel(tf.keras.Model): def __init__(self): ... def call(self): ... def train_step(self, data): # Unpack the data. Its structure depends on your model and on what you pass to `fit()`. x, y = data with tf.GradientTape() as tape: # Forward pass y_pred = self(x, training=True) # Compute the loss value (the loss function is configured in `compile()`) loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses) # Compute gradients trainable_vars = self.trainable_variables gradients = tape.gradient(loss, trainable_vars) # Update weights self.optimizer.apply_gradients(zip(gradients, trainable_vars)) # Update metrics (includes the metric that tracks the loss) self.compiled_metrics.update_state(y, y_pred) # Return a dict mapping metric names to current value return {m.name: m.result() for m in self.metrics}train_step() 메서드는 다음과 같은 순서로 진행됩니다. Step1: computation 기록 tf.GradientTape() 컨텍스트 내부의 연산은 추적되어서 이후 자동 미분이 가능하게 됩니다. Step2: forward pass model class의 call() 메서드를 활용해서 모델의 예측값을 계산합니다. Step3: compute loss model.compile() 메서드에 전달한 loss 함수로 loss가 계산됩니다. Step4: compute gradients 후진 방식 자동 미분(reverse mode differentiation)을 사용해 기록된 연산의 gradient를 계산합니다. Step5: update weights 계산된 gradient와 model.compile() 메서드에 전달한 optimizer를 활용해 weight를 업데이트 합니다. Step6: update metrics 현재 step에서의 metrics를 계산합니다. Step7: return metric dictionary training step 마다 계산된 metrics를 progress bar에 출력하기 위해 해당 딕셔너리를 return 합니다. Conclusiontf.keras를 커스텀 하는 방법은 매우 다양하고 알아야 되는 개념도 많다는 것을 알게 되었습니다. 특히 저는 keras built-in function들을 최대한 활용할 수 있는 방안을 고민하면서 많은 시행착오를 겪었고 그 결과 제가 체득한 가장 최선의 시나리오(?)를 정리하였습니다. 다만 최대한 쉽게 작성하려고는 했으나, 애초에 알아야할 개념들이 많이 있어서 글 자체의 난이도 조절에는 실패해버린 것 같습니다…업무를 어느 정도 일단락 하고 지난 일들을 돌이켜 보면 keras built-in function을 활용한다는 것이 양날이 검이 될 수도 있다는 생각이 들었습니다. 딥러닝 코드에서 어느 정도 정형화된 부분은 keras built-in function을 활용하면 human error를 줄일 수 있는 것은 확실한 장점이라고 생각합니다. 그러나 정말 모든 것을 low-level로 하고 싶은신 분들에게는 어느 정도 규격화된 틀이 있다는 것이 답답하게 느껴질 수도 있을 것 같습니다. 특히 pytorch를 사용하셨던 분들에게는 더욱 크게 다가올 것 같네요.아 그리고 이 글에서 담지 못한 이야기들도 많이 있는데요. metric로 커스터마이징이 가능하고, 만들어진 모델을 tf.serving container를 활용해서 API 서버를 구축하시려면 tf.graph에 대한 개념 이해도 필요합니다. 추후에 기회가 되면 이 부분도 다뤄보겠습니다.Reference Simple custom layer example: Antirectifier 직접 케라스 레이어 만들기 Training and evaluation with the built-in methods Making new Layers and Models via subclassing Writing a training loop from scratch Customize what happens in Model.fit Customizing what happens in fit() tensorflow custom loss Losses (keras.io) The Sequential model Introduction to gradients and automatic differentiation 파이썬 강좌 번외편. 클로저(Closure) 클로져(Closure) 이해하기 Python의 Closure에 대해 알아보자footnote 서브클래싱(subclassing)이란 객체 지향 프로그래밍(OOP)에 등장하는 개념으로서 구현되어 있는 클래스를 상속하는 것을 말합니다. &amp;#8617; 클로저(closure)란 자신을 둘러싼 네임 스페이스에 존재하는 변수를 기억할 수 있는 함수를 뜻합니다. 대표적으로 파이썬 데코레이터는 클로저의 개념을 활용한 것입니다. &amp;#8617; 오버라이딩(overriding)이란 부모 클래스의 메서드를 자식 클래스에서 재정의하는 것을 말합니다. 자식 클래스의 메서드를 작성할 때 부모 클래스의 메서드와 이름은 같지만 로직을 다르게 하고 싶을 때 사용합니다. &amp;#8617; " }, { "title": "고유값 분해(Eigenvalue Decompostion)", "url": "/posts/eigenvalue_decomposition/", "categories": "Math, Linear algebra", "tags": "evd", "date": "2021-01-26 22:18:00 +0900", "snippet": "정방행렬을 고유벡터와 고유값의 행렬로 분해할 수 있다?! (Eigenvalue decomposition, OREILLY)2줄 요약 고유값 분해는 \\(n \\times n\\) 정방 행렬을 고유벡터로 이루어진 행렬과 고유값으로 이루어진 행렬로 대각화 하는 방법 행렬 거듭제곱, SVD 등에서 활용 됨\\(n \\times n\\) 정방 행렬을 고유벡터와 고유값으로 대각화 할 수 있는 고유값 분해에 대해 알아보겠습니다. 고유값 분해를 통해서 행렬 거듭제곱꼴이나 행렬식 계산을 단순화할 수 있습니다. 또한 SVD를 이해하기 위한 선수지식으로서도 의미가 있겠습니다. 본 글을 이해하기 위해서 아래의 개념에 대한 이해가 필요합니다. 고유값과 고유벡터 대칭 행렬(symmetric matrix) 직교 행렬(orthogonal matrix)또한 행렬과 벡터의 표기는 아래를 따릅니다. 행렬: \\(\\boldsymbol{X}\\) 벡터: \\(\\boldsymbol{x}\\) 벡터의 원소: \\(x_1, x_2, \\cdots, x_i\\)1   고유값 분해1.1   고유값 분해란?고유값 분해(eigen value decomposition)란 \\(n \\times n\\) 정방 행렬을 자신의 고유벡터를 열벡터로 가진 행렬 \\(\\boldsymbol{V}\\)와 고유값으로 이루어진 행렬 \\(\\boldsymbol{\\Lambda}\\)로 대각화 분해하는 기법입니다.\\[\\boldsymbol{X} = \\boldsymbol{V} \\boldsymbol{\\Lambda} \\boldsymbol{V}^{-1}\\]1.2   고유값 분해 수식 유도고유값 분해의 수식 유도는 고유값과 고유벡터의 개념과 행렬의 각 열의 상수를 인수 분해 방법을 알면 쉽게 유도할 수 있습니다. 고유값과 고유벡터는 이글을 참고해주시구요. 상수 인수 분해 방법에 대해서 알아 보겠습니다.1.2.1   행렬의 상수의 인수 분해\\(n \\times n\\) 정방 행렬 \\(\\boldsymbol{X}\\)가 다음의 \\(n\\)개의 상수 \\(\\lambda_{1,\\cdots,n}\\)과 벡터 \\(\\boldsymbol{v}_{1,\\cdots,n}\\) 로 이루어져 있다고 생각해보죠.\\[\\boldsymbol{X} = \\begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\lambda_1\\boldsymbol{v}_1 &amp;amp; \\lambda_2\\boldsymbol{v}_2 &amp;amp; \\cdots &amp;amp; \\lambda_n\\boldsymbol{v}_n\\\\ | &amp;amp; | &amp;amp; &amp;amp;|\\end{bmatrix}\\]이 행렬 \\(\\boldsymbol{X}\\)의 상수 \\(\\lambda_{1, \\cdots, n}\\)를 빼내서 행렬의 곱으로 표현하면 아래와 같이 쓸 수 있습니다. 적당한 숫자를 대입해서 계산해보시면 좌항과 우항의 연산 결과가 같다는 것을 알 수 있습니다.\\[\\boldsymbol{X} = \\begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\lambda_1\\boldsymbol{v}_1 &amp;amp; \\lambda_2\\boldsymbol{v}_2 &amp;amp; \\cdots &amp;amp; \\lambda_n\\boldsymbol{v}_n\\\\ | &amp;amp; | &amp;amp; &amp;amp;|\\end{bmatrix}=\\begin{bmatrix} \\vert &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\boldsymbol{v}_1 &amp;amp; \\boldsymbol{v}_2 &amp;amp; \\ldots &amp;amp; \\boldsymbol{v}_n\\\\ \\vert &amp;amp; \\vert &amp;amp; &amp;amp;\\vert\\end{bmatrix}\\begin{bmatrix} \\lambda_1 &amp;amp; \\ldots &amp;amp; 0 \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ 0 &amp;amp; \\ldots &amp;amp;\\lambda_n\\end{bmatrix}\\]1.2.2   고유값과 고유벡터를 행렬 notation으로 표시\\(n \\times n\\) 정방 행렬 \\(\\boldsymbol{X}\\)는 최대 \\(n\\)개의 고유값과 고유벡터를 가질 수 있습니다.\\[\\boldsymbol{X} \\boldsymbol{v}_1 = \\lambda_1 \\boldsymbol{v}_1\\]\\[\\boldsymbol{X} \\boldsymbol{v}_2 = \\lambda_2 \\boldsymbol{v}_2\\]\\[\\vdots\\]\\[\\boldsymbol{X} \\boldsymbol{v}_n = \\lambda_n \\boldsymbol{v}_n\\]여러개의 고유값과 고유벡터를 행렬 하나에 표현해볼까요? 먼저 고유벡터들을 열벡터로 하는 \\(n \\times n\\) 정방 행렬을 \\(\\boldsymbol{V}\\)라고 정의합시다.\\[\\boldsymbol{X} \\boldsymbol{V} = \\boldsymbol{X}\\begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\boldsymbol{v}_1 &amp;amp; \\boldsymbol{v}_2 &amp;amp; \\cdots &amp;amp; \\boldsymbol{v}_n \\\\ | &amp;amp; | &amp;amp; &amp;amp;|\\end{bmatrix} = \\begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\boldsymbol{X}\\boldsymbol{v}_1 &amp;amp; \\boldsymbol{X}\\boldsymbol{v}_2 &amp;amp; \\cdots &amp;amp; \\boldsymbol{X}\\boldsymbol{v}_n \\\\ | &amp;amp; | &amp;amp; &amp;amp;|\\end{bmatrix} = \\begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\lambda_1\\boldsymbol{v}_1 &amp;amp; \\lambda_2\\boldsymbol{v}_2 &amp;amp; \\cdots &amp;amp; \\lambda_n\\boldsymbol{v}_n \\\\ | &amp;amp; | &amp;amp; &amp;amp;|\\end{bmatrix}\\]\\(\\Lambda\\)를 고유값들을 대각성분으로 하는 \\(n \\times n\\) 정방행렬이라고 하면, 인수 분해를 적용하여 \\(\\boldsymbol{X} \\boldsymbol{V}\\)를 다음과 같이 나타낼 수 있습니다.\\[\\begin{align}\\boldsymbol{X} \\boldsymbol{V} &amp;amp;= \\begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\lambda_1\\boldsymbol{v}_1 &amp;amp; \\lambda_2\\boldsymbol{v}_2 &amp;amp; \\cdots &amp;amp; \\lambda_n\\boldsymbol{v}_n \\\\ | &amp;amp; | &amp;amp; &amp;amp;|\\end{bmatrix} = \\begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\boldsymbol{v}_1 &amp;amp; \\boldsymbol{v}_2 &amp;amp; \\cdots &amp;amp; \\boldsymbol{v}_n \\\\ | &amp;amp; | &amp;amp; &amp;amp;|\\end{bmatrix} \\begin{bmatrix} \\lambda_1 &amp;amp; \\ldots &amp;amp; 0 \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ 0 &amp;amp; \\ldots &amp;amp;\\lambda_n\\end{bmatrix} \\\\[1em] &amp;amp;= \\boldsymbol{V}\\boldsymbol{\\Lambda} \\end{align}\\]행렬 \\(\\boldsymbol{X}\\)가 고유값 분해 가능하다면, 다시 말해 아래의 두 조건을 만족한다면 (이와 관련된 조금 더 상세한 내용은 Appendix를 참조해주세요.) 행렬 \\(\\boldsymbol{X}\\)는 \\(n \\times n\\) 정방 행렬입니다. 행렬 \\(\\boldsymbol{X}\\)는 \\(n\\)개의 선형 독립(linearly independent)1 고유벡터를 가집니다.행렬 \\(\\boldsymbol{X}\\)는 최종적으로 다음과 같이 고유벡터와 고유값들로 이루어진 행렬로 분해 가능합니다.\\[\\boldsymbol{X} = \\boldsymbol{V}\\boldsymbol{\\Lambda}\\boldsymbol{V}^{-1}\\]2   고유값 분해를 손으로 해보자행렬 \\(\\boldsymbol{A}=\\left[\\begin{matrix} 2 &amp;amp; 1 \\\\ 1 &amp;amp; 2 \\end{matrix} \\right]\\)를 고유값 분해를 해보겠습니다. 고유값과 고유벡터를 구하는 방법은 여기을 참조해 주시구요. 행렬 \\(\\boldsymbol{A}\\)의 고유값과 고유벡터는 다음과 같습니다.\\[\\lambda_1 =1, \\space \\boldsymbol{v}_1 = \\left[\\begin{matrix} 1/\\sqrt{2} \\\\ -1/\\sqrt{2} \\end{matrix} \\right], \\space \\lambda_2 = 3, \\space \\boldsymbol{v}_2=\\left[\\begin{matrix} 1/\\sqrt{2} \\\\ 1/\\sqrt{2} \\end{matrix} \\right]\\]고유값 분해를 활용하면 행렬 \\(\\boldsymbol{A}\\)를 다음과 같이 분해할 수 있습니다. \\(\\boldsymbol{V}\\)는 \\(\\boldsymbol{A}\\)의 고유벡터를 열벡터로 하는 정방 행렬이고 \\(\\boldsymbol{\\Lambda}\\)는 \\(\\boldsymbol{V}\\)의 고유값들을 대각 성분으로하는 대각 행렬입니다.\\[\\begin{align}\\boldsymbol{A}&amp;amp;= \\boldsymbol{V}\\boldsymbol{\\Lambda}\\boldsymbol{V}^{-1} \\\\[1em]&amp;amp;= \\begin{bmatrix} 1/\\sqrt{2} &amp;amp; 1/\\sqrt{2} \\\\ 1/\\sqrt{2} &amp;amp; -1/\\sqrt{2} \\end{bmatrix} \\begin{bmatrix} 3 \\space &amp;amp; 0 \\\\[0.5em] 0 \\space &amp;amp; 1\\end{bmatrix} \\begin{bmatrix} 1/\\sqrt{2} &amp;amp; 1/\\sqrt{2} \\\\ 1/\\sqrt{2} &amp;amp; -1/\\sqrt{2} \\end{bmatrix} \\end{align}\\]원래 행렬 \\(\\boldsymbol{A}\\)와 정말로 같은 값인지 검증 해볼까요?\\[\\begin{align}\\boldsymbol{A}&amp;amp;= \\begin{bmatrix} 1/\\sqrt{2} &amp;amp; 1/\\sqrt{2} \\\\ 1/\\sqrt{2} &amp;amp; -1/\\sqrt{2} \\end{bmatrix} \\begin{bmatrix} 3 \\space &amp;amp; 0 \\\\[0.5em] 0 \\space &amp;amp; 1\\end{bmatrix} \\begin{bmatrix} 1/\\sqrt{2} &amp;amp; 1/\\sqrt{2} \\\\ 1/\\sqrt{2} &amp;amp; -1/\\sqrt{2} \\end{bmatrix} \\\\[1em]&amp;amp;= \\begin{bmatrix} 3/2+1/2 &amp;amp; 3/2-1/2 \\\\ 3/2-1/2 &amp;amp; 3/2+1/2 \\end{bmatrix} \\\\[1em]&amp;amp;= \\begin{bmatrix} 2 &amp;amp; 1 \\\\ 1 &amp;amp; 2 \\end{bmatrix}\\end{align}\\]3   고유값 분해의 활용3.1   행렬의 거듭제곱임의의 행렬 \\(\\boldsymbol{X}\\)에 대해서 \\(\\boldsymbol{X}^2, \\boldsymbol{X}^3\\) 정도는 우리가 행렬 곱셈을 통해서 손으로도 손쉽게 계산 할 수 있습니다. 그렇다면 \\(\\boldsymbol{X}^{1000}\\)은 어떤가요? 물론 계산할 수도 있겠지만 매우 번거롭습니다. 하지만 고유값 분해를 적용하면 행렬의 거듭제곱꼴을 일정한 규칙으로 단순화 시켜줄 수 있습니다! (물론 고유값 분해가 가능한 조건을 만족하는 행렬에 대해서만 할 수 있겠죠?) 먼저 \\(\\boldsymbol{X}^2\\)과 \\(\\boldsymbol{X}^3\\)은 고유값 분해를 통해 아래와 같이 구할 수 있습니다.\\[\\begin{align}\\boldsymbol{X}^2 &amp;amp;= \\boldsymbol{V \\Lambda V}^{-1} \\boldsymbol{V \\Lambda V}^{-1} = \\boldsymbol{V} \\boldsymbol{\\Lambda}^2 \\boldsymbol{V}^{-1} \\\\\\boldsymbol{X}^3 &amp;amp;= \\boldsymbol{V \\Lambda V}^{-1} \\boldsymbol{V \\Lambda V}^{-1} \\boldsymbol{V \\Lambda V}^{-1} = \\boldsymbol{V} \\boldsymbol{\\Lambda}^3 \\boldsymbol{V}^{-1} \\\\\\end{align}\\]\\[\\vdots\\]규칙을 찾아보면 고유값으로 이루어진 대각 행렬에만 거듭 제곱 횟수만큼 승수를 늘려가는 것을 알 수 있습니다. 대각행렬의 거듭 제곱은 각 대각 원소에 필요한 만큼 거듭 제곱을 취하면 되기 때문에 전체적인 행렬의 거듭 제곱꼴이 아래와 같이 매우 단순화됩니다.\\[\\boldsymbol{X}^n = \\boldsymbol{V} \\boldsymbol{\\Lambda}^n \\boldsymbol{V}^{-1}\\]3.3   SVDSVD는 고유값 분해와 마찬가지로 행렬 분해 기법입니다. 다만 고유값 분해가 정방 행렬에 대해서만 가능하다면, SVD는 직사각 행렬에도 적용할 수 있는 아주 큰 장점이 있습니다. \\(m \\times n\\) 행렬 \\(\\boldsymbol{A}\\)에 대한 특이값 분해는 다음과 같이 나타낼 수 있습니다.\\[\\boldsymbol{A} = \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{T}\\]여기서 \\(\\boldsymbol{U}\\)는 \\(\\boldsymbol{AA}^{T}\\)를 고유값 분해해서 얻어진 행렬이며, \\(\\boldsymbol{V}\\)는 \\(\\boldsymbol{A}^{T}\\boldsymbol{A}\\)를 고유값 분해하여 얻어진 행렬입니다. SVD에 대한 더 자세한 내용은 향후에 더 자세히 다루고, 이글에 링크를 연결해 두겠습니다.4   대칭행렬과 고유값 분해4.1   대칭행렬의 의미와 특성대칭행렬이란 \\(n \\times n\\) 정방행렬이면서 \\(\\boldsymbol{X} = \\boldsymbol{X}^T\\)를 만족하는 행렬을 뜻합니다. 대표적으로 공분산 행렬이 대칭행렬입니다. 대칭행렬은 아래의 두 가지 특성을 지니고 있습니다. 항상 고유값 분해가 가능합니다. 고유값 분해시 직교 행렬(orthogonal matrix)2로 분해가 된다는 특징도 있습니다.직교 행렬은 \\(\\boldsymbol{X}\\boldsymbol{X}^T = \\boldsymbol{I}\\)(단위행렬)인 행렬을 말하며, 각 행벡터는 행벡터끼리 열벡터들은 열벡터끼리 서로간 직교 하면서 크기가 1인 특성이 있습니다. 다시 말해 벡터들이 정규 직교(orthonomal) 한다는 것입니다. 대칭행렬은 SVD를 다루면서 좀더 자세하게 언급할 기회가 있을 것 같습니다.정리하자면 대칭행렬을 고유값 분해하면 다음과 같은 결과를 얻을 수 있습니다.\\[\\begin{align} \\boldsymbol{X} &amp;amp;= \\boldsymbol{V \\Lambda V^{-1}}\\\\ &amp;amp;=\\boldsymbol{V \\Lambda V}^T \\end{align}\\]Appendix고유값 분해 가능 조건고유값 분해는 다음의 두 조건을 만족하는 행렬에 대해서만 가능합니다. 행렬 \\(\\boldsymbol{X}\\)는 \\(n \\times n\\) 정방 행렬입니다. 행렬 \\(\\boldsymbol{X}\\)는 \\(n\\)개의 선형 독립(linearly independent)1 고유벡터를 가집니다.고유벡터의 선형 독립과 관련된 조건은 사실 가역 행렬(invertable matrix) 조건과 관련 있습니다. 어떤 행렬 \\(\\boldsymbol{V}\\)의 열벡터들이 선형 독립이라면 행렬 \\(\\boldsymbol{V}\\)는 역행렬을 가질 수 있습니다. 이를 수식으로 표현하면 다음과 같습니다.\\[\\begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; |\\\\ \\boldsymbol{v}_1 &amp;amp; \\boldsymbol{v}_2 &amp;amp; \\cdots &amp;amp; \\boldsymbol{v}_n\\\\ | &amp;amp; | &amp;amp; &amp;amp;|\\end{bmatrix} \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} = \\boldsymbol{0} \\\\[1em]\\]\\[\\boldsymbol{V}\\boldsymbol{c} = \\boldsymbol{0}\\]만일 \\(\\boldsymbol{v}_{1, \\cdots, n}\\)가 선형 독립이라면 위 수식을 만족시키는 유일한 해는 \\(c_1 = \\cdots = c_n = 0\\) 입니다. 따라서 행렬 \\(\\boldsymbol{V}\\)는 가역행렬이라는 사실을 도출할 수 있습니다. 행렬 \\(\\boldsymbol{V}\\)가 가역 행렬이라는 것은 \\(\\boldsymbol{V}\\)의 열벡터들이 선형 독립이라는 것과 동치입니다.우리 예시에서 \\(\\boldsymbol{V}\\)는 원 행렬 \\(\\boldsymbol{X}\\)의 고유 벡터를 열벡터로 하는 행렬입니다. 따라서 행렬 \\(\\boldsymbol{V}\\)가 선형 독립이라는 사실은 \\(n \\times n\\) 행렬 \\(\\boldsymbol{X}\\)이 \\(n\\)개의 선형 독립 고유벡터를 가진다는 사실을 뜻하게 됩니다.\\[\\boldsymbol{XV}\\boldsymbol{V}^{-1} = \\boldsymbol{V\\Lambda} \\boldsymbol{V}^{-1}\\]\\[\\boldsymbol{X}= \\boldsymbol{V\\Lambda} \\boldsymbol{V}^{-1}\\]Reference 대각화와 고유값 분해 Proof that columns of an invertible matrix are linearly independent 정방행렬의 대각화(diagonalization): 고유값 분해(eigendecomposition).txt 선형독립(linearly independent), 선형종속(linearly dependent) Eigenvalue Decompositionfootnote \\(k\\)개의 벡터 \\(\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\cdots, \\boldsymbol{v}_k\\)에 대해서 이들 벡터의 선형 결합인 \\(c_1\\boldsymbol{v}_1+c_2\\boldsymbol{v}_2+\\cdots+c_k\\boldsymbol{v}_k = 0\\)를 만족하는 해가 \\(c_1=c_2=\\cdots=c_k=0\\)가 유일하다면 이를 선형 독립이라고 합니다. 다른 말로 하면 \\(k\\)개의 벡터 중 임의의 벡터 \\(\\boldsymbol{v}_i\\)를 다른 벡터들의 선형결합으로 표현할 수 없는 것입니다. 대비되는 개념은 선형 의존(linearly dependent)입니다. &amp;#8617; &amp;#8617;2 \\(\\boldsymbol{XX}^T = \\boldsymbol{I}\\), 즉 자신과 대칭인 행렬과 곱하면 단위 행렬이 되는 행렬입니다. 역행렬의 정의에 따라 \\(\\boldsymbol{X}^{-1} = \\boldsymbol{X}^T\\)입니다. &amp;#8617; " }, { "title": "PCA(주성분 분석)", "url": "/posts/PCA/", "categories": "Math, Linear algebra", "tags": "pca", "date": "2021-01-11 11:28:00 +0900", "snippet": "원래 데이터들을 어느 벡터에 사영시켜야 데이터의 구조를 최대한 보존할 수 있을까?3줄 요약 PCA는 데이터의 기존 구조를 최대한 유지하고자 하는 목적을 가진 변수 추출 또는 차원 축소 기법임 데이터의 기존 구조를 최대한 유지 하기 위해서는 사영(projection) 하였을 때 분산이 최대가 되는 방향의 벡터를 찾아야 함 데이터의 공분산 행렬의 고유벡터가 분산이 최대가 되는 방향의 벡터임본 글을 이해하기 위해 필요한 개념 내적 사영(projection) 대칭 행렬 공분산 행렬(covariance matrix) 고유값과 고유벡터 벡터 미분 라그랑주 승수법앞선 글에서 고유값과 고유벡터에 대해 살펴 보았습니다. 본 글에서는 이를 활용한 대표적 변수 추출 또는 차원 축소 기법인 주성분 분석(PCA)에 관련된 내용을 정리하고자 합니다. 머신러닝을 공부해보신 분들은 한번쯤은 들어보셨을 텐데요. 매우 친숙한 알고리즘인데 반해 선형대수 기초 개념이 없으면 생각보다 이해하기 어려운 것도 사실입니다. 저와 함께 차근차근 알아가 보시죠. 본 글에서는 PCA의 개념을 살펴보고 PCA의 해를 찾는 방법, PCA의 가정과 활용 예시를 살펴보도록 하겠습니다.본 글의 행렬, 벡터, 벡터의 원소의 표기는 다음을 따릅니다. 행렬: \\(\\boldsymbol{X}\\) 벡터: \\(\\boldsymbol{x}\\) 벡터의 원소: \\(x_1, x_2, \\cdots, x_i\\)1   PCA(주성분 분석)개요PCA는 주어진 데이터들의 구조를 최대한 보존할 수 있는 주성분(principal component)을 찾아주는 변수 추출(feature extraction) 기법입니다. PCA는 비모수적 기법으로 분포적인 가정을 요구하지 않기 때문에 매우 다양한 분야에서 활용되고 있습니다. 주성분과 변수 추출이라는 어려운 단어가 2개나 나왔네요. 먼저 이해하기 쉬운 것부터 살펴보겠습니다.변수 추출변수 추출이란 데이터가 가진 변수를 조합하여 새로운 변수를 만드는 기법을 말합니다. 예를들어 수학 점수와 영어 점수로 이루어진 데이터가 있다고 해봅사다. 수학 점수와 영어 점수를 잘 조작해서 새로운 변수를 만들 수도 있겠죠. 가장 간단하게는 \\(0.5 \\times\\)수학점수 + \\(0.5 \\times\\)영어 점수를 통해 새로운 변수를 만들 수도 있습니다. 이를 내적의 형태로 표현하면 다음과 같이 표현할 수 있습니다.\\[\\left[ \\begin{matrix} \\text{수학 점수} &amp;amp; \\text{영어 점수} \\end{matrix} \\right]\\\\\\left[ \\begin{matrix} 0.5 \\\\ \\\\ 0.5 \\end{matrix} \\right]= 0.5 \\times \\text{수학 점수} + 0.5 \\times \\text{영어 점수}\\]그렇다면 어떤 벡터에 데이터를 내적해야 기존 변수들을 잘 종합할 수 있을지에 대한 의문이 생깁니다. PCA는 이에 대한 답을 제공합니다. 그러나 막연하게 생각하면 어려우니까 데이터의 구조 혹은 분포를 활용해보자는 아이디어에서 출발하는 것이죠. 정리하자면 PCA는 어떻게 하면 데이터를 잘 종합하는 변수를 만들 수 있을까에 대한 솔루션인 셈입니다. 한편 PCA를 차원축소 기법으로도 많이 이야기 하는데, 이는 PCA를 수행하여 찾아낸 모든 고유벡터를 활용하지 않고 일부의 고유벡터만 활용한다면 데이터의 차원을 축소 할 수 있기 때문입니다. 고유벡터와 관련된 개념은 뒤에서 더 자세히 설명하겠습니다.주성분(principal component)다음으로 주성분입니다. 주성분이란 데이터를 사영1 시켰때 사영된 데이터들의 분산이 최대화 되는 벡터를 말합니다. 글만 보면 이해하기 어렵습니다. 아래 두 이미지를 보시죠. 두 이미지는 파란색 점으로 표현된 데이터들을 검은색 실선으로 표현된 두개의 벡터에 각각 사영시켰습니다. 사영된 데이터들을 빨간색 점으로 나타냈는데요. 사영된 데이터들의 분산이 최대가 되는 (데이터가 더 넓게 퍼져 있는) 벡터는 무엇인가요?왼쪽보다는 오른쪽 벡터가 빨간색 점들이 더 넓게 분포 되어 있음을 알 수 있습니다. 다시 말해 왼쪽 이미지는 분산이 낮고 오른쪽 이미지는 분산이 높다는 것이죠. 이렇게 기하학적으로 보았을 때 어느 쪽이 더 원래의 데이터의 형태를 잘 유지하고 있나요? 물론 두 이미지 모두 기존 데이터가 가진 정보는 일부 상실되었습니다. 그럼에도 불구하고 최대한 기존 구조를 유지하며 정보가 압축된 이미지는 어느 것인가요? 바로 오른쪽 이미지이죠.주성분은 데이터를 사영시켰을 때 기존 구조를 최대한 잘 유지할 수 있게 하는 벡터를 뜻합니다. 데이터의 기존 구조가 최대한 잘 유지 된다는 뜻은 바로 사영 후의 분산이 최대가 되는 것이구요. 그렇다면 결국 PCA라는 알고리즘이 하고 싶은 것은 데이터를 사영 후 분산이 최대가 되도록 하는 벡터를 찾는 일로 귀결됨을 알 수 있습니다. 또한 예시는 2차원을 보여드렸지만 3차원 또는 그 이상에서도 같은 논리로 분산이 최대가 되는 벡터를 찾아 볼 수 있습니다.2   PCA의 가정 및 특성PCA의 가정PCA는 아래의 3가지 가정에 기반하고 있습니다. 그러나 이러한 가정이 항상 들어 맞지는 않겠죠. 데이터의 형태에 따라 PCA는 실패(fail)하기도 합니다(Shlens, J., 2014).Linearity사영된 데이터들은 직선 위에 존재한다고 가정합니다. 그러나 아래의 이미지처럼 데이터들이 곡선을 따라 사영되었을 때 더욱 데이터의 구조를 잘 유지할 수 있는 경우도 있습니다. 기본적인 PCA는 이러한 비선형성을 잡아내지 못합니다. 따라서 비선형성을 반영할 수 있는 non-linear PCA 기법도 존재한다고 합니다.non-linear PCA의 예시 (출처: http://www.nlpca.org/)Large variances have important structure분산이 큰 방향이 데이터 구조의 중요한 정보를 가지고 있다고 가정합니다. 그러나 이러한 가정 역시 데이터의 구조에 따라 위배가 되는 경우가 있습니다. 아래의 그림은 놀이동산 관람차를 탄 사람들의 좌표값을 나타낸 그림입니다. 빨간색 축은 데이터의 분산이 가장 큰 방향의 축입니다. 그러나 기존 데이터를 종합한다는 의미로 볼때, 해당 축에 사영하는 것이 가장 좋은 선택일까요? 아래 그림에서는 오히려 관람차의 회전 각도 \\(\\theta\\)라는 하나의 변수만 있으면 3차원 데이터를 1차원 스칼라 값으로 압축할 수 있습니다. 다시 말해 데이터를 압축하여 표현할 때 분산이 최대인 축을 선택하는 것이 능사가 아니라는 것입니다.“A Tutorial on Principal Component Analysis”, Jonathon ShlensThe principal components are orthogonal주성분끼리는 항상 직교(orthogonal) 한다고 가정합니다. 이 가정 역시 모든 데이터에 항상 맞는 가정은 아닌데요. 아래의 그림을 보시면 빨간색 축이 데이터의 분산이 가장 큰 방향의 벡터입니다. 가로로 긴 첫번째 축은 데이터의 구조를 표현하기에 적절한 선택인 것 같습니다. 그러나 이 축과 직교하는 두번째 축은 non-orthogonal한 데이터의 특징을 잘 잡아내지 못합니다.“A Tutorial on Principal Component Analysis”, Jonathon Shlens3   PCA 해 찾기이제 직접 사영시켰을 때 분산이 최대가 되는 벡터 \\(\\boldsymbol{v}\\)를 찾아보죠 🙌 그전에 몇 가지 가정할 사항이 있습니다. 우리가 찾을 벡터 \\(\\boldsymbol{v}\\)는 단위 벡터2입니다 데이터 행렬 \\(\\boldsymbol{X}\\)는 \\(n\\)개의 데이터, \\(d\\)개의 변수(feature)를 가진 \\(n \\times d\\) 행렬입니다. 데이터 행렬 \\(\\boldsymbol{X}\\)의 각 변수들은 평균이 \\(0\\)으로 centering 되어있습니다. 다시 말해 데이터 행렬 \\(\\boldsymbol{X}\\)의 \\(k\\)번째 열벡터 \\(\\boldsymbol{x}_k\\)는 \\(\\boldsymbol{x}_k - E(\\boldsymbol{x}_k)\\)가 되어 있는 상태입니다. 앞으로 등장할 설명과 수식은 \\(d\\)차원의 데이터 \\(\\boldsymbol{X}\\)를 1차원으로 차원 감소하는 상황을 가정한 예시들입니다.\\(n \\times d\\) 데이터 행렬은 다음과 같이 표기합니다.\\[\\boldsymbol{X}=\\left[ \\begin{matrix} x_{11} &amp;amp; \\cdots &amp;amp; x_{1d} \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ x_{n1} &amp;amp; \\cdots &amp;amp; x_{nd} \\end{matrix} \\right] = \\left[ \\begin{matrix} | &amp;amp; \\cdots &amp;amp; | \\\\ \\boldsymbol{x}_1 &amp;amp; \\ddots &amp;amp; \\boldsymbol{x}_d \\\\ | &amp;amp; \\cdots &amp;amp; | \\end{matrix} \\right]\\]자, 이제 우리는 데이터 행렬 \\(X\\)를 어떤 벡터 \\(\\boldsymbol{v}\\)에 사영해야 사영된 데이터들의 분산이 최대가 될지를 찾아야 합니다. 이는 데이터 행렬 \\(\\boldsymbol{X}\\)의 행벡터들과 열벡터 \\(\\boldsymbol{v}\\)를 내적하는 것으로 구할 수 있습니다. 사영과 내적이 어떤 관련이 있는걸까요? 우리는 앞서 벡터 \\(\\boldsymbol{v}\\)를 단위 벡터라고 가정했습니다. 따라서 어떤 벡터의 단위 벡터에 대한 정사영 벡터는 두 벡터를 내적하는 것만으로도 도출할 수 있습니다3 사영과 관련된 내용은 이 글을 추천드립니다. 행벡터와 열벡터 \\(\\boldsymbol{v}\\)의 내적을 일일이 진행할 수 없으니 matrix notation을 통해 표현해 보죠. 참고로 \\(\\boldsymbol{X}\\boldsymbol{v}\\) 는 \\(n \\times 1\\) 크기를 가지는 열벡터입니다.\\[\\boldsymbol{X}\\boldsymbol{v}=\\left[ \\begin{matrix} x_{11} &amp;amp; \\cdots &amp;amp; x_{1d} \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ x_{n1} &amp;amp; \\cdots &amp;amp; x_{nd} \\end{matrix} \\right]\\left[ \\begin{matrix} v_1 \\\\ \\vdots \\\\ v_d \\end{matrix}\\right]\\]데이터 \\(\\boldsymbol{X}\\)를 어떤 단위 벡터 \\(\\boldsymbol{v}\\)에 사영하는 것은 \\(\\boldsymbol{Xv}\\) 를 계산하는 것과 같다는 것을 알게되었습니다. 그럼 사영된 데이터의 분산이 최대가 되는 벡터 \\(\\boldsymbol{v}\\)를 찾는 것을 수식으로 표현해볼까요?\\[\\DeclareMathOperator*{\\argmax}{argmax}\\argmax_{\\boldsymbol{v}}\\Big[Var(\\boldsymbol{X}\\boldsymbol{v})\\Big]\\]이제 \\(Var(\\boldsymbol{X}\\boldsymbol{v})\\)를 전개해 나가 보겠습니다.\\[\\begin{align} Var(\\boldsymbol{X}\\boldsymbol{v}) \\tag{1} &amp;amp;= E[(\\boldsymbol{X}\\boldsymbol{v})^2] - E[(\\boldsymbol{X}\\boldsymbol{v})]^2 \\\\[1em] \\tag{2} &amp;amp;= \\cfrac{1}{n} \\sum_{i=1}^{n}x_i^2 - \\bigg(\\cfrac{1}{n}\\sum_{i=1}^{n}x_i \\bigg)^2 \\\\[1em] \\tag{3} &amp;amp;= \\cfrac{1}{n} \\sum_{i=1}^{n}x_i^2 \\\\[1em] \\tag{4} &amp;amp;= \\cfrac{1}{n} (\\boldsymbol{X}\\boldsymbol{v})^{T} (\\boldsymbol{X}\\boldsymbol{v}) \\\\[1em] \\tag{5} &amp;amp;= \\cfrac{1}{n} \\boldsymbol{v}^{T}\\boldsymbol{X}^{T}\\boldsymbol{X}\\boldsymbol{v} \\\\[1em] \\tag{6} &amp;amp;= \\boldsymbol{v}^{T} \\cfrac{\\boldsymbol{X}^{T}\\boldsymbol{X}}{n} \\boldsymbol{v} \\\\[1em] \\tag{7} &amp;amp;= \\boldsymbol{v}^{T} \\Sigma \\boldsymbol{v}\\end{align}\\]\\((2)\\)의 \\(\\bigg(\\cfrac{1}{n}\\sum_{i=1}^{n}x_i \\bigg)^2\\)은 \\(0\\)이 되어 사라지는 term입니다. 그 이유는 우리가 데이터 행렬 \\(\\boldsymbol{X}\\)의 열벡터들이 모두 평균 0으로 centering 되어 있다고 가정했기 때문입니다. 직접 숫자를 대입해 계산 해보시면 쉽게 이해가 가실겁니다. 또한 \\((6)\\)의 \\(\\cfrac{\\boldsymbol{X}^{T}\\boldsymbol{X}}{n}\\)는 공분산 행렬을 나타내는데요. 이 역시도 데이터 행렬 \\(\\boldsymbol{X}\\)의 열벡터들이 모두 평균 0으로 centering 되어 있다고 가정했기 때문입니다.목적식을 \\(\\boldsymbol{v}^{T} \\Sigma \\boldsymbol{v}\\), 제약식을 \\(\\|\\boldsymbol{v}\\|= \\boldsymbol{v}^T\\boldsymbol{v} = 1\\)으로 두고 라그랑주 승수법4을 이용하여 다음의 보조 방정식 \\(L\\)을 만들 수 있습니다. 제약식은 \\(\\boldsymbol{v}\\)를 단위벡터로 가정한 결과로 도출되었습니다.\\[L = \\boldsymbol{v}^{T} \\Sigma \\boldsymbol{v} - \\lambda(\\|\\boldsymbol{v}\\|-1)\\]최대값을 구하기 위해 \\(L\\)을 \\(\\boldsymbol{v}\\)에 대해 편미분한 식을 \\(0\\)으로 두고 전개하겠습니다. 벡터의 미분 공식은 이 글을 참고해주세요.\\[\\cfrac{\\partial L}{\\partial \\boldsymbol{v}} = 2\\Sigma\\boldsymbol{v} - 2\\lambda\\boldsymbol{v} = 0\\]최종적으로 아래의 식을 얻을 수 있습니다.\\[\\Sigma\\boldsymbol{v} = \\lambda\\boldsymbol{v}\\]어딘가 익숙한 수식 아닌가요? 어떤 벡터에 선형변환 행렬을 곱했더니 크기는 변하지만 방향이 변하지 않는 벡터가 있다는 뜻이네요. 바로 고유값과 고유벡터에 관한 수식임을 알 수 있습니다.따라서 PCA가 하는 일은 데이터 행렬 \\(\\boldsymbol{X}\\)의 공분산 행렬 \\(\\Sigma\\)의 고유 벡터를 찾는 것입니다. 또한 우리가 수식을 전개해와서 알 수 있듯이 그 고유 벡터가 데이터들의 사영 후 분산을 최대화 시키는 벡터입니다. 또한 우리는 고유벡터끼리의 직교성을 가정하였는데요. 공분산 행렬의 고유벡터는 서로 직교하는 성질이 (정확하게는 대칭행렬5의 특성) 있기 때문에 가정에 위배 되지 않습니다.고유벡터는 최대 데이터 행렬 \\(\\boldsymbol{X}\\)의 차원 수인 \\(d\\)개 만큼 존재할 수 있습니다. 따라서 \\(d\\)개의 고유벡터를 활용한다면 데이터의 차원은 \\(d\\)차원으로 유지할 수 있으면서도 각 열벡터들의 상관 관계를 제거할 수 있는 결과를 가져다 줍니다 (공분산 행렬의 고유벡터들은 서로 orthogonal 하기 때문입니다 ). 또한 고유벡터를 \\(k(\\lt d)\\)개 만큼만 사용한다면 \\(d\\)차원을 \\(k\\)차원으로 차원축소 할 수 있게 됩니다.4   PCA 활용 방법차원 축소를 통한 시각화아래의 이미지처럼 3차원 공간에 존재하는 데이터들을 2개의 고유벡터에 사영시키면 2차원의 데이터로 차원을 축소할 수 있습니다. 따라서 고차원의 데이터를 우리가 쉽게 상상할 수 있는 2차원이나 3차원 데이터로 표현하므로써 데이터에 대한 기하학적 해석을 용이하게 할 수 있습니다.3차원 데이터를 2차원으로 축소한 예시선형 회귀의 데이터로 활용공분산 행렬의 고유 벡터들을 서로 직교(orthogonal) 하는 특성이 있습니다 (정확하게는 대칭행렬5의 특성입니다). 직교하는 벡터는 상관관계가 0이기 때문에 서로 다른 고유 벡터에 사영하여 얻어진 벡터들은 상관관계가 없어집니다. 다시 말해 correlation이 있는 변수들을 decorrelation 하게 변환시켜줄 수 있다는 의미이죠. 따라서 PCA를 통한 변수 추출을 통해 다중공선성 문제에서 벗어날 수 있습니다.참고자료 주성분 분석(PCA), 공돌이의 수학정리노트 주성분분석(Principal Component Analysis), ratsgo’s blog 주성분분석(PCA)의 이해와 활용, 다크 프로그래머 PCA (Principal Component Analysis): 주성분분석에 대한 모든 것! , 통계학에 관한 모든것 Principal Components: Mathematics, Example, Interpretation An Introduction to Principal Component Analysis (PCA) with 2018 World Soccer Players Data, Kan Nishida Shlens, J. (2014). A tutorial on principal component analysis. arXiv preprint arXiv:1404.1100. 고유값 분해와 뗄래야 뗄 수 없는 주성분분석, bskyvision Matrix calculus, wikipedia 벡터 미분과 행렬 미분, 다크 프로그래머 사영(projection), ratsgo’s blog 대각화와 고유값 분해 라그랑주 승수법, 위키피디아footnote 도형의 각 점에서 한 평면에 내린 수선의 발을 의미합니다. &amp;#8617; 길이가 1인 벡터를 뜻합니다. \\(\\|v\\|=1\\) &amp;#8617; 벡터 \\(\\boldsymbol{k}\\)를 벡터 \\(\\boldsymbol{v}\\)에 사영하여 얻을 수 있는 벡터는 \\(c\\boldsymbol{v}\\)로 나타낼 수 있습니다 (\\(c\\)는 스칼라). 이때 \\(c=\\cfrac{\\boldsymbol{k}^T \\boldsymbol{v}}{\\boldsymbol{v}^T \\boldsymbol{v}}\\)입니다. 만일 \\(\\boldsymbol{v}\\)가 단위벡터라면 \\(\\boldsymbol{v}^T\\boldsymbol{v}=1\\) 이므로 \\(c=\\boldsymbol{k}^T\\boldsymbol{v}\\), 즉 두 벡터의 내적을 통해서 구할 수 있습니다. &amp;#8617; 주어진 제약 조건 하에서 최댓값이나 최솟값을 찾는 최적화 문제를 푸는 방법입니다. &amp;#8617; 정방행렬(square matrix)이면서 \\(\\boldsymbol{A} = \\boldsymbol{A}^T\\)를 만족하는 행렬을 뜻합니다. &amp;#8617; &amp;#8617;2 " }, { "title": "고유값(eigen value)과 고유벡터(eigen vector)", "url": "/posts/eigenvalue_eigenvector/", "categories": "Math, Linear algebra", "tags": "eigenvalue, eigenvector", "date": "2021-01-05 22:20:00 +0900", "snippet": "방향은 변하지 않고 크기만 변하는 벡터를 찾아라!두줄 요약 !! 선형 변환을 했을 때 크기는 변하나 방향은 변하지 않는 벡터를 고유벡터라고 하고 변하는 크기는 고유값이라 함 행렬 분해 기법(EVD, SVD)과 PCA 등 여러 응용 사례의 가장 기초가 되는 개념 선형대수학 개념 중 고유값(eigen value)와 고유벡터(eigen vector)는 머신러닝과 아주 밀접한 관련이 있습니다. 머신러닝을 공부해보신 분들은 한번쯤은 꼭 들어보셨을 PCA, SVD 및 행렬 분해를 활용한 추천 시스템 등의 근간이 되는 개념입니다. 그러나 그 의미를 직관적으로 이해하기는 쉽지 않습니다. 이번 글에서는 직관을 기르기 위해 고유값과 고유벡터의 수식적 의미와 기하학적 의미를 살펴보고 간단하게 예시를 들어 직접 계산 해보겠습니다. 그리고 고유값과 고유벡터를 활용하는 응용 분야에 대해서 간단하게 짚고 넘어가겠습니다. 사실 이번 글은 응용 분야를 차례대로 정리하기 위한 시작글입니다. 관련 내용 계속 포스팅 하겠습니다.1   고유값(eigen value)과 고유벡터(eigen vector)란?기본적 의미행렬을 선형 변환1이라고 한다면 선형 변환 정방행렬 \\(A\\)를 가했을 때 크기(scale)만 변하고 방향은 변하지 않는 영벡터가 아닌 벡터를 고유벡터(eigen vector) \\(\\vec{v}\\) 라고 하며 이때의 크기를 고유값(eigen value) \\(\\lambda\\)라고 합니다. 좀더 정확하게 말하면 고유값과 고유벡터는 행렬에 대응되는 개념입니다. 따라서 고유값 \\(\\lambda\\)는 행렬 \\(A\\)의 고유값 \\(\\lambda\\)이며 고유벡터 \\(\\vec{v}\\)는 행렬 \\(A\\)의 고유값 \\(\\lambda\\)에 대한 고유벡터 \\(\\vec{v}\\)라고 표현하는 것이 더욱 정확하겠습니다. 말로 풀어쓴 것을 수식으로 정리하면 매우 간단합니다.\\[A\\vec{v} = \\lambda \\vec{v}\\]\\[\\left[ \\begin{matrix} a_{11} &amp;amp; \\cdots &amp;amp; a_{1n} \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ a_{n1} &amp;amp; \\cdots &amp;amp; a_{nn} \\end{matrix} \\right]\\left[ \\begin{matrix} v_{1} \\\\ \\vdots \\\\ v_{n} \\end{matrix}\\right] = \\lambda\\left[ \\begin{matrix} v_{1} \\\\ \\vdots \\\\ v_{n} \\end{matrix}\\right]\\]위 수식의 우항을 좌항으로 넘겨서 수식을 정리해보면 다음과 같이 나타낼 수 있습니다. 이 수식을 특성 방정식(chracteristic equation)이라고 하며 고유값과 고유벡터를 구하는 것은 특성 방정식의 해를 찾는 것입니다. 이 방정식을 고유값 \\(\\lambda\\)에 대해서 풀고, 다시 그 값을 대입하여 고유벡터 \\(\\vec{v}\\)를 찾을 수 있습니다.\\[(A-\\lambda I)\\vec{x} = 0\\]이 방정식의 \\(\\lambda\\) 해를 어떻게 찾을 수 있을까요? 고유 벡터의 정의를 말씀드렸을 때 고유벡터는 영벡터가 아닌 벡터이다 라고 말씀 드렸죠. 그 조건을 활용해 보자구요. 고유벡터가 영벡터가 아니기 위해서는 \\((A-\\lambda I)\\) 행렬이 역행렬2이 존재하지 않아야 합니다. 만일 \\((A-\\lambda I)\\)이 역행렬을 가지게 된다면 좌항과 우항에 \\((A-\\lambda I)^{-1}\\)을 곱해서 \\(\\vec{x}=0\\)이 되기 때문입니다. 이는 고유벡터의 정의에 위배되는 것이죠. 따라서 특성 방정식의 \\(\\lambda\\) 에 대한 해를 구하기 위해서는 행렬식3의 값이 0 이어야 함을 알 수 있습니다.\\[det(A-\\lambda I)=0\\]마지막으로 중요하게 짚고 넘어가야 할 점이 있습니다. 고유값과 고유벡터는 \\(n \\times n\\) 정방 행렬 \\(A\\)에 대해서만 구할 수 있습니다. 고유값은 행렬에 대해 유한한데 비해, 고유벡터를 유일한 값이 아닙니다. 다시 말해 특정 고유값은 여러개의 고유벡터를 가질 수 있습니다(이 개념은 섹션2를 읽어보시면 이해가 쉽게 되실 겁니다.)기하학적 의미행렬은 선형변환이라는 사실을 알고 있다면 특정 행렬 \\(A\\)와 특정 벡터 \\(\\vec{v}\\)가 있을 때, 그 둘을 곱하는 것은 벡터 \\(\\vec{v}\\)를 새로운 기저 벡터로 표현하는 것이라는 사실을 이해하실 수 있을 것입니다. 따라서 대부분의 경우에는 기존 벡터 \\(\\vec{v}\\)와 선형 변환 후의 벡터 \\(A\\vec{v}\\)의 크기나 방향이 모두 달라질 가능성이 높습니다. 그러나 선형 변환후에도 크기는 달라질 수 있지만 방향이 변하지 않는 벡터들도 존재합니다. 그러한 벡터들을 고유벡터라고 하죠. 아래 이미지를 살펴봅시다. 두 이미지는 원래의 이미지가 옆으로 기울어진 이미지로 변화하는 선형 변환을 보여 주고 있습니다.선형 변환전에는 빨간색 벡터와 파란색 벡터가 각각 \\(\\vec{v}=\\left[\\begin{matrix} 0 \\\\ 5 \\end{matrix} \\right]\\), \\(\\vec{k}=\\left[\\begin{matrix} 5 \\\\ 0 \\end{matrix} \\right]\\)를 나타냅니다. 그러나 선형 변환후에는 빨간색 벡터와 파란색 벡터가 각각 \\(\\vec{v}=\\left[\\begin{matrix} 1.2 \\\\ 5 \\end{matrix} \\right]\\), \\(\\vec{k}=\\left[\\begin{matrix} 5 \\\\ 0 \\end{matrix} \\right]\\)입니다. 빨간색 벡터 \\(\\vec{v}\\)는 크기와 방향이 모두 변화한 반면에 파란색 벡터 \\(\\vec{k}\\)는 크기만 1만큼 변화하였고 방향은 변화하지 않았습니다. 따라서 선형 변환 후에도 크기는 변하지만 방향은 변하지 않는 벡터 \\(\\vec{k}\\)는 해당 선형 변환의 고유벡터입니다. 크기는 1만큼 변했으므로 고유값 \\(\\lambda\\)는 1이라고 할 수 있겠네요.2   직접 고유값과 고유벡터를 계산해보자선형 변환 행렬 \\(A=\\left[\\begin{matrix} 2 &amp;amp; 1 \\\\ 1 &amp;amp; 2 \\end{matrix} \\right]\\)일 때, 고유값 \\(\\lambda\\)와 고유벡터 \\(\\vec{v}\\)를 찾아보겠습니다. 먼저 섹션 1에서 서두에 언급한 고유값과 고유벡터의 정의를 수식으로 다시 적어보겠습니다.\\[A\\vec{x} = \\lambda \\vec{x}\\]또한 위에서 언급하였듯이 \\(\\vec{x}\\)가 non-trivial solution이기 위해서는 다음의 식을 만족해야 합니다.\\[det(A-\\lambda I) = 0\\]위 수식에 실제 값을 대입하면,\\[\\begin{align}det(A-\\lambda I)&amp;amp;= det\\bigg(\\left[\\begin{matrix} 2 &amp;amp; 1 \\\\ 1 &amp;amp; 2 \\end{matrix} \\right] - \\lambda \\left[\\begin{matrix} 1 &amp;amp; 0 \\\\ 0 &amp;amp; 1 \\end{matrix} \\right] \\bigg) \\\\[1em]&amp;amp;= det\\bigg(\\left[\\begin{matrix} 2-\\lambda &amp;amp; 1 \\\\ 1 &amp;amp; 2-\\lambda \\end{matrix} \\right] \\bigg) \\\\[1em]&amp;amp;= \\lambda^2 -4 \\lambda +3 \\\\[1em]&amp;amp;= (\\lambda-3)(\\lambda-1) \\\\[1em]&amp;amp;= 0\\end{align}\\]따라서 행렬 \\(A\\)의 고유값은 \\(\\lambda = 3\\), \\(\\lambda=1\\)임을 얻어내었습니다. 이제 이 값을 이용하여 고유 벡터를 찾아보죠. 먼저 \\(\\lambda=1\\) 일때의 고유벡터를 찾아볼게요. \\(A\\vec{x} = \\lambda \\vec{x}\\)에 \\(\\lambda=1\\)를 대입하면,\\[\\left[\\begin{matrix} 2 &amp;amp; 1 \\\\ 1 &amp;amp; 2 \\end{matrix} \\right] \\left[\\begin{matrix} v_1 \\\\ v_2 \\end{matrix} \\right] = 1 \\left[\\begin{matrix} v_1 \\\\ v_2 \\end{matrix} \\right] \\tag{1}\\]위 수식은 아래의 연립방정식을 계산 하는 것입니다.\\[\\begin{align}2v_1 + v_2 &amp;amp;= v_1 \\\\v_1 + 2v_2 &amp;amp;= v_2\\end{align}\\]따라서 얻을 수 있는 솔루션은\\[v_1 = -v_2\\]따라서 고유값이 \\(\\lambda=1\\)일때의 고유 벡터는 \\(\\left[\\begin{matrix} 1 \\\\ -1 \\end{matrix} \\right]\\), \\(\\left[\\begin{matrix} 0.8 \\\\ -0.8 \\end{matrix} \\right]\\) 등의 여러 값을 가질 수 있습니다.이쯤에서 애매함을 느끼실 것 같습니다. ‘고유값을 구하는 것까지는 딱 떨어져서 이해 했는데, 고유벡터는 여러개의 값을 가질 수 있는건가?’ 네 그렇습니다. 섹션 1에서도 잠깐 언급했지만 어떤 행렬의 고유값은 유한하게 딱 정해져 있지만 고유값에 대응되는 고유벡터는 다수 존재할 수 있습니다. 이는 실제로 여러가지 값을 대입 해보면 이해가 됩니다.이처럼 고유벡터는 여러개가 될 수 있으므로 일반적으로는 고유벡터를 단위벡터4로 표기 한다고 합니다. 그렇다면 본 예시에서는 고유값 \\(\\lambda=1\\)에 대응되는 고유벡터를 \\(\\left[\\begin{matrix} 1 / \\sqrt{2}\\\\ -1 / \\sqrt{2} \\end{matrix} \\right]\\)로 나타낼 수 있습니다.같은 방식으로 고유값 \\(\\lambda=3\\) 일때의 고유 벡터는 \\(\\left[\\begin{matrix} 1 / \\sqrt{2}\\\\ 1 / \\sqrt{2} \\end{matrix} \\right]\\)입니다.3  응용고유값 분해(eigen decompostion)정방행렬을 대각화5하는 방법입니다. 그러나 모든 정방 행렬이 고유값 분해가 가능한 것은 아닙니다. \\(n \\times n\\) 정방 행렬 \\(A\\)를 고유값 분해하기 위해서는 행렬 \\(A\\)가 \\(n\\)개의 선형 독립(linearly independent)6인 고유벡터를 가져야 합니다. 자세한 내용은 추후에 포스팅 하도록 하겠습니다.PCA(주성분 분석)앞서 기하학적 의미에서 살펴 보았듯이 고유벡터는 변화의 ‘축’ 이라고도 생각할 수 있겠습니다. 마치 지구가 자전하는 3차원 선형 변환에서 자전축은 고정된 것처럼 말이죠. 고유벡터를 변화의 축이라는 개념을 활용한 기법이 바로 PCA입니다. PCA는 데이터가 가진 정보를 최대한 보존하면서 변수를 추출하는 기법입니다. 데이터가 가진 정보를 최대한 보존하면서 차원을 줄인다는 의미는 데이터를 공분산 행렬의 고유벡터에 사영(projection) 한다는 의미인데요. 자세한 내용은 이 곳을 참고해주세요.SVD(특이값 분해)SVD는 대각화를 통해 행렬을 분해하는 기법입니다. 고유값 분해는 정방 행렬에만 대각화를 할 수 있으나 SVD는 정방행렬이 아니어도 대각화가 가능하다는 장점이 있습니다. 그러나 단순히 행렬을 ‘분해’하는 것보다는 분해한 행렬에서 정보가 큰 순서대로 일정 개수의 벡터를 추려서 근사적으로 기존 행렬로 복원하는 식으로 많이 사용되는 기법입니다. SVD의 수식을 살펴 보면, 결과적으로 특정 행렬의 고유값과 고유벡터를 구하는 문제로 귀결됩니다. 자세한 내용은 추후에 따로 포스팅 하도록 하겠습니다.참고자료 고유값과 고유벡터 (eigenvalue &amp;amp; eigenvector), 다크 프로그래머 고윳값과 고유벡터, 공돌이의 수학정리노트 고윳값 분해(eigen-value decomposition), 공돌이의 수학정리노트 고유값(eigenvalue)과 고유벡터(eigenvector)의 정의, R Friend) 행렬식(determinant), ratsgo’s blog 행렬식의 기하학적 의미, 공돌이의 수학정리노트 SVD와 PCA, 그리고 잠재의미분석(LSA), ratsgo’s blog각주 좌표 변환과 선형 변환은 한끗 차이입니다. 어떤 행렬에 벡터를 곱했을 때 산출되는 값은 ‘점이 이동한 것’으로 볼 수도 있고 ‘좌표 축을 변환’ 한 것으로도 볼 수 있기 때문입니다. &amp;#8617; 원래 행렬과 곱했을 때 단위 행렬이(=항등 행렬) 되는 행렬을 뜻합니다. \\(AA^{-1} = I\\) &amp;#8617; 행렬의 원소들을 특정 수식에 따라 계산하여 나온 결과값. 특별한 정의는 없으나 그 결과값이 행렬의 특성을 결정 짓는다는 점에서 중요하게 다뤄집니다. 특히 행렬식을 통해서 역행렬의 존재 여부를 판정할 수 있습니다. &amp;#8617; 길이가 1인 벡터를 뜻합니다. \\(\\|v\\|=1\\) &amp;#8617; 행렬에 조작을 가하여 대각 성분을 제외한 모든 값을 0으로 만드는 것을 말합니다. &amp;#8617; 어느 한 벡터를 다른 벡터들의 선형 결합(상수배의 합)으로 표현할 수 없으면 이를 선형 독립이라고 합니다. &amp;#8617; " }, { "title": "2020년 회고", "url": "/posts/2020_retrospective/", "categories": "ETC, Retrospective", "tags": "retrospective", "date": "2020-12-27 15:03:05 +0900", "snippet": "올 한해를 간략히 정리해 보면…참 다사다난 했던 2020년입니다. 저는 캘린더 앱을 통해 항상 스케줄을 관리하는데요. 이번 회고글을 쓰면서 2020년 1월부터 오늘까지의 캘린더를 쭉 훑어 보았습니다. 소기의 성과를 달성한 일도 있었고, 스스로 다짐했으나 지키지 못했던 일도 많이 있었네요. 그와 동시에 한 해가 이렇게 빨리 지나가버린 것에 대해 놀라운 마음도 들었습니다. 진부 하지만 올 한해를 돌아보면 “Time flies like an arrow” 말이 떠오르네요.간략하게 올 한해를 돌아볼게요. 2월에는 힘들었지만 여러가지를 배울 수 있었던… 대학원 석사 과정을 졸업했습니다. 대학원 생활을 통해 가장 크게 남긴 것은 학문적 관심사를 공유하는 여러 선배, 동기, 후배들이었습니다. 특히 같은 분야로 실무에 진출한 동기들이 있어 주니어 시절의 어려움을 털어 놓고 얘기할 수 있어서 큰 힘이 되고 있습니다. 또한 데이콘에서 진행하던 ‘KB 금융 문자 분석’ 대회에서 운이 좋게도 private 리더보드에서 5위로 입상의 영광을 얻을 수 있었습니다. 디펜스 이후 취준을 하면서 뭔가 실무자분들에게 어필할만한 이력이 많지 않다는 생각에 정말 열심히 했던 기억이 있습니다. 리더보드를 하나씩 올리는 그 쾌감이 있었는데… 여유가 생긴다면 다시 한번 컴페티션에 참여해보고 싶습니다. 이 시기를 얘기할 때 코로나19 이야기를 빼 놓을 수 없겠죠. 저도 참 취준 시기에 코로나 이슈가 터져서 많이 걱정을 했습니다. 다행히도 너무 늦지도 빠르지도 않은 3월에 현재 회사에 데이터 사이언티스트로서 취업을 할 수 있었습니다. 3월부터 6월까지는 새로운 회사 및 업무에 적응하고 필요한 지식을 쌓으려고 노력했었고, 7월부터 12월까지는 여러가지 프로젝트를 수행하면서 본격적으로 실무적인 활동(?)을 수행했던 것 같습니다.스스로에 대한 당근과 채찍회사와 동료들에게 도움이 되고 싶어 나름 열심히 무언가를 했지만, 여전히 아직 많이 부족한 주니어라고 스스로 느끼고 있습니다. 그럼에도 불구하고 소소하지만 스스로에게 칭찬을 해줄 점도 있는 것 같습니다. 따라서 칭찬할 점과 부족하거나 보완해야할 점을 정리해보려고 합니다. 이를 통해서 2021년은 잘한 점은 계속 잘할 수 있도록 꾸준히 유지하고, 보완해야할 점은 확실히 메꿀 수 있는 한해로 만들고 싶습니다.칭찬할 점 여러 우여곡절이 있었지만 포기하지 않고 무사히 석사 과정을 마쳤던 것 리눅스 운영체제를 처음으로 다루어 보았고 CLI 환경과 git에 익숙해지기 위해 노력한 것 세미나를 준비하면서 청자 입장에서 필요한 정보가 무엇일지 생각해보는 습관을 들였던 것 많은 논문을 읽으면서 논문 읽는 능력을 길렀던 것 처음으로 참여한 컴페티션에서 입상을 한 것 점수 상승이 정체 되었을 때 포기하지 않고 끝까지 매달려 본 점 대회를 진행하면서 파이토치에 입문해서 기본적인 사용법을 익힌 것 pyspark를 기초적인 수준에서 활용하기 위해 노력한 점 주변 동료들의 도움으로 기초 수준의 pyspark application을 짜보기 위해 노력한 점 동료들과 기초적인 수준에서는 커뮤니케이션이 가능한 정도 AWS, Airflow, 네크워크 지식이 동료들과 간단한 커뮤니케이션이 가능한 수준에 이르기 위해 노력한 점 주변 동료들의 도움으로 꾸준히 용어에 익숙해지기 위해 노력함 최근 현업에서 간단한 프로젝트를 통해 조금 더 관련 지식에 익숙해진 느낌 팀원의 중요성을 깨닫게 된 점 입사 초반엔 내가 모든 것을 알아야 된다는 부담감이 조금 있었음 그러나 ‘내가 모든 것을 알 수 없기 때문에’ 팀원이 존재한다는 것을 어느 순간 깨닫게 되었음 모르는 것에 대해 도움을 요청할 수 있는 팀원들의 존재에 감사함을 느낌 통계학을 정규 커리큘럼 과정으로 끝까지 완주한 것 실무를 하며 통계학 지식이 매우 약하다는 것을 깨닫게 되었고, 정규 커리큘럼 과정을 통해 기초 통계학 지식을 공부함 난이도가 있는 수업이라 한 강의를 듣는 것에 많은 시간이 소요되어 퇴근 후 시간을 확보하여 공부함 수업 내용을 100% 이해하지는 못했지만 자신과의 약속을 지키고 끝까지 완주한 것에 스스로 보람을 느낌 통계 관련 개념과 수식을 보는 것에 예전 보다는 불편함이 줄어들었음 보완할 점 DS 분야에서 나에게 가장 잘 맞는 커리어를 아직 고민하는 중 ML Researcher가 더 맞을지 ML engineer가 더 맞을지 아직 확실히 방향을 정하지 못함 최근에는 ML engineer에 조금 더 관심을 두고 있긴 함 스스로의 강점에 대한 확신이 부족한 점 누군가 나에게 본인의 전문 분야나 강점에 대해 물으면 자신있게 대답하지 못할 것 같음 e-commerce 분야에 계속 종사하고 싶은데 추천 시스템쪽을 더 파야할지, 고객 데이터 분석에 집중해야할지 잘 모르겠음 SQL을 활용 능력이 아직 미비한 점 실무에서 활용할 일이 적어서 공부가 미비하였으나 최근 타부서의 요청사항을 처리하면서 필요성을 느낌 join, group, window 함수를 자유자재로 활용하기 위한 학습이 필요한 것 같음 논문 리딩을 많이 하지 못했던 점 특히 추천 시스템 관련 논문 리딩이 부족하였음 내년에는 구글, 넷플릭스 등 현업에서 추천시스템을 활용하는 기업의 논문을 정리해볼 계획 추천 시스템 review/summary 논문을 통해 전반적인 흐름을 잡을 것 DS에 필요한 이론적 개념 보완 및 실무에서의 활용 올해 공부한 통계학 지식을 바탕으로 추론 통계학 지식을 공부하여 A/B 테스트에 실제로 활용 해볼 예정 선형대수에서 특히 행렬 분해 관련 지식 보완 필요 통계학을 실무에서 어떻게 유용하게 활용할지에 대한 고민 끝으로…올 한해 코로나19로 인해 힘든일도 많았지만 개인적으로는 현업에 종사할 수 있게 되어서 개인적인 꿈도 이루었고 부모님의 걱정도 덜어드렸던 뿌듯한 한 해였습니다. 이제 스스로에게 칭찬할 점들은 내년에도 가져갈 수 있도록 노력하고, 보완할 점들은 실제로 보완해서 2020년 보다는 성장한 주니어로서 2021년을 마무리하기 위해 또 달려야 하겠습니다. 이 글을 읽고 계신 분들, 올 한해 너무 고생 많으셨고 얼마 남지 않은 2020년 마무리 잘 하셨으면 좋겠습니다. 내년 이맘 때쯤 다시 뵙겠습니다. 고생하셨습니다 여러분!" }, { "title": "큰수의 법칙(LLN, Law of Large Numbers)", "url": "/posts/LLN/", "categories": "Math, Statistics", "tags": "statistics, lln", "date": "2020-12-15 22:03:00 +0900", "snippet": "표본의 크기가 커질수록 표본평균은 모평균에 근접해 갑니다.우리는 공정한 동전을 던졌을 때 앞면이 나타날 확률이 \\(\\cfrac{1}{2}\\)이라는 것을 특별히 증명하지 않아도 알 수 있습니다. 우리가 지금까지 살아오면서 겪은 수많은 경험들에 의하면 동전의 앞면이 나타날 확률이 \\(\\cfrac{1}{2}\\)이기 때문이죠. 이처럼 수많은 경험의 경향성, 다시 말해 수많은 표본에 따른 평균(표본평균)이 실제 평균(모평균)에 다가가는 현상을 큰수의 법칙이라고 일컫습니다. 한편 큰수의 법칙과 가장 헷갈릴만한 개념이 중심 극한 정리(CLT)일 것입니다. 이 글의 끝에는 중심 극한 정리와의 차이점을 간략하게 짚고 넘어 가겠습니다. 중심 극한 정리에 대해 더욱 자세하게 알고 싶으신 분들은 여기를 참고 해주세요.1   큰수의 법칙(LLN, Law of Large Numbers)정의먼저 평균이 \\(\\mu\\), 분산이 \\(\\sigma^2\\)인 i.i.d. 확률 변수 \\(X_1, X_2, ...\\) 가 있다고 가정해 봅시다. 이 때 \\(X_1\\)에서 \\(X_n\\)까지의 평균을 표본 평균 \\(\\bar{X}_n\\)이라고 하고 다음과 같이 계산할 수 있습니다.\\[\\bar{X}_n = \\cfrac{X_1 + \\cdots + X_n}{n}\\]큰수의 법칙이란 표본의 크기 \\(n\\)이 증가함에 따라 표본 평균 \\(\\bar{X}_n\\)이 모평균 \\(\\mu\\)에 수렴하는 현상을 말합니다. 큰수의 법칙은 시뮬레이션, 통계학, 과학 등에서 필수적인 개념입니다. 시뮬레이션 상황 또는 현실 세계에서 독립적인 표본을 추출(생성, generating)하는 실험을 반복한다고 생각해 봅시다. 우리는 이론적인 평균값(theoretical average)을 추정하기 위해서 자연스럽게 표본들에서 알 수 있는 평균값(average value in the replications)을 활용하고자 할 것입니다. 이 같은 사실은 우리는 우리도 모르는 사이에 큰수의 법칙을 활용하고 있는 셈이죠!! 큰수의 법칙은 큰수의 강법칙(SLLN)과 큰수의 약법칙(WLLN), 두 가지 버전으로 나눌 수 있습니다. 두 가지 버전은 개념적으로 약간의 차이가 존재하지만, \\(n\\)이 증가함에 따라 표본 평균 \\(\\bar{X}_n\\)이 모평균 \\(\\mu\\)에 수렴하는 현상을 설명하려는 점에서는 공통점이 있습니다. 그래도 각각의 차이를 조금은 이해해 보아야 하겠죠?큰수의 약법칙(Weak law of large numbers)i.i.d. 확률변수 수열 중에서 \\(n\\)번째까지의 확률 변수의 평균 \\(\\bar{X}_n\\)과 모평균 \\(\\mu\\)의 차이의 절대값이 임의의 양수 \\(\\epsilon\\) 보다 클 확률이 0에 수렴한다는 정리(theorem)입니다. 수식으로 나타내면 아래와 같습니다.\\[n \\rightarrow \\infty \\text{ 일때,}\\]\\[P(|\\bar{X}_n - \\mu| \\gt \\epsilon) \\rightarrow 0\\\\\\]정리하자면 큰수의 약법칙은 확률 수렴(convergence in probability)에 대해 말하는 것입니다. 확률 수렴이란 \\(n\\)이 증가함에 따라 확률변수가 특정 상수에 가까워지는 확률값이 특정값에 수렴하는 것을 뜻합니다. 위 식이 의미하는 바를 그림으로 나타내어 보았습니다. 아래 그림을 통해서 큰수의 약법칙은 \\(n\\)이 증가할 때, 확률 변수인 표본 평균 \\(\\bar{X}_n\\)이 실제 모수인 \\(\\mu\\)의 근처에 존재할 확률이 1에 근사한다는 의미로 해석할 수 있습니다.제가 위에서 확률 수렴을 말할 때 특별히 확률이라는 단어를 강조한 이유는 이것이 다음에 설명할 큰수의 강법칙과의 차이점이기 때문입니다. 큰수의 약법칙은 확률값의 수렴을 말하는데 반해 큰수의 강법칙은 확률변수 자체가 수렴한다는 것을 말합니다. 따라서 큰수의 강법칙이 조금 더 강하게 큰수의 법칙을 설명하고 있다고 해석할 수 있습니다.한편 확률 수렴은 다음의 표기들로도 나타낼 수 있습니다.\\[\\bar{X}_n \\xrightarrow{p} \\mu\\]\\[\\text{plim}_{n \\rightarrow \\infty} \\bar{X}_n = \\mu\\]\\[\\lim_{n \\rightarrow \\infty}\\text{Pr}(|\\bar{X}_n - \\mu| \\gt \\epsilon) = 0\\]큰수의 강법칙(Strong law of large numbers)큰수읙 강법칙은 다음의 수식으로 요약할 수 있습니다.\\[P(\\bar{X}_n \\rightarrow \\mu) =1\\]다시 말해 확률변수인 표본 평균 \\(\\bar{X}_n\\)이 모평균 \\(\\mu\\)에 1의 확률로 수렴한다는 것을 뜻합니다. 큰수의 약법칙에서 언급했던 것처럼 큰수의 강법칙은 확률변수가 수렴한다는 것을 뜻하므로 이 부분에서 큰수의 약법칙과 약간의 차이가 있습니다. 두가지 버전을 구분해서 설명하자면 큰수의 약법칙은 \\(n\\)이 증가함에 따라 표본 평균 \\(\\bar{X}_n\\)이 존재할 범위가 아주 작은 구간에 점점 집중되어 가는 것을 말하는데 반해 큰수의 강법칙은 표본평균 \\(\\bar{X}_n\\) 자체가 모평균 \\(\\mu\\)에 수렴하는 것을 뜻합니다. 이러한 관점에서 큰수의 강법칙이 조금 더 강하게(?) 큰수의 법칙을 설명하려는 느낌이 있습니다.2   큰수의 약법칙 증명큰수의 약법칙은 쳬비셰프 부등식(che… inequality)을 활용하며 쉽게 증명이 가능합니다. 먼저 쳬비셰프 부등식은 다음과 같습니다. 확률 변수 \\(X\\), 확률 변수의 기대값 \\(\\mu(=E(X))\\), 임의의 양수 \\(a(&amp;gt;0)\\)가 주어졌을 때,\\[P(|X-\\mu|\\geq a) \\leq \\cfrac{\\text{Var}(X)}{a^2}\\]쳬비셰프 부등식은 마르코프 부등식을 통해 간단하게 유도됩니다. 마르코프 부등식에 대한 내용은 인터넷에 많은 자료 있으니 참고해주세요. 이제 쳬비셰프 부등식을 이용하여 큰수의 약법칙을 간단하게 증명해보겠습니다. 위 식에서 몇몇 변수들을 우리의 목적에 맞게 변환하면 아래의 식이 나타납니다.\\[P(|\\bar{X}_n - \\mu|&amp;gt;\\epsilon) \\leq \\cfrac{\\sigma^2}{n \\epsilon^2} \\leftarrow \\text{Var}(\\bar{X}_n) = \\cfrac{\\sigma^2}{n}\\]\\(n \\rightarrow \\infty\\)에 따라 우변이 0으로 수렴함을 쉽게 알 수 있으므로 확률 수렴을 뜻하는 큰수의 약법칙이 간단하게 증명되었습니다. 참고로 표본 평균 \\(\\bar{X}_n\\)의 분산이 도출되는 과정이 궁금하시다면 여기를 참고해주세요.3   예시동전을 \\(n\\)번 던지기i.i.d.인 확률 변수 \\(X_1, X_2, \\cdots\\)가 존재하고 각 확률 변수들의 분포는 \\(Bern(1/2)\\)를 따른다고 가정해 봅시다. 이때 \\(X_j\\)를 지시 확률 변수(사건이 발생하면 1, 발생하지 않으면 0을 나타내는 확률 변수)로도 볼 수 있습니다. 왜냐하면 동전기 시행은 앞면이 나오는 사건과 앞면이 아닌 사건(뒷면) 두개만 존재하기 때문에 앞면이 나왔을 때를 1, 뒷면이 나왔을 때를 0으로 볼 수 있습니다. 이러한 상황에서는 표본 평균 \\(\\bar{X}_n\\)을 동전 던지기 시행을 \\(n\\)번 했을 때, 앞면이 나오는 횟수로 생각 할 수 있습니다. 다시 말해 표본 평균 \\(\\bar{X}_n\\)을 앞면이 나타날 확률로 생각할 수 있다는 것이죠.큰수의 강법칙(SLLN) 입장에서 보면 확률 변수 \\(\\bar{X}_n\\)이 모평균 \\(\\mu(=1/2)\\)에 수렴할 확률은 \\(1\\)입니다. 한편 큰수의 약법칙(WLLN)의 입장에서는 시행 횟수 \\(n\\)이 커질수록 표본평균 \\(\\bar{X}_n\\)과 모평균 \\(\\mu(=1/2)\\)의 차이가 임의의 양수 \\(\\epsilon\\) 보다 클 확률이 점점 작아져 0에 수렴하게 됩니다.큰수의 법칙을 그래프로 확인해 볼까요? 동전을 300번 던지는 시행을 6번 반복한다고 해봅시다(실제로는 시행 자체는 무한번 하는 것이지만 그래프의 단순화를 위해 임의로 6번으로 하였습니다. 특별한 의미는 없음). 우리가 주목할 점은 6번의 시행의 표본 평균이 동전 던지기 횟수 \\(n\\)가 증가함에 따라 모평균 \\(1/2\\)에 실제로 근접해 가는지를 눈으로 확인해 보는 것입니다.\\(n\\)의 크기가 커질수록(표본의 크기가 커질수록) 표본평균은 모평균에 근사한다는 것이 확실히 보인다!4   중심 극한 정리와의 차이점큰수의 법칙과 중심 극한 정리는 공통점도 있고 차이점도 있습니다. 먼저 공통점은 둘다 표본 평균 \\(\\bar{X}_n\\)에 대해 설명한다는 것입니다. 하지만 중요한 차이점이 존재합니다. 지금까지 정리한 큰수의 법칙 내용을 떠올리신다면, 표본 평균 \\(\\bar{X}_n\\)이 \\(n \\rightarrow \\infty\\)에 따라 모평균 \\(\\mu\\)에 확률 수렴한다는 이야기는 쭉 진행해 왔지만, 표본 평균 \\(\\bar{X}_n\\)이 따르는 분포에 대해서는 한번도 설명하지 않았다는 사실을 알아 차리실 수 있습니다. 표본 평균 \\(\\bar{X}_n\\)은 확률 변수이므로 당연히 어떤 분포를 따를텐데 말이죠… 분포에 대해 설명하는 이론은 없을까요? 그것이 바로 중심 극한 정리입니다. 중심 극한 정리는 표본 평균 \\(\\bar{X}_n\\)이 \\(n \\rightarrow \\infty\\)에 따라 정규 분포로 분포 수렴 한다는 사실을 밝히는 정리입니다. 중심 극한 정리에 대한 내용은 여기를 참고해주세요.참고자료 위키피디아-확률변수의 수렴 “Introduction to Probability”, Joseph K. Blitzstein, Jessica Hwang" }, { "title": "중심 극한 정리(CLT, Central Limit Theorem)", "url": "/posts/CLT/", "categories": "Math, Statistics", "tags": "statistics, clt", "date": "2020-12-11 13:32:00 +0900", "snippet": "석사과정 때부터 중심극한정리에 의해서 표본의 크기가 30 이상이면 정규분포가 되어서…’ 라는 말을 많이 들어왔습니다. 그래서 ‘설문자료를 수집할 때 표본이 30개 이상이면 분석을 할 수 있겠구나…’ 라고 단순하게 생각 했던 때가 있었는데요. 최근에 하버드 확률론 기초 강의(Statistics 110)를 수강하면서 수업 말미에 등장한 중심극한정리에 대한 내용을 들으면서 제가 너무 단순하게 알고 있었다는 것을 깨달았습니다. 그래서 이 주제로 정리를 꼭 한번 해봐야지라고 생각하고 있었는데, 제가 생각 했던 것 보다 어려운 개념이었습니다… 😩 이 분야를 공부하면 정말 겸손해지네요. 아무튼 제가 아는 선에서 중심극한정리에 대한 내용을 담아 냈습니다. 틀린 부분 있으면 지적해 주시면 감사하겠습니다.1   중심 극한 정리(Central Limit Theorem, CLT)란?정의중심 극한 정리란 i.i.d. 확률 변수 \\(X_1, X_2, ...\\) 가 표본의 크기 \\(n\\)이 \\(\\infty\\)에 다가가면, 표본평균 \\(\\bar{X}\\)의 분포가 정규 분포에 분포 수렴한다는 정리을 말합니다. 만약 표본 평균이 표준화(standardization)된 상태(\\(\\mu=0, \\sigma^2=1\\))이면 표준 정규 분포에 수렴합니다.큰수의 법칙으로는 표본의 분포(shape)를 알 수 없다.먼저 큰수의 법칙을 다시 상기해 봅시다. 큰수의 법칙은 모집단에서 추출한 표본 \\(X_1, X_2, \\cdots, X_n\\) 이 i.i.d. 이면서 평균 \\(\\mu\\), 분산 \\(\\sigma^2\\)를 따를 때, \\(n \\rightarrow \\infty\\)이면 \\(\\bar{X}\\)가 1의 확률로 \\(\\mu\\)에 수렴함을 말합니다. 그러나 큰수의 법칙은 표본 평균 \\(\\bar{X}\\)의 shape 즉, 분포 대해서는 전혀 알려 주지 못합니다.중심 극한 정리는 표본의 분포(shape)를 설명할 수 있다.그렇다면 \\(n \\rightarrow \\infty\\)일때, \\(\\bar{X}\\)의 분포는 어떤지 알 수 있을까요? 결론적으로 말하면 중심 극한 정리를 통해 표본 평균 \\(\\bar{X}\\)의 분포를 설명할 수 있습니다. 중심 극한 정리는 모집단에서 크기가 \\(n\\)인 표본 \\(X_1, X_2, \\cdots, X_n\\)을 임의 복원 추출 했을 때 \\(n \\rightarrow \\infty\\) 이면 표본평균 \\(\\bar{X}\\)는 정규 분포에 수렴한다는 것을 말합니다. 만일 표본 평균 \\(\\bar{X}\\)가 표준화(standardization)되었다면, 표준 정규 분포에 수렴합니다.\\[\\text{As } n \\rightarrow \\infty, \\\\\\]\\[\\cfrac{\\sqrt{n}\\big(\\bar{X}_{n}-\\mu \\big)}{\\sigma} \\rightarrow N(0,1)\\]참고로 표준화 되지 않은 표본 평균은 \\(n\\)이 충분히 크다면, 평균 \\(\\mu\\), 분산 \\(\\cfrac {\\sigma^2} {n}\\)인 정규분포를 따릅니다.\\[\\text{As } n \\rightarrow \\infty,\\\\[1em]\\]\\[\\bar{X}_n \\rightarrow N\\bigg(\\mu, \\cfrac{\\sigma^2}{n}\\bigg)\\]2   표본 평균의 평균과 분산 계산표본 평균은 확률 변수먼저 반드시 헷갈리지 말아야 할 것이 표본 평균(sample mean)은 확률 변수라는 점입니다. 따라서 표본 평균은 기대값(표본평균의 평균), 분산(표본평균의 분산), 표준 편차(표본평균의 표준편차)를 가지게 됩니다. 말이 굉장히 헷갈릴 수 있으므로 주의해서 살펴보셔야 합니다.표본 평균의 평균(기대값)\\[\\begin{aligned} E(\\bar{X}_n) &amp;amp;= E\\bigg(\\cfrac{1}{n}\\bigg(X_1+\\cdots+X_n\\bigg)\\bigg) \\\\ &amp;amp;= \\cfrac{1}{n}E\\bigg(X_1+\\cdots + X_n \\bigg) \\\\ &amp;amp;= \\cfrac{1}{n}\\bigg(E(X_1)+\\cdots+E(X_n)\\bigg) \\\\ &amp;amp;= \\cfrac{1}{n} \\cdot n \\cdot \\mu \\\\ &amp;amp;= \\mu \\end{aligned}\\]표본 평균의 표준편차\\[\\begin{aligned} Var(\\bar{X}_n) &amp;amp;= Var\\bigg(\\cfrac{1}{n}\\bigg(X_1+\\cdots+X_n\\bigg)\\bigg) \\\\ &amp;amp;= \\cfrac{1}{n^2}\\cdot Var\\bigg(X_1+ \\cdots + X_n \\bigg) \\\\ &amp;amp;= \\cfrac{1}{n^2} \\cdot \\bigg(Var(X_1)+\\cdots+Var(X_n)\\bigg) \\\\ &amp;amp;= \\cfrac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\ &amp;amp;= \\cfrac{\\sigma^2}{n} \\\\ \\therefore \\space SD(\\bar{X}_n) &amp;amp;= \\cfrac{\\sigma}{\\sqrt{n}} \\end{aligned}\\]표본 평균의 표준화먼저 표준화는 다음의 수식을 따릅니다. 그 결과 평균이 0, 분산 1이 되는 분포로 변화됩니다.\\[\\cfrac{X-E(X)}{\\sigma}\\]이를 활용해 표본 평균을 표준화 하면 아래의 값이 도출 됩니다.\\[\\begin{aligned} \\cfrac{\\bar{X}_n-E(\\bar{X}_n)}{SD(\\bar{X}_n)} &amp;amp;= \\cfrac{\\bar{X}_n-\\mu}{\\cfrac{\\sigma}{\\sqrt{n}}} \\\\[1em] &amp;amp;= \\cfrac{\\sqrt{n}(\\bar{X}_n-\\mu)}{\\sigma} \\end{aligned}\\]참고로 표준화의 의미는 평균을 0, 분산을 1로 강제하는 것이지만 단순히 scaling, shift를 한 것이지 원래의 분포의 모양 자체를 바꿀 수는 없습니다. 다시 말해 표준화 한다고 해서 원래 정규 분포가 아닌 어떤 분포가 표준 정규 분포로 바뀌는 것은 아닙니다. 아래 그림을 보면 원래 분포(Before)를 표준화하여 \\(\\mu=0, \\sigma^2=1\\)로 만들었는데요. 그 결과가 표준 정규 분포가 아닙니다.3   중심 극한 정리는 왜 중요할까?위에서 중심 극한 정리가 어떤 의미인지 살펴보았습니다. 그런데 중심 극한 정리의 놀라운 점은 i.i.d. 가정이 충족되고 유한한 평균 \\(\\mu\\) 및 분산 \\(\\sigma^2\\)만 정의 된다면 원래의 분포 \\(X_j\\)의 어떠한 정보가 없더라도 표본 평균의 분포가 표평균 \\(\\mu\\), 분산 \\(\\cfrac{\\sigma^2}{\\sqrt{n}}\\)인 정규 분포에 가까워 진다는 것을 알려 준다는 점입니다.따라서 우리는 중심 극한 정리에 기반하여, 표본의 크기가 충분하다면 내가 수집한 표본의 표본 평균이 발생할 확률을 정규 분포에서 계산할 수 있게 됩니다. 특히 이러한 통계적 추론은 모집단의 분포가 어떤 모양이든지 관계 없이 가능 하다는 점에서 엄청난 편의성을 제공합니다. 정리하자면, 중심 극한 정리는 표본 평균과 모집단 간의 관계를 나타냄으로써 표본 통계량(statistics)를 이용해 모수(parameter)를 추정할 수 있는 수학적 근거를 제시합니다. 따라서 중심 극한 정리는 통계에서 가장 중요한 이론적 근거라고 하겠습니다.여기부터는 사견입니다. 왜 모집단의 ‘분포’ 자체를 추정하지 않고 모집단의 ‘모수’를 추정하려고 할까요? 그 이유는 2가지 인 것 같습니다. 먼저, 모집단의 분포를 우리는 알 수 없습니다. 모집단의 분포를 알 수 없기에 통계적 추정을 하는 것이죠. 그리고 어떤 분포의 모수(모평균, 모분산 등)를 알면 그 분포를 거의 정확하게 그려 낼 수 있습니다. 우리가 흔히 들어 본 정규 분포, 이항 분포, 베타 분포 등 다양한 분포는 평균과 분산만 알면 그 PDF, PMF 식을 알 수 있습니다.4  중심 극한 정리를 증명해 보자!적률 생성 함수의 성질증명을 위해서는 MGF(적률 생성 함수), 로피탈의 정리에 대한 사전 지식이 필요합니다. 이와 관련해서는 쉽고 자세 하게 정리된 글들이 많으니 자세한 내용은 해당 글들을 먼저 참고 부탁드립니다 🙏 간단히 언급하자면, 다음과 같은 적률 생성 함수의 성질에 대한 사전 지식이 필요합니다. 확률 변수 \\(X\\), \\(Y\\)가 독립이라면, \\(M_{X+Y}(t) = M_{X}(t)M_{Y}(t)\\) 어떤 두 확률 분포의 적률 생성 함수가 동일하면, 두 확률 분포는 동일합니다.증명 순서이제 수식을 통해 증명을 해보겠습니다. 증명 순서는 다음과 같습니다. 표준화(standardization)한 표본 평균의 적률 생성 함수를 구합니다. 해당 함수를 \\(n \\rightarrow \\infty\\)로 보내 봅니다. 이 때 구해지는 적률 생성 함수가 표준 정규 분포의 적률 생성 함수와 동일하다는 것을 확인합니다. 따라서 표본의 크기가 충분히 클때 표본 평균은 표준 정규 분포에 분포 수렴한다는 결론을 내립니다. 먼저 표준화한 표본 평균의 적률 생성 함수를 구해보겠습니다.증명 과정\\[\\begin{align}M_{\\tfrac{\\sqrt{n}(\\bar{X}-\\mu)}{\\sigma}}(t)&amp;amp;= M_{\\tfrac{\\sqrt{n}(\\tfrac{1}{n}(X_1+\\cdots+X_n)-\\mu)}{\\sigma}}(t) \\\\[1em]&amp;amp;= M_{\\tfrac{(X_1 + \\cdots + X_n)-n\\mu }{\\sigma \\sqrt{n}}}(t) \\\\[1em]&amp;amp;= M_{\\tfrac{X_1-\\mu}{\\sigma} + \\cdots + \\tfrac{X_n-\\mu}{\\sigma}}(t) \\\\[1em]&amp;amp;= M_{\\tfrac{X_1-\\mu}{\\sigma}}(t) M_{\\tfrac{X_2-\\mu}{\\sigma}}(t) \\cdots M_{\\tfrac{X_n-\\mu}{\\sigma}}(t) \\\\[1em]&amp;amp;= E\\Big(\\text{exp}\\Big(\\tfrac{(X_1-\\mu)t}{\\sigma\\sqrt{n}}\\Big)\\Big) E\\Big(\\text{exp}\\Big(\\tfrac{(X_2-\\mu)t}{\\sigma\\sqrt{n}}\\Big)\\Big) \\cdots E\\Big(\\text{exp}\\Big(\\tfrac{(X_n-\\mu)t}{\\sigma\\sqrt{n}}\\Big)\\Big) \\\\[1em]&amp;amp;= \\Big\\{ E\\Big(\\text{exp}\\Big(\\tfrac{(X-\\mu)t}{\\sigma\\sqrt{n}}\\Big)\\Big) \\Big\\}^n \\\\[1em]&amp;amp;= \\Big\\{ M_{\\tfrac{X-\\mu}{\\sigma}} \\Big( \\tfrac{t}{\\sqrt{n}} \\Big) \\Big\\}^n \\\\[1em]\\end{align}\\]여기까지 표준화한 표본 평균의 적률 생성 함수를 유도했습니다. 이제 해당 함수를 \\(n \\rightarrow \\infty\\)으로 보내려고 하는데요. 약간의 문제가 있습니다. 위에서 유도한 식에 극한을 취해서 \\(n \\rightarrow \\infty\\)로 보내면 \\(1^{\\infty}\\)라는 값이 등장하게 됩니다. 그래서 자연로그를 취한 후 극한을 취하는 테크닉을 적용하게 됩니다.\\[\\begin{align}\\lim_{n \\rightarrow \\infty} \\text{ln} \\Big\\{ M_{\\tfrac{X-\\mu}{\\sigma}} \\Big( \\tfrac{t}{\\sqrt{n}} \\Big) \\Big\\}^n &amp;amp;= \\lim_{n \\rightarrow \\infty} n \\text{ln} M_{\\tfrac{X-\\mu}{\\sigma}} \\Big( \\tfrac{t}{\\sqrt{n}} \\Big) \\\\[1em]&amp;amp;= \\lim_{y \\rightarrow 0} \\frac{\\text{ln} M_{\\tfrac{X-\\mu}{\\sigma}}(yt)}{y^2} \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space \\text{where } y=\\frac{1}{\\sqrt{n}} \\\\[1em]&amp;amp;= \\lim_{y \\rightarrow 0} \\frac{\\cfrac{tM&#39;(yt)}{M_{\\tfrac{X-\\mu}{\\sigma}}(yt)}}{2y} \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space \\text{by L’Hˆopital’s rule} \\\\[1em]&amp;amp;= \\lim_{y \\rightarrow 0} \\frac{tM&#39;_{\\tfrac{X-\\mu}{\\sigma}}(yt)}{2y} \\\\[1em]&amp;amp;= \\cfrac{t}{2} \\lim_{y \\rightarrow 0} \\frac{M&#39;_{\\tfrac{X-\\mu}{\\sigma}}(yt)}{y} \\\\[1em]&amp;amp;= \\cfrac{t}{2} \\lim_{y \\rightarrow 0} \\cfrac{tM&#39;&#39;_{\\tfrac{X-\\mu}{\\sigma}}(yt)}{1} \\\\[1em]&amp;amp;= \\cfrac{t^2}{2} \\lim_{y \\rightarrow 0} M&#39;&#39;_{\\tfrac{X-\\mu}{\\sigma}}(yt) \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space \\text{by L’Hˆopital’s rule} \\\\[1em]&amp;amp;= \\cfrac{t^2}{2} M&#39;&#39;(0) \\\\[1em]&amp;amp;= \\cfrac{t^2}{2} \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space \\text{by MGF of standard normal dist.}\\end{align}\\]위 식이 말하고자 하는 것은 \\(n \\rightarrow \\infty\\) 일 때,\\[\\text{ln} \\bigg\\{ M_{\\tfrac{X-\\mu}{\\sigma}}\\bigg(\\frac{t}{\\sqrt{n}}\\bigg) \\bigg\\}^n \\rightarrow \\frac{t^2}{2}\\]화살표 왼쪽은 증명의 첫 출발점이었던 표준화한 표본 평균의 MGF에 자연로그를 취한 것과 동일합니다. 따라서\\[\\text{ln }M_{\\tfrac{\\sqrt{n}(\\bar{X}-\\mu)}{\\sigma}}(t) \\rightarrow \\frac{t^2}{2}\\]최종적으로 \\(n \\rightarrow \\infty\\) 일 때 표준화된 표본 평균의 MGF는 표준 정규 분포의 MGF \\(\\big(=e^{t^2/2}\\big)\\)와 같으므로 표준화된 표본 평균은 표준 정규 분포에 분포 수렴한다는 사실을 증명할 수 있습니다.\\[M_{\\tfrac{\\sqrt{n}(\\bar{X}-\\mu)}{\\sigma}}(t) \\rightarrow e^{t^2/2}\\]참고자료 중심극한정리 - 위키피디아 중심극한 정리는 무엇이고 왜 중요한가? Can any data be transformed into a standard normal distribution? “Introduction to Probability”, Joseph K. Blitzstein, Jessica Hwang" }, { "title": "연속형 확률 분포 정리", "url": "/posts/continuous_distributions/", "categories": "Math, Statistics", "tags": "statistics, distribution", "date": "2020-11-28 16:26:00 +0900", "snippet": "하버드 확률론 기초 강의(Statistics 110)을 수강 후, 교수님께서 강조하신 여러가지 분포에 대해 개념정리 할 필요성을 느꼈습니다. 특히 이커머스 도메인에서는 통계에 기반한 분석 기법들이 많이 활용되는데(LTV, MAB 등), 실무에서 주어진 태스크를 빠르고 정확히 수행하기 위해 미리 관련 개념 정리를 해두려고 합니다. 이번 포스트는 대표적인 연속형 확률 분포(정규분포, 지수분포, 베타분포, 감마분포)의 정의, PDF, 기대값, 분산에 대해 정리해보았습니다. 그리고 보너스로 지수 분포, 감마분포, 포아송 분포를 한꺼번에 다루는 포아송 과정(poisson process)에 대해서도 미약하지만 정리해보았습니다.본 내용은 하버드 확률론 기초 강의(Statistics 110)를 참고하여 정리했음을 밝힙니다. 이산형 확률 분포에 대한 글은 이곳을 참고해주세요.0   확률 변수(Random Variable)와 확률 분포(Distribution)확률 변수란 표본 공간(\\(S\\))에서 발생 가능한 outcome을 실수 공간에 맵핑 시키는 함수를 의미합니다. 확률 변수는 함수이기 다음과 같이 표현 할 수 있습니다.\\[X:S \\rightarrow \\mathbb{R}\\]확률 분포는 확률 변수와 깊은 관련성으로 인해 헷갈리기 쉬운 개념입니다. 확률 변수와 확률 분포의 공통점은 함수라는 점입니다. 그러나 함수의 역할이 다르다는 점에서 차이가 있는데, 확률 분포란 확률 변수가 특정한 값을 가질 확률을 나타내는 함수를 의미합니다.1 확률 분포는 확률 변수가 어떤 종류의 값을 가지느냐에 따라서 크게 이산 확률 분포와 연속 확률 분포로 구분됩니다. 이산 확률 분포는 확률 질량 함수(PMF, Probability Mass Function)로 표현 가능 하며, 연속 확률 분포는 확률 밀도 함수(PDF, Probability Density Function)으로 표현 가능 합니다.1   연속 확률 변수(Continuous Random Variable) 분포1.1   균등 분포(Uniform Distribution)1.1.1 정의일정 구간의 확률 밀도가 모두 동일한 연속 확률 분포입니다. 모수인 \\(a\\)와 \\(b\\)는 각각 구간의 최솟값과 최댓값을 나타냅니다.\\[U \\sim Unif(a, b)\\]1.1.2 PMF\\[f_{U}(u) = \\begin{cases} c\\big(=\\cfrac{1}{b-a}\\big) &amp;amp; a \\le x \\le b \\\\ 0 &amp;amp;\\text{otherwhise}\\end{cases}\\]1.1.3 PMF 검증\\[\\int_{a}^{b}cdu = c(b-a) = 1\\]1.1.4 기댓값\\[\\begin{aligned}E(U) &amp;amp;= \\int_{a}^{b}uf_U(u)du \\\\[1em]&amp;amp;= \\int_{a}^{b}\\cfrac{u}{b-a}du \\\\[1em]&amp;amp;= \\cfrac{b^2-a^2}{2(b-a)} \\\\[1em]&amp;amp;= \\cfrac{(b+a)(b-a)}{2(b-a)} \\\\[1em]&amp;amp;= \\cfrac{a+b}{2}\\end{aligned}\\]1.1.5 분산\\[\\begin{aligned}Var(U) &amp;amp;= E(U^2) - E(U)^2 \\\\[1em]&amp;amp;= \\int_{a}^{b}u^2f_{U}(u)du - \\bigg(\\cfrac{a+b}{2}\\bigg)^2 \\\\[1em]&amp;amp;= \\int_{a}^{b}u^2\\cfrac{1}{b-a}du - \\bigg(\\cfrac{a+b}{2}\\bigg)^2 \\\\[1em]&amp;amp;= \\cfrac{b^3-a^3}{3(b-a)} - \\cfrac{(b+a)^2}{4} \\\\[1em]&amp;amp;= \\cfrac{4(a-b)(a^2+ab+b^2) - (b+a)^2}{12} \\\\[1em]&amp;amp;= \\cfrac{(b-a)^2}{12}\\\\[1em]\\end{aligned}\\]1.2   표준 정규 분포(Standard Normal/Gaussian Distribution)1.2.1 정의평균이 0(zero average)이고 분산이 1(unit variance)인 연속 확률 분포입니다.\\[X \\sim Normal(0, 1)\\]1.2.2 PDF표준 정규 분포의 PMF를 유도하기 위해서는 가우스 적분1, 이중 적분, 극 좌표계, 삼각함수 등의 사전 지식이 필요함을 언급해 둡니다. 표준 정규 분포의 PDF는 다음과 같이 나타낼 수 있습니다. 여기서 \\(\\cfrac{1}{\\sqrt{2\\pi}}\\)는 해당 식의 적분 값을 1로 만들기 위한 정규화 상수(normalizing constant) 입니다. 적분 값을 1로 만들어야 하는 이유는 확률의 합이 반드시 1이 되어야 하기 때문입니다.\\[f_Z(z) = \\cfrac{1}{\\sqrt{2\\pi}}e^{-z^2/2}\\]정규화 상수를 미지수로 둔 후에 \\(\\sqrt{2\\pi}\\)가 되도록 유도해 보겠습니다.\\[\\begin{aligned}I &amp;amp;= \\int_{-\\infty}^{\\infty}e^{-z^2/2}dz \\space \\text{일 때,} \\\\[1em]I^2 &amp;amp;= \\int_{-\\infty}^{\\infty}e^{-x^2/2}dx \\int_{-\\infty}^{\\infty}e^{-y^2/2}dy \\\\[1em]&amp;amp;= \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}e^{-(x^2+y^2)/2}dxdy \\space \\Leftarrow \\text{이중 적분 꼴로 치환} \\\\[1em]&amp;amp;= \\int_{\\theta=0}^{2\\pi}\\int_{r=0}^{\\infty}e^{-r^2/2}rdrd\\theta \\space \\Leftarrow \\text{좌표계를 극좌표계로 변환} \\\\[1em]&amp;amp;= - \\int_{\\theta=0}^{2\\pi}\\int_{u=0}^{-\\infty}e^udud\\theta \\space \\Leftarrow -\\cfrac{r^2}{2}=u \\space \\text{and} \\space rdr=-du \\\\[1em]&amp;amp;= - \\int_{\\theta=0}^{2\\pi}\\Big[e^u\\Big]_{0}^{-\\infty}d\\theta \\\\[1em]&amp;amp;= \\int_{\\theta=0}^{2\\pi}d\\theta \\\\[1em]&amp;amp;= 2\\pi \\\\[1em]\\therefore \\space I &amp;amp;= \\sqrt{2\\pi} \\space (\\because I &amp;gt; 0)\\end{aligned}\\]1.2.3 기댓값표준 정규 분포의 기댓값은 기함수(홀함수, odd function)의 성질을 이용하여 쉽게 도출 가능합니다. 기함수에 대한 내용은 이 곳을 참고해주세요. 간단히 말하자면 기함수는 원점 대칭이기 때문에 \\(\\int_{-a}^{a}f(x)dx=0\\)의 성질을 가지고 있습니다. 어떤 함수가 기함수라면, \\(-f(x) = f(-x)\\)를 만족합니다. 기댓값이 0인 이유는 표준 정규 분포의 기댓값 수식이 기함수의 성질 \\(-f(x) = f(-x)\\)를 만족하기 때문입니다.\\[E(z) = \\cfrac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}ze^{-z^2/2}dz = 0\\]1.2.4 분산\\[\\begin{aligned}Var(Z) &amp;amp;= E(Z^2) - E(Z)^2 \\\\[1em]&amp;amp;= E(Z^2) - 0^2 \\\\[1em]&amp;amp;= E(Z^2) \\\\[1em]&amp;amp;= \\cfrac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} z^2e^{-z^2/2}dz \\\\[1em]&amp;amp;= \\cfrac{2}{\\sqrt{2\\pi}}\\int_{0}^{\\infty} z^2e^{-z^2/2}dz \\space \\Leftarrow \\space \\text{by even function&#39;s property}\\\\[1em] &amp;amp;= \\cfrac{2}{\\sqrt{2\\pi}}\\int_{0}^{\\infty} zze^{-z^2/2}dz \\space \\Leftarrow \\space \\text{by parts}\\end{aligned}\\]1.3   정규 분포(Normal/Gaussian Distribution)1.3.1 정의표준 정규 분포를 평균이 \\(\\mu\\), 분산이 \\(\\sigma^2\\)이 되도록 location과 scale을 변화시킨 분포입니다.\\[X \\sim Normal(\\mu, \\sigma^2)\\]참고로, \\(X = \\mu + \\sigma z\\)를 통해 표준 정규 분포에서 정규 분포로 변환할 수 있습니다. \\(z=\\cfrac{X-\\mu}{\\sigma}\\)를 표준화(standardization)라고 합니다.1.3.2 PDF\\[F_X(x) = P(X\\le x) = P\\bigg(\\cfrac{X-\\mu}{\\sigma} \\le \\cfrac{x-\\mu}{\\sigma}\\bigg) = \\Phi(z) \\space \\text{일 때,} \\\\\\]\\[\\begin{aligned}f_X(x) &amp;amp;= \\Phi&#39;(z) \\\\[1em]&amp;amp;= \\cfrac{\\partial \\Phi(z)}{\\partial z} \\cfrac{\\partial z}{\\partial x} \\\\[1em]&amp;amp;= \\text{표준 정규 분포의 pdf} \\space \\cdot \\space \\cfrac{1}{\\sigma} \\\\[1em]&amp;amp;= \\cfrac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\bigg(\\cfrac{x-\\mu}{\\sigma}\\bigg)^2/2}\\end{aligned}\\]1.3.3 기댓값\\[E(X) = E(\\mu + \\sigma z) = \\mu + \\sigma \\cdot0 = \\mu\\]1.3.4 분산\\[Var(X) = Var(\\mu + \\sigma z) = Var(\\sigma z) = \\sigma^2 Var(z) = \\sigma^2\\]1.4   지수 분포(Exponential Distribution)1.4.1 정의다음 사건아 발생하기까지 대기 시간에 대한 연속형 확률 분포입니다. 또는 포아송 분포와 연결 지어서 설명할 수 있는데, 포아송 분포에서 한 사건이 발생한 후 다음 사건이 발생하기까지의 대기 시간이라고도 해석합니다. 모수인 \\(\\lambda\\)는 포아송 분포의 모수와 같은 의미로 생각하면 되겠습니다(단위 시간당 평균 사건 발생 횟수)\\[X \\sim E\\text{x}po(\\lambda)\\]1.4.2 PDF\\[f_X(x) = \\lambda e^{-\\lambda x}\\]1.4.3 기댓값\\[\\begin{aligned}\\int_{0}^{\\infty}x\\lambda e^{-\\lambda x} &amp;amp;= \\Big[x(-e^{-\\lambda x})\\Big]_{0}^{\\infty} + \\int_{0}^{\\infty}e^{-\\lambda x} \\space \\Leftarrow \\text{by parts} \\\\[1em] &amp;amp;= \\int_{0}^{\\infty}e^{-\\lambda x} \\\\[1em] &amp;amp;= \\Big[-\\cfrac{1}{\\lambda}e^{-\\lambda x}\\Big]_{0}^{\\infty} \\\\[1em]&amp;amp;= \\cfrac{1}{\\lambda}\\end{aligned}\\]1.4.4 분산\\[\\begin{align} Var(X) &amp;amp;= E(X^2) - E(X)^2 \\\\[1em] &amp;amp;= \\cfrac{2}{\\lambda^2} - \\bigg(\\cfrac{1}{\\lambda}\\bigg)^2 \\Leftarrow \\space E(X^2) = \\cfrac{2}{\\lambda^2} \\\\[1em] &amp;amp; = \\cfrac{2-1}{\\lambda^2} \\\\[1em] &amp;amp;= \\cfrac{1}{\\lambda^2}\\end{align}\\]1.5   베타 분포(Beta Distribution)1.5.1 정의확률 변수가 0과 1사이에서 정의되는 연속형 확률 분포입니다. 모수 \\(a\\), \\(b\\)에의해 분포의 모양이 유연하게 변화할 수 있는 특성이 있습니다. 확률 변수의 범위가 0과 1사이라는 특성 때문에 0과 1사이에서 정의되는 parameter를 가지는 사전 확률 분포로 자주 활용됩니다.\\[X \\sim Beta(a. b)\\]1.5.2 PDF베타 분포의 PDF는 다음과 같습니다. \\(x\\)의 범위가 0과 1사이에만 정의 됩니다.\\[f_{X}(x) = \\begin{cases} \\cfrac {1} {\\beta(a, b)}x^{a-1}(1-x)^{b-1} &amp;amp;, \\space 0 \\lt x \\lt1 \\\\[1em] 0 &amp;amp;, \\space \\text{otherwhise} \\end{cases}\\]참고로 \\(\\beta(a,b)\\)은 정규화 상수(normalizing constant)로서 적분시 값이 1이 되도록 보장하기 위해 필요한 값이며 beta integral을 통해서 도출됩니다.\\[\\beta(a,b) = \\int_{0}^{1}x^{a-1}(1-x)^{b-1}dx\\]정규화 상수의 값이 어떻게 도출되는지 궁금지 않으신가요? 정규화 상수는 감마 분포와의 관계를 통해서 도출이 가능합니다. 다음을 가정을 통해 정규화 상수를 유도해 봅시다.\\[X \\sim Gamma(a, 1)\\]\\[Y \\sim Gamma(b, 1)\\]\\[T = X+Y\\]\\[W = \\cfrac{X}{X+Y}\\]\\[\\text{Suppose X, Y are independent}\\]다음으로 \\(T\\)와 \\(W\\)의 결합 확률 분포 \\(f_{T,W}(t,w)\\)를 계산 해보겠습니다. 이때 확률 변수의 변환(transformation of random variable) 개념이 사용되었습니다. 확률변수 변환에 대한 자세한 내용은 이 곳2을 참조해 주시길 바랍니다.\\[\\begin{aligned} f_{T,W}(t,w) &amp;amp;= f_{X,Y}(x,y)\\Bigg\\vert det\\bigg(\\cfrac{\\partial(x, y)}{\\partial(t, w)}\\bigg)\\Bigg\\vert \\\\[1em] &amp;amp;= f_{X}(x)f_{Y}(y)\\Bigg\\vert det\\bigg(\\cfrac{\\partial(x, y)}{\\partial(t, w)}\\bigg)\\Bigg\\vert \\Leftarrow \\space \\text{independence of X and Y} \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}x^{a}e^{-x}y^{b}e^{-y}\\cfrac{1}{xy}\\Bigg\\vert det\\bigg(\\cfrac{\\partial(x, y)}{\\partial(t, w)}\\bigg)\\Bigg\\vert \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}x^{a}e^{-x}y^{b}e^{-y}\\cfrac{1}{xy}\\Bigg\\vert det\\bigg( \\begin{bmatrix} \\partial x/\\partial t &amp;amp; \\partial x/\\partial w \\\\ \\partial y/\\partial t &amp;amp; \\partial y/\\partial w \\\\ \\end{bmatrix} \\bigg)\\Bigg\\vert \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}x^{a}e^{-x}y^{b}e^{-y}\\cfrac{1}{xy}\\Bigg\\vert det\\bigg( \\begin{bmatrix} w &amp;amp; t \\\\ 1-w &amp;amp; -t \\\\ \\end{bmatrix} \\bigg)\\Bigg\\vert \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}x^{a}e^{-x}y^{b}e^{-y}\\cfrac{1}{xy}\\Bigg\\vert -wt-t+tw \\Bigg\\vert \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}x^{a}e^{-x}y^{b}e^{-y}\\cfrac{1}{xy}t \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}x^{a-1}e^{-x}y^{b-1}e^{-y}t \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}(tw)^{a-1}e^{-x}(t(1-w))^{b-1}e^{-y}t \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}w^{a-1}(1-w)^{b-1}e^{-(x+y)}t^{a+b-1} \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}w^{a-1}(1-w)^{b-1}e^{-t}t^{a+b}\\cfrac{1}{t} \\\\[1em] &amp;amp;= \\cfrac{1}{\\Gamma(a) \\Gamma(b)}w^{a-1}(1-w)^{b-1}\\Gamma(a+b) \\cfrac{1}{\\Gamma(a+b)} e^{-t}t^{a+b}\\cfrac{1}{t} \\\\[1em] &amp;amp;= \\cfrac{\\Gamma(a+b) }{\\Gamma(a) \\Gamma(b)}w^{a-1}(1-w)^{b-1}\\cfrac{1}{\\Gamma(a+b)} e^{-t}t^{a+b}\\cfrac{1}{t} \\\\[1em] \\end{aligned}\\]위와 같이 결합 확률 분포 \\(f_{T,W}(t,w)\\)를 도출할 수 있습니다. 이제 거의 다 왔습니다!! 결론적으로 말하면, 주변 확률 분포인 \\(f_{W}(w)\\)를 유도하면 베타 분포의 정규화 상수와 감마 분포와의 관계성을 도출할 수 있습니다.\\[\\begin{aligned} f_{W}(w) &amp;amp;= \\int_{-\\infty}^{\\infty} f_{T,W}(t, w)dt \\\\[1em] &amp;amp;= \\int_{-\\infty}^{\\infty} \\cfrac{\\Gamma(a+b) }{\\Gamma(a) \\Gamma(b)}w^{a-1}(1-w)^{b-1}\\cfrac{1}{\\Gamma(a+b)} e^{-t}t^{a+b}\\cfrac{1}{t} \\\\[1em] &amp;amp;= \\cfrac{\\Gamma(a+b) }{\\Gamma(a) \\Gamma(b)} w^{a-1}(1-w)^{b-1} \\end{aligned}\\] 참고로, 두번째 항에서 세번째 항으로 변화한 것은 \\(\\cfrac{1}{\\Gamma(a+b)} e^{-t}t^{a+b}\\cfrac{1}{t}\\) 가 \\(Gamma(a+b, \\space 1)\\)의 PDF이기 때문입니다. 확률 분포 전체의 합은 1이 된다는 것을 상기해봅시다.따라서 베타 분포의 정규화 상수 \\(\\cfrac {1} {\\beta(a, b)}\\)는 \\(\\cfrac{\\Gamma(a+b) }{\\Gamma(a) \\Gamma(b)}\\)이며, 베타 분포의 정규화 상수는 감마 분포의 비율과 연관되어 있다는 것을 유도할 수 있습니다.1.5.3 기댓값감마 함수의 재귀 공식 \\(\\Gamma(a+1) = a \\Gamma(a)\\), \\(\\Gamma(a) = \\cfrac{\\Gamma(a+1)}{a}\\)을 이용하면 베타 분포의 기대값을 계산할 수 있습니다.\\[\\begin{align}E(T) &amp;amp;= \\int_{0}^{1}t \\cdot \\cfrac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} t^{a-1}(1-t)^{b-1}dx \\tag{1}\\\\[1em] &amp;amp;= \\int_{0}^{1} \\cfrac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} t^{a}(1-t)^{b-1}dx \\tag{2} \\\\[1em] &amp;amp;= \\int_{0}^{1} \\cfrac{\\cfrac{\\Gamma(a+b+1)}{a+b}}{\\cfrac{\\Gamma(a+1)\\Gamma(b)}{a}}t^{a}(1-t)^{b-1}dx \\tag{3} \\\\[1em] &amp;amp;= \\cfrac{a}{a+b} \\int_{0}^{1} \\cfrac{\\Gamma(a+1+b)}{\\Gamma(a+1)\\Gamma(b)}t^a(1-t)^{b-1}dx \\tag{4} \\\\[1em] &amp;amp;= \\cfrac{a}{a+b} \\tag{5}\\end{align}\\]특히 식 \\((4)\\)의 적분 부분은 \\(Beta(a+1, \\space b)\\)의 PDF임을 눈치 채셨다면, 당연히 확률 분포의 적분값은 1이 됨을 알 수 있습니다.1.5.4 분산분산도 기댓값과 같은 방식으로 감마 함수의 재귀 공식을 활용하여 도출할 수 있습니다. \\(Var(X) = E(X^2) - E(X)^2\\) 공식을 활용하기 위해 \\(E(X^2)\\)을 먼저 구해보겠습니다.\\[\\begin{align} E(T^2) &amp;amp;= \\int_{0}^{\\infty} t^2 \\cfrac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} t^{a-1} (1-t)^{b-1}dt \\tag{1} \\\\[1em] &amp;amp;= \\cfrac{a(a+1)}{(a+b)(a+b+1)} \\int_{0}^{\\infty} \\cfrac {\\Gamma(a+b+2)} {\\Gamma(a+2) \\Gamma(b)} t^{a+1} (1-t)^{b-1} dt \\tag{2} \\\\[1em] &amp;amp;= \\cfrac{a(a+1)}{(a+b)(a+b+1)} \\tag{3}\\end{align}\\]식 \\((2)\\)의 적분 부분은 \\(Beta(a+2, \\space b)\\)의 PDF입니다. 확률 분포이므로 적분 값이 1임을 알 수 있습니다. 최종적으로 분산을 구해보겠습니다.\\[\\begin{align} Var(T) &amp;amp;= \\cfrac {a(a+1)} {(a+b)(a+b+1)} - \\cfrac{aa}{(a+b)(a+b)} \\\\[1em] &amp;amp;= \\cfrac {a} {a+b} \\cdot \\cfrac{(a+1)(a+b) - a(a+b+1)}{(a+b)(a+b+1)} \\\\[1em] &amp;amp;= \\cfrac {ab} {(a+b+1)(a+b)^2}\\end{align}\\]1.6   감마 분포(Gamma Distribution)1.6.1 정의\\(a\\)번째 사건이 발생하기까지 대기시간에 대한 연속형 확률 분포를 나타냅니다. 참고로 감마 분포, 지수 분포, 포아송 분포는 포아송 과정(poisson process)에서 서로 연관이 되어 있는데, 관련 내용은 appendix를 참고해주세요.\\[Y \\sim Gamma(a, \\lambda)\\]1.6.2 PDF감마 분포는 감마 함수와 표준 감마 분포 \\(Gamma(a, 1)\\)의 PDF를 구하면 손쉽게 도출 가능합니다. 먼저 감마 함수를 정의해 보겠습니다. 감마 함수는 다음과 같습니다.\\[\\begin{aligned}\\Gamma(a) &amp;amp;= \\int_{0}^{\\infty}x^{a-1}e^{-x}dx \\\\[1em]&amp;amp;= \\int_{0}^{\\infty}x^{a}e^{-x}\\cfrac{1}{x}dx\\end{aligned}\\]이제 감마 함수의 양변을 \\(\\Gamma(a)\\)로 나누어 봅시다. 이를 통해 우리는 \\(\\cfrac{1}{\\Gamma(a)} x^{a-1} e^{-x}\\)를 0부터 무한대까지 더했을 때의 값이 \\(1\\) 사실을 유도할 수 있습니다. 모든 가능한 값들을 다 더해서 1…? 확률 분포의 적분값이 1이라는 사실을 통해, 우리는 \\(\\cfrac{1}{\\Gamma(a)} x^{a-1} e^{-x}\\)가 확률 분포임을 알 수 있습니다. 다시 말해 감마 함수에 약간의 조작을 가해서 표준 감마 분포 \\(Gamma(a, 1)\\)의 PDF(\\(x&amp;gt;0\\))가 도출 되었습니다.\\[\\begin{aligned}\\cfrac{1}{\\Gamma(a)} \\Gamma(a) &amp;amp;= \\int_{0}^{\\infty}\\cfrac{1}{\\Gamma(a)} x^{a-1} e^{-x}dx \\\\[1em]1 &amp;amp;= \\int_{0}^{\\infty}\\cfrac{1}{\\Gamma(a)} x^{a-1} e^{-x}dx \\\\[1em] \\end{aligned}\\]이제 표준 감마 분포를 일반화 하여 감마 분포를 도출해 봅시다. \\(X \\sim Gamma(a, 1)\\), \\(Y=\\cfrac{X}{\\lambda}\\) 일때, \\(Y\\)의 PDF를 찾아봅시다.\\[\\begin{aligned}f_{Y}(y) &amp;amp;= f_{X}(x)\\cfrac{dx}{dy} \\\\[1em]&amp;amp;= \\cfrac{1}{\\Gamma(a)}(\\lambda y)^{a-1}e^{-\\lambda y} \\lambda \\space \\Leftarrow \\space \\because \\space x=\\lambda y \\space \\text{and} \\space \\lambda = \\cfrac{dx}{dy} \\\\[1em]&amp;amp;= \\cfrac{\\lambda^{a}}{\\Gamma(a)}y^{a-1}e^{-\\lambda y}\\end{aligned}\\]1.6.3 기댓값감마 분포의 기댓값은 감마 함수의 재귀 공식 \\(\\Gamma(a+1) = a \\Gamma(a)\\)을 활용하면 쉽게 구할 수 있습니다. 먼저 \\(X \\sim Gamma(a, 1)\\)일때, \\(nth\\) moment를 구해보도록 하죠.\\[\\begin{aligned}E(X^n) &amp;amp;= \\cfrac{1}{\\Gamma(a)}\\int_{0}^{\\infty} x^{n}\\cdot x^{a} e^{-x} \\cfrac{1}{x}dx \\\\[1em]&amp;amp;= \\cfrac{1}{\\Gamma(a)}\\int_{0}^{\\infty} x^{a+n} e^{-x} \\cfrac{1}{x} dx \\\\[1em]&amp;amp;= \\cfrac{\\Gamma(a+n)}{\\Gamma(a)} \\space \\Leftarrow \\space \\Gamma(a+n) = \\int_{0}^{\\infty} x^{a+n} e^{-x} \\cfrac{1}{x} dx\\end{aligned}\\]결국 확률 변수 \\(X\\)의 \\(nth\\) moment는 감마 함수로 표현할 수 있게됨을 알 수 있습니다. 이제 기대값을 구해보죠.\\[\\begin{aligned}E(X)&amp;amp;= \\cfrac{\\Gamma(a+1)}{\\Gamma(a)} \\\\[1em]&amp;amp;= \\cfrac{a\\Gamma(a)}{\\Gamma(a)} \\\\[1em]&amp;amp;= a\\end{aligned}\\]표준 감마 분포의 기대값은 \\(a\\)임을 알 수 있습니다. \\(Y = \\cfrac{1}{\\lambda}\\)를 이용하여 일반 감마 분포의 기대값을 도출해 봅시다.\\[\\begin{aligned}E(Y) &amp;amp;= E\\bigg(\\cfrac{X}{\\lambda}\\bigg) \\\\&amp;amp;= \\cfrac{1}{\\lambda}E(X) \\\\&amp;amp;= \\cfrac{a}{\\lambda}\\end{aligned}\\]1.6.4 분산분산도 역시 \\(X \\sim Gamma(a, 1)\\) 일때를 기준으로 \\(X\\)의 \\(nth\\) moment를 구하여 도출할 수 있습니다. 아참, \\(Var(X) = E(X^2) - E(X)^2\\)임을 상기해주세요.\\[\\begin{aligned}Var(X)&amp;amp;= E(X^2) - E(X)^2 \\\\[1em]&amp;amp;= \\cfrac{\\Gamma((a+1) +1)}{\\Gamma(a)} - \\bigg( \\cfrac{\\Gamma(a+1)}{\\Gamma(a)} \\bigg)^{2} \\\\[1em]&amp;amp;= \\cfrac{(a+1)\\Gamma(a+1)}{\\Gamma(a)} - \\bigg( \\cfrac{a\\Gamma(a)}{\\Gamma(a)} \\bigg)^{2} \\\\[1em]&amp;amp;= \\cfrac{(a+1)a\\Gamma(a)}{\\Gamma(a)} - a^{2} \\\\[1em]&amp;amp;= a^{2} +a - a^{2} \\\\[1em] &amp;amp;= a\\end{aligned}\\]이상 표준 감마 분포의 분산을 도출 했습니다. 표준 감마 분포의 기대값과 마찬가지로 \\(a\\)임을 알 수 있습니다. 그럼 마지막으로 감마 분포의 분산을 계산해 보겠습니다.\\[\\begin{aligned}Var(Y) &amp;amp;= E(Y^2) - E(Y)^2 \\\\[1em]&amp;amp;= \\cfrac{1}{\\lambda^2}E(X^2) - \\bigg(\\cfrac{1}{\\lambda}E(X) \\bigg)^2 \\\\[1em]&amp;amp;= \\cfrac{a^2+a}{\\lambda^2} - \\bigg(\\cfrac{a}{\\lambda}\\bigg)^2 \\\\[1em]&amp;amp;= \\cfrac{a}{\\lambda^2}\\end{aligned}\\]2   부록: 포아송 과정(Poisson Process)34지수 분포, 감마 분포, 포아송 분포가 관련되어 있는데 포아송 과정에 대해서 알아보겠습니다. 사실 포아송 과정을 이해하기 위해서는 먼저 확률 과정(stochastic process) 및 셈 과정(counting process)에 대한 개념이 있어야 합니다. 단어가 정말 어려운데… 하나하나 차근차근 살펴보죠. 먼저 과정(process)란 단어가 굉장히 어렵게 느껴집니다. 통계에서 활용되는 과정이라는 개념은 시간과 관련 있는 개념이라고 생각하시면 조금 쉬울 것 같습니다.2.1   확률 과정(stochastic process)과정은 시간과 관련된 개념이라는 것은 알겠는데… 그래서 확률 과정(stochastic process)란 무슨 뜻일까요? 확률 과정이란 순차적으로 관측되는 확률 변수들의 집합을 의미합니다. 다시 말해 어느 시점 \\(t\\)에서의 값이 상수가 아니라 어떤 값을 확률적으로 가지는 확률 변수라는 의미입니다. 예를 들어 60분 동안 도착하는 이메일의 개수와 같이 연속 구간(보통 시간)에서 발생하는 불규칙적인 사건을 모델링 하는데 활용됩니다. 여기서 60분 동안 도착하는 이메일의 개수는 2개, 3개와 같이 고정된 상수 값이 아니라 어떤 분포를 따르는 확률 변수 입니다.2.2   셈 과정(counting process)그렇다면 셈 과정(counting process)란 무엇일까요? 셈 과정이란 \\(t\\)시간 동안 발생하는 사건의 수를 나타내는 확률 과정을 뜻합니다. 위에서 언급한 60분 동안 도착하는 이메일 수, 1분 동안 은행에 방문하는 고객 수와 같은 것들이 셈 과정의 대표적인 예시라고 하겠습니다. 셈 과정은 확률 과정이므로 확률 변수들의 집합 입니다. 따라서 셈 과정은 아래와 같이 나타낼 수 있습니다.\\[\\{N(t), \\space t \\ge0\\} \\\\[1em]\\]\\[N(t) \\space \\text{represents the number of events that have occured through time} \\space t\\]2.3   포아송 과정(poisson process)마지막으로 포아송 과정(poisson process)는 무엇일까요? 포아송 과정은 아래의 조건을 따르는 셈 과정을 뜻합니다. 요악하자면, \\(t\\) 시점까지의 사건 발생 횟수가 포아송 분포를 따르는 셈과정이라고 할 수 있겠습니다.(1) \\(N(0)=0\\)(2) 모든 \\(t\\)에 대해 \\(N(t) \\sim \\text{Pois}(\\lambda), P(N(t)=n)=\\cfrac{(\\lambda t)^{n}e^{-\\lambda t}}{n!}\\)(3) (독립 증분) \\(0 \\le q \\le r \\le s \\le t\\)인 \\(q,r,s,t\\)에 대해 \\(N(t)-N(s)\\)와 \\(N(r)-N(q)\\)는 독립인 확률 변수(4) (정상 증분) 모든 \\(s, t \\ge 0\\)에 대해 \\(N(t+s)-N(s)\\)는 \\(N(t)\\)와 같은 분포독립 증분(independent increment)이란 서로 다른 시간 구간에서 발생하는 사건의 수가 서로 연관이 없다는 성질을 말하며, 정상 증분(stationary increment)란 두 시점 사이에 발생하는 사건의 수가 두 시점간의 시간의 폭에만 의존하는 성질을 의미합니다.참고자료 공돌이의 수학 정리 노트: 가우스 적분 &amp;#8617; &amp;#8617;2 분석 벌레의 공부방: 확률변수들의 함수 &amp;#8617; Seoncheol Park: 포아송과정(Poisson process) &amp;#8617; 종혁의 저장소: [확률 과정] 푸아송 과정 &amp;#8617; " }, { "title": "글또 5기로서의 다짐", "url": "/posts/gulddo/", "categories": "ETC, Retrospective", "tags": "retrospective", "date": "2020-11-11 09:48:00 +0900", "snippet": "안녕하세요. 이커머스 도메인에서 데이터 분석을 하고 있는 구국원이라고 합니다. 평소에 블로그에 글을 작성하고는 있었지만 특정 독자를 염두에 둔 글이 아니다 보니 글이 흐지부지 되는 경우가 많았습니다. 그러던 중 글또라는 좋은 취지의 모임(?)이 있다는 소식을 주변 동료에게 접하고 바로 지원서를 작성하게 되었습니다. 또 운이 좋게도 글또 활동을 할 수 있는 기회를 주셔서 글을 쓰는 이유와 어떤 종류의 글을 쓰고 싶은지에 대해서 정리하고 남은 올해의 목표를 간략하게 작성해 보겠습니다.글을 쓰려는 이유?데이터 사이언티스트는 배우고 내면화 해야할 지식이 매우 넓고 깊습니다. 특히 수리적 지식이 많이 요구되는데요. 다음은 머신러닝 속 필요한 수학을 요약한 그림입니다. 데이터 사이언스를 제대로 하기 위해서는 엄청난 수리적 지식이 요구됨을 알 수 있습니다.잘 구축된 머신러닝, 딥러닝 라이브러리들은 많습니다. 그런데 어느 순간부터 이런 라이브러리를 수리적으로 깊게 이해하지 못하고 머신러닝 모델을 구축하는 것에 회의감이 들었습니다. 모래성을 쌓는 기분이라고 해야할까요? 이렇게 어느 순간 현타가 온 뒤로 개념적으로 알고 있던 머신러닝 이론들의 수리적인 근거들을 탐구하고 싶은 욕구가 강하게 생겼습니다. 특히 실무를 하면서 만나게 되는 머신러닝 자료들을 빠르게, 잘 이해하고 싶었습니다. 이를 위해서는 결국 기초를 탄탄히 해야 되겠다는 생각이 들었고 확률 및 통계 이론을 처음부터 다시 공부를 해보자고 결심을 했습니다. 특히 제가 알고 있는 수리적 지식들이 파편적으로 흩어져 있었기 때문에 정규 과정을 수강하고, 학습한 지식을 체계화 하는 것이 느리지만 가장 빠른 길이라고 판단했습니다.그러나 학습한 지식들은 휘발성이 매우 강합니다. 나만의 언어로 표현하고 정리하지 않으면 금방 사라지기 마련이죠. 따라서 저는 학습한 내용을 글로 남기기로 결심하였습니다. 글을 쓰는 과정은 결국 파편적인 정보를 나만의 언어로 정리하는 과정입니다. 하나의 글을 완성하기 위해서는 어떻게 표현 해야 독자들이 이해하기 쉬울지, 교수님이 설명하진 않았지만 추가적으로 알면 좋은 정보가 어떤 것이 있을지를 끊임없이 고민하기 때문입니다. 따라서 저는 이번 글또 5기 활동을 통해서 글을 꾸준히 작성하는 습관을 들여 보려고 합니다.어떤 글을 쓸까?글을 쓰는 이유에서 언급했다시피 작성하는 글은 주로 아래의 세 가지 영역이 될 것 같습니다. 통계, 선형대수 등의 수학과 관련된 학습 내용 정리 머신러닝/딥러닝 관련 논문 내용 정리그런데 두가지 영역 모두 엄청 딱딱하고 지루할 것으로 예상되는데… 어떻게 하면 쉽게 풀어 쓸지가 고민됩니다. 사실 쉽게 풀어 쓰는 방법이 있을지도 잘 모르겠네요… 🤣 그래도 제가 문돌이 출신인만큼 수리적 개념을 최대한 비유를 들어서 설명해보려고 노력하겠습니다.남은 올해의 목표는?일단 올해의 최대 과제 중 하나가 하버드 statistics 110 강의를 완강하는 것이었는데요. 목표는 일단 달성 했습니다 😊 그러나 자체 평가를 했을 때 강의에 대한 이해도가 50% 정도 수준인 것 같아서 11월 중에는 해당 강의 내용을 쭉 복습하는 방향으로 진행하려고 합니다. 그리고 나서는 아직 정확한 목표는 잡지 못했는데요. 선형대수학 쪽을 다시 정리할 것인지 아니면 추론 통계쪽으로 가지를 뻗어 나갈지 확실히 정하지는 못했습니다. 결국 두 가지 다 언젠가는 공부해야하는 것들이지만… 실무에 필요한 우선순위를 정해 두고 공부를 해볼 생각입니다. 앞으로 따끔한 질책 부탁드립니다. 긴 글 읽어 주셔서 감사합니다.참고자료 The Mathematics of Machine Learning [번역] 머신러닝 속 수학 " }, { "title": "이산형 확률 분포 정리", "url": "/posts/discrete_distributions/", "categories": "Math, Statistics", "tags": "statistics, distribution", "date": "2020-11-05 20:53:00 +0900", "snippet": "이산형 확률 분포에 대해서 정리해 보았습니다. 본 내용은 하버드 확률론 기초 강의(Statistics 110)를 참고하여 정리했음을 밝힙니다.연속형 확률 분포에 대한 글은 이곳을 참고해주세요.0   확률 변수(Random Variable)와 확률 분포(Distribution)확률 변수란 표본 공간(\\(S\\))에서 발생 가능한 outcome을 실수 공간에 맵핑 시키는 함수를 의미합니다. 확률 변수는 함수이기 다음과 같이 표현 할 수 있습니다.\\[X:S \\rightarrow \\mathbb{R}\\]확률 분포는 확률 변수와 깊은 관련성으로 인해 헷갈리기 쉬운 개념입니다. 확률 변수와 확률 분포의 공통점은 함수라는 점입니다. 그러나 함수의 역할이 다르다는 점에서 차이가 있는데, 확률 분포란 확률 변수가 특정한 값을 가질 확률을 나타내는 함수를 의미합니다.1 확률 분포는 확률 변수가 어떤 종류의 값을 가지느냐에 따라서 크게 이산 확률 분포와 연속 확률 분포로 구분됩니다. 이산 확률 분포는 확률 질량 함수(PMF, Probability Mass Function)로 표현 가능 하며, 연속 확률 분포는 확률 밀도 함수(PDF, Probability Density Function)으로 표현 가능 합니다.1   이산 확률 변수(Discrete Random Variable) 분포1.1   이항 분포(Binomial Distribution)1.1.1 정의독립적인 베르누이 시행을 \\(n\\)번 했을 때 성공 횟수 \\(k\\)에 대한 분포입니다.\\(X \\sim Bin(n,p)\\)1.1.2 PMF이항 분포의 PDF는 아래와 같습니다.\\[P(X=k)= {n \\choose k} p^{k}(1-p)^{n-k}\\] 이항분포에 왜 조합(combination)이 있을까요? 독립적인 동전 던지기 시행을 5번 했을 때, 2번 성공(=앞면이 나옴) 했을 때를 가정해봅시다. 첫번째, 세번째에서 동전의 앞면이 나왔을 때와 두번째 다섯번째에서 동전이 앞면이 나오는 경우는 모두 같은 확률 \\(p^{2}(1-p)^{3}\\)입니다. 그러나 두 경우 모두 \\(X=2\\) 사건이므로 이러한 경우를 모두 고려하여 확률 분포를 고안해야 합니다. 다시말해, 5개 중 2개를 순서와 상관없이 뽑는 경우를 모두 고려해야하며, 각각의 사건은 서로 배반사건(disjoint, 동시에 발생할 수 없음)입니다.1.1.3 PMF 검증먼저 이항 정리(binomial theorem)에 대해서 간단하게 알아보겠습니다. 이항 정리란 \\((p+q)\\)의 거듭 제곱의 전개식을 말합니다2. 참고로 먼저 이항(二項)은 두 개의 항이라는 뜻이며, 항을 옮긴다는 이항(移項))의 뜻이 아님을 주의해주세요.\\[\\sum_{k=0}^{n} {n \\choose k}p^{k}q^{n-k} = (p+q)^n\\]이항 정리를 알아본 이유는 이항 정리를 활용하면 PMF를 검증할 수 있기 때문입니다. 아래 식을 살펴 보시면 이항 분포를 따르는 확률 변수 \\(X\\)에 대응되는 모든 확률의 합이 \\(1\\)이 된다는 것을 쉽게 알 수 있습니다. 위에서 언급한 이항 정리 식이 어떻게 쓰였는지 살펴 보시길 바랍니다.\\[\\begin{aligned}P(S) &amp;amp;= P(X=0) + P(X=1) + \\cdots + P(X=n) \\\\[1em]&amp;amp;= \\sum_{k=0}^{n}p^{k}(1-p)^{n-k} = (p+(1-p))^n \\\\[1em]&amp;amp;= 1^n = 1\\end{aligned}\\]1.1.4 기댓값향후 추가 1.1.5 분산이항 분포의 분산은 지시 확률 변수(indicator random variable)을 활용하여 구할 수 있습니다. 먼저, 지시 확률 변수란 어떤 사건(event)가 발생 했을 때는 1, 발생하지 않았을 때는 0을 출력하는 함수입니다.\\[I = \\begin{cases} 1 &amp;amp;\\text{if } \\space \\text{event occured} \\\\ 0 &amp;amp;\\text{if } \\space \\text{otherwise}\\end{cases}\\]이항 분포는 독립적인 베르누이 시행에서의 성공 횟수에 대한 분포임을 언급 했습니다. 다시 말해서 이항 분포의 확률 변수는 베르누이 시행의 지시 확률 변수의 합으로 표현할 수 있습니다.\\[\\text{Let} \\space X \\sim Bin(n,p), \\\\[1em]X = I_1 + \\cdots + I_n, \\text{where} \\space I_j \\space \\text{are} \\space \\text{i.i.d.} \\space Bern(p)\\]먼저 베르누이 분포의 분산 \\(Var(I_j)\\)를 구해보겠습니다.\\[\\begin{aligned}Var(I_j)&amp;amp;= E(I_{j}^2) - E(I_{j})^2 \\\\[1em]&amp;amp;= \\sum_{x \\in\\{0,1\\}}x^{2}P(X=x) - p^2 \\\\[1em]&amp;amp;= p-p^2 \\\\[1em]&amp;amp;= p(1-p)\\end{aligned}\\]이항 분포의 확률 변수는 베르누이 지시 확률 변수의 합이므로 이항 분포의 분산은 다음과 같이 도출됩니다.\\[\\begin{align} Var(X) &amp;amp;= Var(I_{1} + \\cdots + I_{n}) \\\\[1em] &amp;amp;= Var(I_{1}) + \\cdots + Var(I_{n}) \\Leftarrow \\text{by independence} \\\\[1em] &amp;amp;= p(1-p) + \\cdots + p(1-p) \\\\[1em] &amp;amp;= np(1-p)\\end{align}\\]1.2   기하 분포(Geometric Distribution)1.2.1 정의독립적인 베르누이 시행에서 첫 성공까지의 실패 횟수에 대한 분포입니다. 참고로 기하 분포와 비슷한 의미를 지니는 연속형 확률 분포로 지수 분포(exponential distribution)이 있습니다.\\[X \\sim Geom(p)\\]1.2.2 PMF\\[P(X=k) = q^kp\\]1.2.3 PMF 검증\\[\\sum_{k=0}^{\\infty}q^kp = p\\sum_{k=0}^{\\infty}q^k = \\cfrac{p}{1-q} = \\cfrac{1-q}{1-q} = 1\\]1.2.4 기댓값향후 추가1.2.5분산향후 추가1.3   음이항 분포(Negative Binomial Distribution)1.3.1 정의독립적인 베르누이 시행에서 \\(r\\)번 성공하기 까지의 실패 횟수에 대한 분포입니다. 참고로 음이항 분포와 비슷한 의미를 지니는 연속형 확률 분포로는 감마 분포(gamma distribution)를 들 수 있습니다.\\[X \\sim NB(r, p)\\]1.3.2 PMF향후 추가1.3.3 PMF 검증향후 추가1.3.4 기댓값향후 추가1.3.5 분산향후 추가1.4   초기하 분포(Hypergeometric Distribution)1.4.1 정의크기가 \\(N\\)인 모집단에서 \\(n\\)개의 표본을 비복원 추출 했을 때 성공 횟수 \\(k\\)에 대한 분포입니다. 예를 들어 파란 공이 담긴 주머니에 8개의 공이 있고 빨간 공이 담긴 주머니에 2개의 공이 있다고 가정해봅시다. 이때 모집단의 크기는 10인데, 여기서 비복원 추출로 2개를 뽑았을 때, 파란 공이 뽑힌 개수는 초기하 분포를 따릅니다. 같은 행위를 복원 추출로 하였을 때는 이항 분포가 됩니다.\\[X \\sim HGeom(N, n, p)\\]1.4.2 PMF\\[P(X=k) = \\cfrac { {w \\choose k} {b \\choose {n-k}} } { {N \\choose n} }\\]1.4.3 PMF 검증\\[\\begin{align} \\sum_{k=0}^{n} P(X=k) &amp;amp;= \\sum_{k=0}^{n} \\cfrac {\\binom wk \\binom b{n-k}} {N \\choose n} \\\\[1em] &amp;amp;= \\cfrac {1} {N \\choose n} \\sum_{k=0}^{n}{w \\choose k} {b \\choose n-k} \\\\[1em] &amp;amp;= \\cfrac {N \\choose n} {N \\choose n} = 1\\end{align}\\]참고로 3번째 term에서 4번째 term으로의 변화는 Vandermonde 항등식에 의해서 가능합니다.\\[{w+b \\choose k} = \\sum_{k=0}^{n} {w \\choose k} {b \\choose n-k}\\]1.4.4 기댓값향후 정리1.4.5 분산향후 정리1.5   포아송 분포(Poisson Distribution)1.5.1 정의단위 시간/공간 동안의 사건 발생 횟수에 대한 이산 확률 분포를 말합니다. 모수인 \\(\\lambda\\)는 단위 시간 동안의 평균 사건 발생 횟수를 뜻합니다. 여기서 ‘평균’이라는 단어를 쓴 이유는, 포아송 분포의 기댓값(평균)이 \\(\\lambda\\)이기 때문입니다.\\[P(X=k) \\sim Pois(\\lambda)\\]1.5.2 PMF\\[P(X=k) = \\cfrac{\\lambda^ke^{-\\lambda}}{k!}\\]1.5.3 PMF 검증먼저 우리는 \\(e^\\lambda\\)의 talyor series(expansion)을 아래와 같이 나타낼 수 있다는 것을 알고 있습니다.\\[e^{\\lambda} = \\sum_{k=0}^{\\infty}\\frac{\\lambda^k}{k!}\\]이와 같은 사실을 활용해 PMF를 검증해보겠습니다.\\(\\sum_{k=0}^{\\infty} \\cfrac{\\lambda^k e^{-\\lambda}}{k!} = e^{-\\lambda} \\sum_{k=0}^{\\infty} \\cfrac{\\lambda^k}{k!} = e^{-\\lambda}e^{\\lambda}=1\\)​1.5.4 기댓값\\[\\begin{aligned}E(X) &amp;amp;= e^{-\\lambda} \\sum_{k=0}^{\\infty} k \\cfrac{\\lambda^k}{k!} \\\\[1em]&amp;amp;= e^{-\\lambda} \\sum_{k=1}^{\\infty} \\cfrac{\\lambda^k}{(k-1)!} \\\\[1em]&amp;amp;= \\lambda e^{-\\lambda} \\sum_{k=1}^{\\infty} \\cfrac{\\lambda^{k-1}}{(k-1)!} \\\\[1em]&amp;amp;= \\lambda e^{-\\lambda} e^{\\lambda} \\\\[1em]&amp;amp;= \\lambda\\end{aligned}\\]1.5.5 분산향후 추가1.5.6 이항 분포와의 관계먼저 이항 분포를 ‘시간’의 맥락에서 생각해 보겠습니다. 음식점에 방문하는 손님의 수를 이항 분포로 모델링 하는데, 하루동안 음식점에 한명의 고객이 방문할 확률을 0.3이라고 해보죠. 그렇다면 10일간 4명의 고객이 방문할 확률은 \\(P(X=4)={10 \\choose 4}0.3^40.7^6\\)으로 계산할 수 있습니다. 그러나 이러한 계산은 직관적으로 보았을 때 어딘가 부족해 보입니다.위의 예시를 이항 분포로 모델링할 경우에는 하루동안 음식점에 방문하는 손님이 1명이라는 가정이 내재되어있습니다. 그런데 이러한 가정은 너무 비현실적이죠. 하루동안 여러명이 손님이 방문할 수 있다는 정보를 반영하여 모델링을 할 수 없을까요? 시간을 더욱 작은 단위로 쪼개면 가능할 것 같습니다. 예를들어 24시간이라는 1시간 단위로 잘게 쪼개서 한 시간 단위로 방문자 수를 모델링하면 결국 하루 동안의 방문자가 여러명이 될 수도 있다는 정보를 반영할 수 있게 됩니다.이항 분포의 시행을 최대한 잘게 쪼갠댜는 말은 결국 시행을 무한번하게 되는 것과 동치가 됩니다. 이러한 맥락에서 포아송 분포가 등장하게 됩니다. 포아송 분포는 단위 시간당 평균 사건 발생 횟수를 나타내는 \\(\\lambda\\)를 모수로 가지고 있습니다. 그리고 이항 분포의 기대값은 \\(np\\)입니다. 평균 사건 발생 횟수를 의미하죠. 따라서 \\(\\lambda=np\\)로 셋팅 해놓고 \\(n\\)을 무한대로 보내면 \\(p\\)는 0으로 수렴하는 방식으로 포아송 분포를 도출할 수 있을 것 같습니다.\\[\\begin{aligned}\\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0}P(X=k) &amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} {n \\choose k}p^k(1-p)^{n-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} {n \\choose k} \\bigg(\\cfrac{\\lambda}{n}\\bigg)^k\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{n-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} {n \\choose k} \\bigg(\\cfrac{\\lambda}{n}\\bigg)^k\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{n}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} \\cfrac{n!}{(n-k)!k!} \\bigg(\\cfrac{\\lambda}{n}\\bigg)^k\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{n}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} \\cfrac{n!}{(n-k)!n^k} \\cfrac{\\lambda^k}{k!}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{n}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} \\cfrac{n(n-1)\\cdots(n-k+1)}{n^k} \\cfrac{\\lambda^k}{k!}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{n}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} \\cfrac{n}{n} \\cfrac{n-1}{n} \\cdots \\cfrac{n-k+1}{n} \\cfrac{\\lambda^k}{k!}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{n}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} \\cfrac{\\lambda^k}{k!}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{n}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} \\cfrac{\\lambda^k}{k!}e^{-\\lambda}\\bigg(1-\\cfrac{\\lambda}{n}\\bigg)^{-k} \\\\&amp;amp;= \\lim_{n \\rightarrow\\infty \\\\ p \\rightarrow0} \\cfrac{\\lambda^k}{k!}e^{-\\lambda} \\\\&amp;amp;= \\cfrac{\\lambda^k}{k!}e^{-\\lambda}\\end{aligned}\\] 참고로 지수 함수에 대한 다음의 식이 활용 되었습니다.\\(e^\\lambda = \\lim_{n \\rightarrow \\infty}\\bigg(1+ \\cfrac{\\lambda}{n} \\bigg)^n \\\\[1em]e^{-\\lambda} = \\lim_{n \\rightarrow \\infty}\\bigg(1 - \\cfrac{\\lambda}{n} \\bigg)^n\\)1.6   다항 분포(Multinomial Distribution)정의\\(k(\\ge 3)\\)개의 상태(outcome)을 가질 수 있는 독립적인 experiment를 \\(n\\)번 시행 했을 때, 각 상태의 발생 횟수에 대한 이산 확률 분포입니다. 이항 분포를 상태가 \\(k(\\ge 3)\\)개 발생할 경우로 일반화 하는 것이라고 생각하면 이해하기 수월합니다. 여기서 \\(X_k\\)는 \\(k\\)번째 상태가 발생한 횟수를 나타내며, \\(p_k\\)는 \\(k\\)번째 상태가 발생할 확률을 나타냅니다.\\[\\vec{X} \\sim Mult_k(N, \\vec{p})\\]\\[\\vec{X}=(X_1, \\cdots, X_k), \\space \\vec{p}=(p_1, \\cdots, p_k)\\]PMF\\[\\text{if} \\space \\sum_k n_k=n \\space \\text{and} \\space 0 \\space \\text{otherwise}\\\\P(X_1=n_1, \\cdots, X_k=n_k)=\\cfrac{n!}{n_1!, \\cdots, n_k!}\\space p_{1}^{n_1} \\cdots p_{k}^{n_k}\\]PMF 검증향후 추가기댓값향후 추가분산향후 추가참고자료 위키피디아: 확률 분포 &amp;#8617; 위키피디아: 이항 정리 &amp;#8617; " }, { "title": "Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift", "url": "/posts/batch_normalization/", "categories": "ML, Paper Review", "tags": "ml, dl, paper, review", "date": "2020-11-03 09:42:00 +0900", "snippet": "배치 정규화(batch normalization) 기법을 자주 활용했으나, 정확한 작동 원리에 대해서 알지 못했기 때문에 논문을 읽고 내용을 정리해 보았습니다. 친절한 논문은 아니어서 읽는데 꽤 시간이 걸렸습니다. 또한 관련 자료를 탐색 하던 중 배치 정규화 논문에서 주장하는 covariate shift에 대해 반박하는 논문도 있다는 정보를 보았는데요. 이 논문도 따로 정리해 보겠습니다. 먼저 논문의 내용을 요약하면 다음과 같습니다. 뉴럴넷 학습을 방해하는 요소로 Internal Covariate Shift 현상을 지목합니다. 다시 말해 학습이 진행되는 동안 network parameter들이 변화하면서 network activation의 distribution이 변화하기 때문에 뉴럴넷의 학습이 느려진다는 것입니다. 배치 정규화는 각 레이어의 출력값을 평균 0, 분산 1의 표준정규분포로 변환하기 때문에 covariate shift 문제를 벗어날 수 있습니다. 배치 정규화를 적용하면 다음의 이점을 얻을 수 있습니다. 학습률을 크게 셋팅할 수 있기 때문에 배치 정규화를 적용하지 않았을 때 대비 수렴 속도가 빠릅니다. 따라서 학습률 감소(learning rate decay)를 기존 보다 빠르게 가져갈 수 있습니다. randomness를 주기 때문에 regularization 효과가 있습니다. 따라서 드롭 아웃을 제거 할 수 있으며, 오버 피팅이 방지되는 효과가 있습니다. 1   Introduction각 레이어의 인풋은 모든 이전 레이어의 파라미터(저자는 가중치라는 표현 대신 파라미터라는 표현을 사용합니다)에 영향을 받습니다. 따라서 앞선 레이어 파라미터의 작은 변화는 네트워크의 층이 깊어질수록 증폭될 것입니다. 각 레이어들은 이전 레이어의 출력 분포의 변화에 맞춰서 계속 해서 학습을 이어나가야 하기 때문에 이전 레이어의 출력 분포의 변화는 네트워크의 학습을 방해합니다.저자는 이러한 현상을 internal covariate shift라고 부릅니다. 만일 각 출력층의 분포를 일정하게 유지할 수 있다면 covariate shift 현상을 억제하여 각 레이어가 이전 레이어의 출력 분포의 변화에 재적응(readjust)할 필요가 없으므로 학습을 원할하게 진행시킬 수 있을 것입니다.레이어 출력 분포를 일정하게 유지시키는 것은 gradient를 잘 흐를 수 있게 한다는 이점도 있습니다. 시그모이드 활성화 함수 \\(g(x) = \\cfrac {1} {1 + exp(-x)}\\)를 생각해 보죠. \\(\\vert x \\vert\\) 값이 커지면 그때의 gradient는 거의 0에 수렴하게 됩니다. 따라서 vanish graident 문제는 학습을 느리게 하는 주요 원인 입니다.\\(\\vert x \\vert\\)값이 커지면 그때의 미분계수는 0에 가까워짐을 알 수 있습니다.따라서 저자는 배치 정규화 기법(batch normalization)의 도입이 네트워크의 각 레이어의 출력 분포를 일정하게 만들어서 네트워크를 빠르게 수렴시킬 수 있다고 주장합니다. 배치 정규화는 네트워크 각 레이어의 출력 분포를 일정하게 유지하여 internal covariate shift 문제를 완화시켜 딥 뉴럴넷의 학습을 가속화시킵니다. 배치 정규화의 자세한 과정은 뒤에서 다시 언급하도록 하겠습니다. 이제 좀더 자세히 알아 보도록 하죠 👊2   Towards Reducing Internal Covariate Shift본 섹션에서 저자는 covariate shift를 줄이기 위해 필요한먼저 internal covariate shift를 정확히 정의해야하겠습니다. internal covariate shift는 학습이 진행되는 동안 네트워크의 파라미터가 지속적으로 갱신됨에 따라 발생하는 네트워크 각 레이어의 출력 분포의 변화를 뜻합니다. 뉴럴넷 학습 과정에서 whitening을 통해 분포를 고정(fixing)하는 것은 학습의 수렴을 빠르게 한다는 것이 기존 연구에 의해 알려져 있습니다([2]). activation을 whitening 하는 방법은 다양합니다. 하지만 중요한 점은 whitening 과정이 반드시 gradient descent 과정에 포함되어야 한다는 것입니다. 그렇지 않다면 어떻게 될까요? 예를 들어 input \\(u\\)와 learnable bias \\(b\\)를 더한후 normalization을 진행하여 \\(\\hat x\\)을 출력하는 간단한 네트워크를 생각해봅시다.\\[\\hat x = x - E[x],\\]\\[\\text {where} \\space x=u+b, \\space X=\\{x_{1 ...N}\\} \\space \\text{is the set of values of} \\space x \\space \\text{over the training set}, \\space \\text{and} \\space E[x] = \\frac{1}{N} \\textstyle \\sum_{i=1}^{N}x_{i}\\]만일 gradient descent 과정에서 \\(E[x]\\)의 \\(b\\)에 대한 의존성을 고려하지 않고 계산 된다면 어떻게 될까요? \\(E(X)\\) 방향으로 gradient를 흘려 보내 않을 때의 상황을 생각하면 직관적으로 이해가 됩니다. 아래의 그림에서 ❌ 부분에 gradient가 흐르지 않는다고 생각해보세요. \\(\\Delta b\\)는 \\(\\frac{\\partial l}{\\partial \\hat x}\\)에 비례하게 됩니다. epoch가 한번 돌면 \\(b\\)는 \\(b+\\Delta{b}\\)로 업데이트 됩니다. 따라서 새로운 \\(\\hat{x}\\)는 아래와 같이 계산 됩니다.\\[\\begin{aligned}\\hat{x}&amp;amp;= u+(b+\\Delta{b}) - E[u+(b+\\Delta{b})] \\\\&amp;amp;= u+b+\\Delta{b}-E[u+b]-\\Delta{b} \\\\&amp;amp;= u+b - E[u+b] \\\\&amp;amp;= x-E[x]\\end{aligned}\\] 분명히 \\(b\\)를 업데이트 했는데도 불구하고 \\(\\hat{x}\\)의 값이 업데이트 전과 동일합니다. 이렇게 되면 파라미터 \\(b\\)가 발산해 버리게 됩니다. 왜냐하면 \\(b\\)는 \\(\\Delta{b}\\)만큼 계속 해서 그 값이 커지는데, \\(\\hat{x}\\) 값은 학습을 아무리 진행해도 특정 값으로 고정되기 때문입니다. \\(\\Delta{b}\\)는 \\(\\frac{\\partial l}{\\partial \\hat{x}}\\)에 비례하는데, 계산 그래프 상에서 \\(b\\)를 제외한 모든 값이 고정적이기 때문에 \\(\\Delta{b}\\)는 일정하게 계속 증가되어 결국 발산해버리는 것이죠. 저자는 초기 실험에서 이러한 상황을 경험적으로 확인하였으며, loss에 대한 gradient를 구할 때 normalization 과정도 함께 고려함으로써 문제를 해결했다고 합니다.간단한 레이어의 계산 그래프. \\(E(x)\\)의 \\(b\\)에 대한 의존성을 고려하지 않으면 학습 과정상에 문제가 발생하게 됩니다.이제는 사고를 한차원 확장하여 \\(x\\)를 vector로 생각하고 \\(X\\)를 이러한 vector들의 set으로 생각해봅시다. \\(x\\)는 \\(u\\)와 \\(b\\)를 곱한 값이라는 점을 주의해주세요. 이러한 셋팅에서 \\(\\hat{x}\\)를 구하는 과정을 다음과 같이 단순할 수 있습니다.\\[\\hat{x} = Norm(x, X)\\]\\(\\hat{x}\\)는 개별 example인 \\(x\\)뿐만 아니라 전체 데이터셋 \\(X\\)에도 의존한다는 것을 알 수 있습니다. 또한 역전파를 위해서는 다음과 같은 자코비안 행렬을 계산해야 합니다.\\[\\cfrac{\\partial \\text{Norm}(x, X)}{\\partial x} \\space \\text{and} \\space \\cfrac{\\text{Norm}(x, X)}{\\partial X}\\]위 식에서 두번째 term을 무시하게 되면 앞서 언급한 \\(b\\)의 발산 문제가 똑같이 발생하게 됩니다. 왜 두번째 term과 앞서 언급한 현상이 관련이 있다는 것일까요? 충분히 고민하다가 내린 개인적인 생각을 덧붙여보겠습니다. 전체 데이터셋이 2개인 상황을 가정해보면 normalization 계산 그래프는 아래의 figure처럼 표현 할 수 있습니다. \\(b\\)가 발산하는 문제는 \\(E(x)\\)쪽 경로의 gradient를 고려하지 않았을 때 발생한다는 점을 앞서 언급하였습니다. 그런데 \\(E(x)\\)를 구하는 과정에서 전체 데이터셋 \\(X\\)가 필요하게 됩니다. 데이터셋이 2개인 상황을 가정하였으므로 \\(X=\\{x_{1}, x_{2}\\}\\)라고 생각할 수 있겠네요. 결국 위 식에서 말하는 전체 데이터 셋에 대한 미분값은 \\(E(x)\\) 쪽 경로로 흘러가는 gradient라고 생각할 수 있습니다.다시 논점으로 돌아와서, 이러한 셋팅에서 normalization을 진행하기 위해서는 다음과 같은 공분산 행렬과 그것의 inverse square root에 대한 연산이 필요하며 해당 연산들에 대한 미분값 역시 필요하게 됩니다. normalization 과정에 엄청난 연산이 요구되는 것이죠.\\[\\text{Cov}[x] = E_{x \\in X}[xx^T] - E[x]E[x]^T \\space \\text{and} \\space \\text{Cov}[x]^{-1/2}(x-E[x])\\]따라서 저자는 1) 미분 가능하면서(gradient descent 과정에 포함시키기 위해) 2) 전체 트레이닝 셋을 고려하지 않는 normalization기법을 고안하게 됩니다. 바로 배치 정규화 기법이죠!3   Normalization via MIni-Batch Statistics앞서 언급했다시피 full whitening은 매우 계산량이 높고, 모든 곳에서 미분이 가능하지 않다는 단점이 있습니다. 따라서 저자는 각각의 feature들을 독립적으로 zero mean and unit variance로 만드는 방법을 제안합니다. 이러한 normalization 방식은 feature 간 decorrelated가 되지 않았을 때도 모델의 수렴 속도를 빠르게 만든다는 것이 기존 연구에서 입증되었습니다(LeCun et al., 1998).4   Experiments5   ConclusionReferencePapers Ioffe, S., &amp;amp; Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167. LeCun, Y. A., Bottou, L., Orr, G. B., &amp;amp; Müller, K. R. (2012). Efficient backprop. In Neural networks: Tricks of the trade (pp. 9-48). Springer, Berlin, Heidelberg. Articles 배치 정규화 논문 리뷰 (Batch normalization) - Slow walking manhttps://arxiv.org/abs/1404.5997) [Deep Learning] Batch Normalization 개념 정리 " }, { "title": "하버드 확률론 기초 강의(Statistics 110)을 완강하고 나서 느낀점, 앞으로의 계획", "url": "/posts/statistics_110/", "categories": "ETC, Retrospective", "tags": "retrospective, statistics110", "date": "2020-11-01 16:20:00 +0900", "snippet": "하버드 기초 통계학 강의(Statistics 110)를 오늘에서야 완강하였습니다 😄. 분명히 통계학 기초 강의인데… 제 수준에서는 결코 기초가 아니었습니다. 한번에 이해가 안되는 강의가 거의 80% 정도였던 것 같고, 강의 전반에 대한 이해는 50%도 되지 않는 것 같습니다. 그럼에도 불구하고 간단한 회고의 글을 쓰는 것은 그만큼 저에게는 어려웠고, 담대한 도전이었기 때문입니다. 개인적으로는 완강까지 왔다는 것에 굉장한 뿌듯함을 느끼고 있습니다. 강의 자체가 쉬운 내용으로만 구성되어 있진 않아서 완강까지 대략 3~4개월 정도 소요된 것 같습니다.이렇게까지 오래 걸린 이유는 제가 많이 부족해서이겠죠. 강의당 재생시간은 대부분 50분 이내 정도인데, 수박 겉핥기 식으로 빨리 완강하는 것보다는 천천히 이해하며 가보자는 태도로 강의 하나를 듣는데 거의 2시간 반 이상씩 걸렸습니다. 그리고 강의를 원할하게 이해하기 위해서 어느정도 기초 수학 지식이 필요했습니다. Joe Blitzstein 교수님이 직접적으로 언급하시진 않지만, 완강한 시점에서 제가 느끼는 선수 지식은 아래와 같습니다. 기초 미적분학 지식 편미분, 부분적분, 치환적분 여러 이산형, 연속형 분포를 유도하기 위해 필요 극좌표 및 삼각함수 정규분포 유도를 이해하기 위해 필요 테일러 시리즈 적률생성함수 부분을 이해하기 위해 필요 이 수업을 들어야 하겠다고 다짐한 것은 두가지 이유가 있었습니다. 먼저 ML 논문에 등장하는 통계학적 개념들과 수식에 대한 이해력이 부족하다보니, 배보다 배꼽이 더 큰 상황이 많이 발생했습니다(논문을 이해해야하는데 관련 수학적 개념을 찾아보는데 드는 시간이 더 많이 소요…) 그리고 결정적으로 LDA를 수학적으로 이해해보고 싶다는 생각이 시발점이었습니다. LDA는 결국 베이지안 통계학을 이해하여야 완벽하게 이해할 수 있는데, 관련 논문과 자료를 보면서 저의 통계학적 지식이 매우 파편적이라는 것을 느끼게 되었습니다.결국 통계/수리적 지식이 커리어를 발전 시켜나가는데 발목을 잡을 것 같다는 생각이 들어서 기초 내용을 다루는 정규 커리큘럼으로 공부해보자고 마음을 먹게 되었습니다. 그래서 여러가지 통계학 강의를 검색해본 결과 하버드 기초 확률론 강의가 처음 시작하기에 적절하다고 판단하였습니다. 이제 시작이니 마지막 강의에서 교수님이 뽑아주신 10개의 개념을 확실히 복습하고 다시 정진 해보려고 합니다. Randomness and Uncertainty 조건부(conditioning) 조건부 확률 조건부 기대값 베이즈 정리 대칭성(symmetry) 확률변수와 확률분포(randon variabels and their distributions) 이야기(stories) stories of proof stories of distribution Computing Expectation 선형성(linearity) 지시확률변수(indicator random variables) 무의식적 통계학자의 법칙(LOTUS) Long-run behaviors 큰수의 법칙(LLN, Law of Large Number) 중심극한정리(CLT, Central Limit Theorem) 마르코프 연쇄(Markov Chain) 최종 공부 목표주변 동료들과 Joe Blitzstein 교수님의 조언에 따라 저의 최종 공부 목표는 계량경제학으로 잡았습니다. 제는 이커머스 업계에 종사하고 있는데요, 고객의 interaction 데이터를 통해 통찰력을 얻는 것이 제 커리어에서 중요한 포인트라고 생각합니다. 이를 위해서는 현실의 데이터를 활용한 선형 모델 분석 기법을 통달하는 것이 가장 중요하다고 판단했습니다. 마지막으로 명강의를 해주신 Joe Blitzstein교수님과 자막과 함께 영상을 제공해주신 edwith 관계자 여려분께도 감사드립니다. 배운 내용을 바탕으로 계량경제학까지 쭉쭉 달려나가보겠습니다 👊.힘들었던 Statistics 110 수업도 결국은 완강👏" }, { "title": "Deep Learning is Robust to Massive Label Noise", "url": "/posts/deep_learning_is_robust_to_massive_label_noise/", "categories": "ML, Paper Review", "tags": "ml, dl, paper, review", "date": "2020-10-20 10:00:00 +0900", "snippet": "현업의 데이터를 다루다보면 데이터에 noisy label이 많이 발생합니다. 가장 좋은 점은 일일이 수작업으로 data cleaning을 하는 것이 좋겠지만, 데이터의 양이 늘어남에 따라 라벨링을 교정하는 것 자체가 일이 되는 경우가 발생하게 됩니다. 이와 관련된 고민을 하던 중 noisy label이 모델에 끼치는 영향력을 분석한 논문을 발견하여 읽고 리뷰해보도록 하겠습니다. 먼저 이 논문의 결론을 정리하자면 다음과 같습니다. 충분히 큰 클린 데이터셋이 구축되어 있으면, 노이즈 데이터로 인한 악영향을 극복할 수 있습니다. noisy data가 증가함에 따라 필요한 clean data의 개수는 선형적으로 증가하는 경향이 있습니다. 배치 사이즈를 크게 하거나 학습률을 작게 하면 노이즈 데이터로 인한 performance 손실을 완화할 수 있습니다. 비록 딥뉴널넷은 noisy 데이터에 robust한 면을 보이지만, 같은 양의 학습 데이터안에서 clean data의 비중이 높을 수록 performance가 좋습니다.1   Learning with massive label noise본 논문에서는 클린 데이터의 크기는 고정한 상태에서 noisy 데이터의 크기를 점차 늘려감에 따라 multi-class classification task의 성능을 평가하는 방법을 통해 noisy data로 인한 결과를 보고자 하였습니다. clean data의 크기를 \\(n\\), 클린 데이터 당 noisy 데이터의 개수를 \\(\\alpha\\)라고 하였습니다. 따라서 최종적인 데이터 셋의 크기는 \\(n+\\alpha n\\)가 됩니다. 본 논문에서는 \\(\\alpha\\)의 크기를 변화시켜감에 따라 performance가 어떻게 변화하는지를 체크합니다. 특히 label noise를 아래의 3가지 유형으로 분류하여 실험을 진행했다는 점이 흥미롭네요. uniform label-swapping structured label-swapping out-of-vocabulary examples1.1   Training with uniform label noise첫번재 실험은 noisy label data가 correct label data가 보다 많은 일반적인 상황을 보여줍니다. 이때 생성되는 noisy data에 붙일 label은 uniform distribution에서 뽑습니다. 다시 말해 모든 label이 같은 확률로 추출될 수 있다는 것입니다. 예를 들어 \\(n=5\\)이고 \\(\\alpha = 10\\)이면 noisy data를 총 50개를 생성해야하는데, 그 50개 data에 대한 uncorrect label은 어떤 label이든 동일한 확률 설정된다는 것입니다. 아래의 figure를 보고 결과를 봅시다. 다음의 경향이 있음을 할 수 있습니다. noisy data per clean label의 개수가 증가함에 따라 test performance가 감소하는 경향이 있습니다. network architecture가 클수록 label noise에 robust한 경향이 있습니다. noise tolerance가 필요한 분야일 수록 ConvNets이나 RestNets 등의 깊은 구조가 필요합니다. 1.2   Training with structured label noise뉴럴넷은 uniform label noise에 robust 하다는 것을 보였습니다. 그러나 일반적인 실무 환경에서 수집된 데이터의 경우, 노이즈 데이터의 확률 분포가 uniform distribution을 따르는 비현실적입니다. 따라서 두번째 실험에서는 현업에서의 현실성을 좀 더 반영하기 위해 noisy label의 분포를 특정한 noisy label structure를 통해 실험을 진행하였습니다. 특히 3가지의 noisy label structure를 실험하였습니다.먼저 correct label을 뽑을 확률 \\(\\varepsilon=1/(1+\\alpha)\\)를 정의하고, noisy label의 structure를 유도하기 위해, noisy label 중 특정 클래스가 뽑일 확률에 bias를 주는 방법을 취했습니다. 이를 위해 \\(\\delta\\)라는 파라미터를 간단하게 도입하였는데요. \\(\\delta\\)는 noisy label의 structure의 정도를 표현합니다. 저자는 이를(\\(\\delta\\))를 샘플링 될 가능성이 두번째로 높은 클래스의 가능성의 정도가 우연을 넘어설 정도(over chance)라고 정의합니다. 직역 하면 말이 어려운데, 여기서 말하는 ‘우연’은 uniform structure를 뜻합니다. uniform structure는 모든 라벨이 샘플링될 확률이 동일합니다. 바꿔 말하면, 모든 라벨이 샘플링될 확률이 우연(랜덤)하다는 것이죠. 말로 풀어쓰는 것보다 figure로 보는 것이 더 이해하기 쉬우실 것 같습니다. 아래의 figure를 보시면 왼쪽은 uniform noise일때의 label의 strurcture(혹은 distribution이라고 표현해도 될 것 같습니다)이고 오른쪽은 structured noise에 대한 예시입니다. \\(\\delta\\varepsilon\\)라고 적힌 부분을 보시면 두번째로 가능성이 높은 클래스가 뽑힐 확률이 uniform noise(우연히) 대비 얼마나 높아졌느냐를 뜻한다는 것을 알 수 있습니다. 따라서 \\(\\delta=0\\)이면 uniform noise와 완전히 동일하게 되고, \\(\\delta=1\\)이면 두번째로 샘플링 될 확률이 높은 클래스의 가능성이 correct label의 확률과 동일하게 됩니다. 따라서 \\(\\delta\\)를 0과 1사이의 값으로 조절하면 noise의 structure를 자유롭게 조절 할 수 있습니다. 참고로 다른 label의 likelihood는 linear하게 scale 한다고 언급되어 있습니다.저자는 noise label을 3가지 유형으로 구분하여 실험을 진행하였습니다. labels biased towards hardly confused classes(Confusing order): correct label과 비교해서 헷갈리기 쉬운(confused) 라벨순으로 많이 뽑음 labels biased towards easily confused classes(Reverse confusion order): correct label과 비교해서 헷갈리기 쉬운(confused) 라벨의 역순으로 많이 뽑음 labels biased towards random classes(Random order): noise structure를 random으로 구성그 결과는 아래와 같이 요약할 수 있습니다. 3가지 유형의 noise structure 간에 결과의 큰 차이가 없었습니다. \\(\\delta\\)가 커질수록 모델의 정확도가 감소하는 경향이 있습니다. 이 결과는 현실적인 noisy dataset에서도 deep neural net이 좋은 결과를 보여주는 이유에 대해 설명해줄 수 있습니다.1.3   Source of noisy labels1.1~1.2의 실험들은 같은 dataset에서 뽑은 데이터에 false label을 할당하여 진행한 실험들이었습니다. 그러나 natural scenario에서는 noisy example들이 다른 data source에서 발생된 경우가 많습니다. 따라서 저자는 다른 data source에서 발생된 noisy example에 대한 실험도 필요하다고 언급합니다. 따라서 CIFAR10 데이터셋을 기준으로 두가지 실험을 진행하였습니다. Examples from similar but different dataset: CIFAR-10 데이터셋의 라벨을 기준으로 CIFAR-100 데이터에 noise label을 할당한 데이터를 사용 Examples from simply white nosie: CIFAR-10 이미지 데이터 픽셀의 평균과 분산을 이용하여 random noise 생성하여 CIFAR-10 데이터의 라벨을 랜덤으로 할당결과를 요약하면 다음과 같습니다. white noise example의 prediction accuracy가 가장 높습니다. 이는 neural net이 random noise에 fitting 할 수 있다는 기존의 연구 결과와 일치합니다(Zhang et al., 2017) 비슷(관련)하지만 다른 데이터셋에서 추출한 데이터가 같은 데이터셋에서 추출한 데이터보다 prediction accuracy가 높습니다.논문에서는 결과를 위와 같이 언급하였는데, white noise example이 다른 noise example에 비해서 정확도가 높게 나온 것은 직관적으로 조금 이해하기 힘든 부분입니다. 저자는 해당 실험의 결과를 다음과 같이 해석합니다. 대부분의 noisy data는 CIFAR-10과 CIFAR-100 사이의 데이터(어느 정도 관련은 있지만, 데이터가 이곳저곳에 수집되었기 때문에 source가 다른)입니다. noisy data 중 일부는 관련도가 깊은 데이터이지만 mislabeld 되어서 학습에 부정적인 영향을 주겠지만, 대부분의 noisy data는 관련도가 현저히 떨어지기 때문에 학습에 부정적인 영향을 주지 못했기 때문입니다.이 실험 결과에 제 생각을 덧붙여 보면, examples from similar but different dataset에 대한 실험은 noisy data를 만드는 과정에서 label을 랜덤하게 할당하기 때문에 큰 틀에서 보면 white noise 데이터로 실험한 것에 포함될 수 있다고 볼 수 있습니다. 그러나 examples from similar but different dataset는 원래의 데이터와 어느정도 관련성이 있는 반면에, white noise 데이터는 실제 데이터와 관련도가 상대적으로 매우 적기 때문에 학습 과정에 부정적인 영향을 주는 정도 훨씬 적을 것으로 생각해볼 수 있습니다. 따라서 오히려 white noise dataset의 prediction accuracy가 더 높게 나온 것 같습니다.2   The importance of larger datasets사실 이 부분이 논문에서 핵심적으로 주장하고 싶은 내용을 담은 부분이라고 볼 수 있습니다. 딥러닝에 큰 데이터셋이 필요하다는 것은 널리 알려진 사실입니다(Deng et al., 2009; Sun et al., 2017). 저자는 noisy example이 많은 데이터셋에서는 데이터셋의 크기가 어떤 영향을 미치는지를 알아보고자 하였습니다. 결과적으로 말씀드리면 저자는 다음의 내용을 주장합니다. 데이터셋 내에 noisy label data의 비중이 클수록 같은 accuracy에 도달하기 위해 필요한 clean data의 개수가 증가하는 경향이 있습니다. 데이터셋 내에 noisy label data의 비중에 따라 accuracy를 급격하게 증가시키는 threshold dataset의 크기가 다릅니다.아래의 왼쪽 figure를 보면, noisy label:clean label의 비중이 50:1일 때가 20:1일 때보다 accuracy 90%를 달성하기 위해 필요한 clean label의 개수가 많음을 알 수 있습니다. 아래의 오른쪽 figure도 역시 일맥상통한 결과를 주장하고 있습니다.3   The importance of batch size and learning rate지금까지는 뉴럴넷 학습시 필요한 하이퍼파라미터를 일정한 값으로 고정시켜 실험을 진행하였습니다. 그러나 저자는 배치사이즈와 학습률이 gradient update의 stochasticity를 줄여주는 중요한 요소로 보고, 두 하이퍼파라미터 값의 변화에 따른 accuracy 스코어를 관찰하였습니다. 그 결과 다음의 결론을 주장합니다. 배치 사이즈가 커질수록 noisy data에 강건해지는 경향이 있습니다. 학습률이 작아질수록 noisy data에 강건해지는 경향이 있습니다.먼저 아래의 왼쪽 figure를 보시면 배치 사이즈에 대해 주장하는 바가 명확합니다. clean label 당 noisy label의 개수가 50일때를 보면 배치 사이즈가 커질 수록 noisy label에 더욱 강건한 모델이 구축됨을 알 수 있습니다. 참고로 \\(H_\\alpha\\)는 배치 사이즈를 무한대로 보았을 때의 결과입니다. 실제 실험을 할 때는 배치 사이즈를 무한대로 하는 것은 불가능한데요. 저자는 손실 함수 부분을 수정하여 이론적으로 배차 사이즈가 무한일 때를 환경을 구축하여 실험을 하였습니다. 해당 부분에 대해서 자세히 알고 싶으신 분들은 논문을 참고해 주시길 바랍니다. 저자는 미니 배치 학습시 배치 단위의 loss는 평균을 내어 도출되는데요, 저자는 이와 같은 로직에 의해서 noisy label에 대한 잘못된 loss는 cancel out 되며, correct label의 gradient에 대한 기여도가 더 많이 반영된다고 해석합니다. 다시말해, ‘평균’이라는 로직에 때문에, 배치 사이즈가 증가할 수록 평균 gradient는 correct label의 gradient에 점점 가까워 짐을 뜻합니다.아래의 오른쪽 figure는 학습률과 정확도의 관계를 보여줍니다. 일반적으로 뉴럴넷 학습시 배치 사이즈를 증가시키면 학습률도 같이 scale up 하게 됩니다. 특히 배치사이즈가 작아질수록 optimal 학습률도 역시 작아지는 경향이 있다는 연구 결과도 있습니다 [3]. 저자는 실험을 통해서 noisy label의 개수의 증가는 effective 배치 사이즈를 감소시키는 결과를 초래함을 관찰하였습니다. 따라서 noisy data가 증가하면 effective 배치 사이즈가 작아지므로 optimal 학습률도 작아져야 하므로 이러한 결과한 발생하였다고 주장합니다. 개인적으로 근거가 부족하지 않나라는 생각을 해봅니다. 특히 아래의 오른쪽 figure를 보면 가장 작은 학습률 값은 0.01인데, 0.01의 prediction accuracy가 가장 낮습니다. 따라서 데이터셋을 달리하거나 실험 환경을 조금만 수정해도 아예 다른 결과가 도출되지 않을까라는 생각이 듭니다.4   덧 붙이는 말실무에서 다루는 데이터는 대부분 noisy가 포함되게 됩니다. 특히 최근에 업무를 수행하면서 noisy data 처리 문제에 대해 많은 고민을 하게 되었는데요, 역시 가장 확실한 방법은 noisy data를 clean data로 만드는 것입니다. 가장 강력하지만 가장 많은 비용을 수반하죠. 다시말해 현실적으로 불가능한 경우가 많다라는 것입니다. 그렇다면 noisy data를 어느 정도 감안하고 학습해도 될까요? 본 논문에 이에 대한 답을 간접적으로 나마 제안합니다. noisy data의 특성과 크기에 따라, 또 달성하고자 하는 accuracy에 따라 clean label을 생성하는데 수반되는 성능과 비용을 trade-off 관계를 잘 고려하여 의사결정을 해라는 것이 이 논문에서 핵심적으로 주장하려는 바인 것 같습니다. 그러나 해당 논문의 결과는 데이터셋에 따라 크게 달라질 수 있기 때문에 참고용 정도로만 활용해야할 것 같습니다.Reference[1] Rolnick, D., Veit, A., Belongie, S., &amp;amp; Shavit, N. (2017). Deep learning is robust to massive label noise. arXiv preprint arXiv:1705.10694.[2] Deep Learning is Robust to Massive Label Noise - Paper Review[3] Krizhevsky, A. (2014). One weird trick for parallelizing convolutional neural networks. arXiv preprint arXiv:1404.5997." }, { "title": "Attention Is All You Need", "url": "/posts/attention_is_all_you_need/", "categories": "ML, Paper Review", "tags": "nlp, paper review", "date": "2020-10-16 00:00:00 +0900", "snippet": " “Attention Is All You Need” 논문을 읽은 후 관련 자료를 정리한 내용을 바탕으로 논문 리뷰를 진행 해보겠습니다. 서론 및 문헌연구는 제외하겠습니다.1     Model Architecturetransformer에서 가장 중요한 block은 self-attention과 point-wise feed forward network sub-layer입니다. 인코더와 디코더 셀 하나는 self-attention 및 point-wise feed forward network 2개로 구성되어 있습니다. 각 sub-layer는 residual connection와 layer batch normalization으로 연결되어 있습니다.1.1     Encoder and Decoder StacksTransformer imitates the classical attention mechanism (known e.g. from Bahdanau et al., 2014 or Conv2S2) where in encoder-decoder attention layers queries are form previous decoder layer, and the (memory) keys and values are from output of the encoder. Therefore, each position in decoder can attend over all positions in the input sequence. Decoder acts similarly generating one word at a time in a left-to-right-pattern. It attends to previously generated words of decoder and final representation of encoder.1.2   Positional Encodingtransformer는 sequence token의 sequence 정보를 알 수 없으므로, 순서 정보를 주입(inject) 시켜주어야 합니다.1.3   Scaled Dot-Product Attention\\[\\begin{aligned}Attention(Q, K, V) = softmax\\Bigg(\\cfrac{QK^{T}}{\\sqrt{d_{k}}}\\Bigg)V\\end{aligned}\\]왜 \\(\\sqrt{d_{k}}\\)로 나누어 줄까요? \\(d_{k}\\)가 커짐에 따라 dot-product가 너무 커져버리는 효과를 상쇄하기 위함입니다. 예를 들어 아래의 두 벡터를 비교해봅시다.\\[\\begin{aligned}\\vec{a}&amp;amp;=[2, 2], \\space where \\space d_{k}=2 \\\\\\vec{b}&amp;amp;=[2, 2, 2, 2, 2], \\space where \\space d_{k}=5 \\\\\\end{aligned}\\]\\[\\begin{aligned}\\vec{a} \\cdot \\vec{a} &amp;amp;= 8\\\\\\vec{b} \\cdot \\vec{b} &amp;amp;= 20, \\end{aligned}\\]\\(d_k\\), 즉 임베딩 차원이 길 수록, dot-product 값은 커지는 필연적인 결과가 나타납니다. dot-product 값이 커지면 어떤 문제가 생길까요? 결론적으로 말하면 특정 노드의 softmax값이 1에 수렴하게 되어 gradient가 매우 작아지므로 초기 학습시에 문제가 발생할 여지가 있습니다. 저자는 논문에 이렇게 표현하고 있습니다. We suspect that for large values of \\(d_{k}\\), the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients . To counteract this effect, we scale the dot products by \\(\\cfrac{1}{\\sqrt{d_{k}}}\\)간단하게 코드로 알아봅시다. \\(0.3\\)과 \\(0.4\\) 두 개의 원소를 가지고 있는 \\(d_{k}=2\\)인 \\(\\vec{v_{1}}\\)를 만들고 softmax 함수의 값을 구해봅시다.[In]:v1 = np.array([0.3, 0.4])print(np.exp(v1)/np.sum(np.exp(v1)))[Out]: array([0.47502081 0.52497919])이제 \\(\\vec{v_{1}}\\)의 각 원소에 100을 곱한 \\(\\vec{v_{2}}\\)에 역시 softmax 함수를 통과한 값을 구해봅시다. \\(\\vec{v_{1}}\\)과 \\(\\vec{v_{2}}\\)는 절대적 크기는 달라졌지만, 상대적 크기는 달라지지 않았다는 점을 유념해 주시기 바랍니다.[In]:v2 = v1 * 100print(np.exp(v2) / np.sum(np.exp(v2)))[Out]:array([4.53978687e-05 9.99954602e-01])결과를 보면, 원소의 magnitude가 큰 벡터에 softmax를 씌웠을 때는 1에 수렴하는 값이 발생함을 할 수 있습니다. 따라서 초기에 학습이 잘 이루어지기 위해서는 gentle한 softmax 값을 얻어낼 필요가 있다는 것을 알 수 있습니다. 큰 softmax 값에 대해서는 graident가 매우 작아 역전파시 전달되는 값이 거의 0에 가깝기 때문입니다.왜 softmax 값이 크면 전달되는 gradient가 작아질까요?(small gradient problem) 먼저 notation을 정의합시다.\\[\\begin{aligned}z_j &amp;amp;= element_{j}\\text{ of output vector}\\\\y_i &amp;amp;= \\cfrac {e^{z_i}} {\\sum_{k}e^{z_i}}\\end{aligned}\\]softmax 함수에 대한 미분을 구하면 아래와 같습니다(자세한 계산 과정은 Appendix를 참조해 주세요).\\[\\cfrac {\\partial {y_{i}}} {\\partial {z_{j}}} = \\begin{cases} y_{i}(1-y_{i}) &amp;amp;\\text{if } i=j \\\\ -y_{i}y_{j} &amp;amp;\\text{if } i\\not=j\\end{cases}\\]만약 \\(i=j\\)이고, \\(y_i\\)의 값이 1에 가깝다면, gradient는 0에 가까운 값이 전달 됩니다. 한편 \\(i \\not = j\\)이고 \\(y_i\\)의 값이 1에 가깝다면, \\(y_j\\)는 0에 가까운 값이므로 역시 gradient 값이 매우 작아질 것입니다. 이러한 현상이 학습 말미에 벌어진다면 학습이 잘 되었다는 증거로 생각할 수 있겠으나, 학습 초기부터 small gradient 문제가 발생한다면 학습이 정상적으로 이루어지지 않을 것이라는 것을 미루어 짐작할 수 있습니다. 따라서 학습 초기에는 gentle softmax를 만드는 것이 중요하므로 \\(\\sqrt d_k\\)로 나누어 주는 것입니다.1.4     Multi-Head AttentionThe encoder self-attention distribution for the word “it” from the 5th to the 6th layer of a Transformer trained on English to French translation (one of eight attention heads).1.5   Position-wise Feed-Forward Networksself-attention layer를 통과한 결과에 feed-forward network를 붙여주는 구간입니다. 이는 네트워크에 비선형성을 전달하기 위한 과정이라고 보시면되겠습니다. self-attention layer에는 비선형성을 만들만한 연산이 포함되어 있지 않습니다.1.6   Encoder-Decoder Attentionmask-attention layer가 필요한 부분입니다.2   Appendix2.1   Derivative of softmax\\[\\begin{aligned}\\text{If } i=j, \\\\\\cfrac{\\partial y_{i}}{\\partial z_{i}}&amp;amp;= \\cfrac{\\partial}{\\partial z_{i}} \\bigg(\\cfrac{e^{z_{i}}}{\\sum_{k}e^{z_{k}}}\\bigg) \\\\&amp;amp;= \\cfrac {e^{z_{i}}\\sum_{k}e^{z_{k}}-e^{z_{i}}e^{z_{i}}}{(\\sum_{k}e^{z_{k}})^{2}} \\\\&amp;amp;= \\cfrac {e^{z_{i}}(\\sum_{k}e^{z_{k}}-e^{z_{k}})} {(\\sum_{k}e^{z_{k}})^{2}} \\\\&amp;amp;= \\cfrac {e^{z_{i}}} {\\sum_{k}e^{z_{k}}} * \\cfrac {\\sum_{k}e^{z_{k}}-e^{z_{i}}} {\\sum_{k}e^{z_{k}}} \\\\&amp;amp;= \\cfrac {e^{z_{k}}} {\\sum_{k}e^{z_{k}}}(1-\\cfrac {e^{z_{k}}} {\\sum_{k}e^{z_{k}}}) \\\\&amp;amp;= y_{i}(1-y_{i})\\end{aligned}\\]\\[\\begin{aligned}\\text{If } i \\not= j, \\\\\\cfrac{\\partial y_{i}}{\\partial z_{j}}&amp;amp;= \\cfrac{\\partial}{\\partial z_{i}} \\bigg(\\cfrac{e^{z_{j}}}{\\sum_{k}e^{z_{k}}}\\bigg) \\\\&amp;amp;= \\cfrac {0*\\sum_{k}e^{z_{k}}-e^{z_{i}}e^{z_{j}}}{(\\sum_{k}e^{z_{k}})^{2}} \\\\&amp;amp;= - \\cfrac {e^{z_i}}{\\sum_k e^{z_{k}}} * \\cfrac {e^{z_j}}{\\sum_k e^{z_{k}}} \\\\&amp;amp;= -y_i y_j\\end{aligned}\\]3   참고자료 Softmax-with-Loss 계층 The Transformer: Attention Is All You Need Transformer model for language understanding-tensorflow Google AI Blog - Transformer: A Novel Neural Network Architecture for Language Understanding 딥러닝을 통한 자연어처리 입문: 시퀀스-투-시퀀스(Sequence-to-Sequence, seq2seq) A PyTorch implementation of the Transformer model in “Attention is All You Need”. BERT 톺아보기" }, { "title": "에라토스테네스의 체", "url": "/posts/Sieve_of_Eratosthenes/", "categories": "Algorithms, Theory", "tags": "algorithms", "date": "2020-09-19 00:00:00 +0900", "snippet": "1   에라토스테네스의 체란?고대 그리스 수학자 에라토스테네스가 고안한 N까지의 수열에서 소수만을 골라내는 알고리즘입니다. 소수를 대량으로 빠르게 판별할 수 있는 장점이 있습니다.2   알고리즘 구현 원리 Step1. 먼저 판별하고 싶은 범위의 수열을 초기화 합니다. 예시로 2부터 120까지의 자연수(\\(N=120\\)) 중 소수를 판별하는 과정을 들어보도록 하겠습니다.\\[arr = [2, 3, 4, 5, ..., 120]\\] Step2. 배열의 첫번째 원소인 2를 제외한 2의 배수를 모두 제거합니다 Step3. 배열의 다음 원소인 3을 제외한 3의 배수를 모두 제거합니다. Step4. 배열의 다음 원소인 4는 2의 배수를 제거하는 과정에서 이미 제거 되었으므로 넘어갑니다. Stpe5. 배열의 다음 원소인 5를 제외한 5의 배수를 모두 제거합니다. Step6. 이와 같은 과정을 \\(sqrt{(N)} = \\sqrt{120}\\) 이하인 자연수까지만 반복하고 배열에 남아 있는 원소를 출력합니다.3   파이썬 구현import numpy as npn = 10000 # 10000까지의 자연수 중 소수를 골라내 보자mask = [True for _ in range(2, n+1)] # 2부터 n까지의 자연수 배열_n = int(np.sqrt(len(mask))) # _n까지만 배수 삭제 작업을 진행for i in range(_n): # True는 삭제 되지 않은 숫자 if mask[i]: # 자기 자신을 제외한 배수들의 mask를 False로 바꾸기 for j in range(i+(i+2), len(mask), i+2): mask[j] = Falseprint([prime+2 for prime, b in enumerate(mask) if b])Reference 에라토스테네스의 체-위키피디아 에라토스테네스의 체-나무위키" }, { "title": "미분 공식 증명", "url": "/posts/proof_of_derivative/", "categories": "Math, Calculus", "tags": "derivative", "date": "2020-09-06 00:00:00 +0900", "snippet": " 미분 공식을 이해하고 내면화하기 위해 대표적인 미분 공식 증명을 정리해 보겠습니다.1   \\(f(x)=x^{n}\\)일때, \\(f&#39;(x)=nx^{n-1}\\)\\[\\begin{aligned}f&#39;(x) &amp;amp;= \\lim_{h \\to 0} \\cfrac {f(x+h) - f(x)} {h} \\\\&amp;amp;= \\lim_{h \\to 0} \\cfrac {(x+h)^n - x^n} {h} \\\\&amp;amp;= \\lim_{h \\to 0} \\cfrac {(x+h-x)((x+h)^{n-1}x^{0} + (x+h)^{n-2}x^{1} + ... + (x+h)^{0}x^{n-1})} {h} \\\\&amp;amp;= \\lim_{h \\to 0} {((x+h)^{n-1}x^{0} + (x+h)^{n-2}x^{1} + ... + (x+h)^{0}x^{n-1})} \\\\&amp;amp;= x^{n-1}x^{0} + x^{n-2}x^{1} + ...+ x^{0}x^{n-1} \\\\&amp;amp;= x^{n-1} + x^{n-1} + ... +x^{n-1} \\\\&amp;amp;= nx^{n-1}\\end{aligned}\\]참고) \\(a^n - b^n = (a-b)(a^{n-1}b^{0} + a^{n-2}b^{1} + ... + a^{0}b^{n-1})\\)2   자연상수 \\(e\\)의 정의\\(e=\\lim_{n \\to\\infty}\\bigg(1+\\cfrac{1}{n}\\bigg)^n=\\lim_{x\\to0}\\big(1+x\\big)^{1/n}\\)참고) 마지막항은 \\(x = \\cfrac{1}{n}\\)을 이용한 것3   \\(\\lim_{x\\to0}\\cfrac{e^x-1}{x}=1\\)\\[\\begin{aligned}\\lim_{x\\to0}\\cfrac{e^x-1}{x}&amp;amp;= \\lim_{t\\to0}\\cfrac{t}{ln(1+t)} \\Leftarrow e^x-1=t \\\\&amp;amp;= \\lim_{t\\to0}\\cfrac{1}{\\cfrac{ln(1+t)}{t}} \\\\&amp;amp;= \\lim_{t\\to0}\\cfrac{1}{\\frac{1}{t} ln(1+t)} \\\\&amp;amp;= \\lim_{t\\to0}\\cfrac{1}{ln(1+t)^{\\frac{1}{t}}} \\\\&amp;amp;= \\cfrac{1}{ln(\\lim_{t\\to0}(1+t)^{\\frac{1}{t}})} \\\\&amp;amp;= \\cfrac{1}{lne} \\Leftarrow \\lim_{x\\to0}\\big(1+x\\big)^{1/n} \\\\&amp;amp;= 1\\end{aligned}\\]4   지수함수 \\(f(x) =e^x\\)일 때, \\(f&#39;(x)=e^x\\)\\[\\begin{aligned}f&#39;(x) &amp;amp;= \\lim_{h \\to 0} \\cfrac {f(x+h) - f(x)} {h} \\\\&amp;amp;= \\lim_{h \\to 0} \\cfrac {e^{x+h} - e^{x}} {h} \\\\&amp;amp;= \\lim_{h \\to 0} \\cfrac {e^{x}(e^{h}-1)} {h} \\\\&amp;amp;= e^{x} \\lim_{h \\to 0} \\cfrac {e^{h}-1} {h} \\\\&amp;amp;= e^{x} \\Leftarrow \\lim_{x\\to0} \\cfrac{e^x-1}{x}=1 \\\\\\end{aligned}\\]4   지수함수 \\(f(x) =a^x\\)일 때, \\(f&#39;(x)=e^{xlna}\\cdot lna\\)다음 수식을 먼저 정의 하겠습니다.\\[\\begin{aligned}a^x &amp;amp;= a^{log_{e}e^{x}} \\\\&amp;amp;= (e^{x})^{log_{e}a} \\Leftarrow a^{log_{c}b} = b^{log_{c}a} \\\\&amp;amp;= e^{xlog_{e}a} \\\\&amp;amp;= e^{xlna} \\\\\\end{aligned}\\]위의 수식을 이용하여 증명을 해보겠습니다.\\[\\begin{aligned}f&#39;(x) &amp;amp;= \\cfrac {da^x} {dx} \\\\&amp;amp;= \\cfrac {d} {dx} e^{xlna} \\\\&amp;amp;= \\cfrac {d} {dx} e^t \\Leftarrow t=xlna \\\\&amp;amp;= \\cfrac {de^t} {dt} \\cfrac {dt} {dx} \\\\&amp;amp;= e^t \\cfrac {dt} {dx} \\\\&amp;amp;= e^t \\cdot lna \\\\&amp;amp;= e^{xlna} \\cdot lna \\\\\\end{aligned}\\]5   로그함수 \\(f(x) =lnx\\) 일 때, \\(f&#39;(x)=\\cfrac{1}{x}\\)\\[\\begin{aligned}f&#39;(x) &amp;amp;= \\lim_{h \\to 0} \\cfrac {f(x+h) - f(x)} {h} \\\\&amp;amp;= \\lim_{h \\to 0} \\cfrac {ln(x+h) - lnx} {h} \\\\&amp;amp;= \\lim_{h \\to 0} \\cfrac {1} {h} \\cdot {ln \\cfrac {x+h} {x}} \\\\&amp;amp;= \\lim_{h \\to 0} ln\\bigg(\\cfrac{x+h}{x}\\bigg)^{\\frac{1}{h}} \\\\&amp;amp;= \\lim_{h \\to 0} ln\\bigg(\\cfrac{x+h}{x}\\bigg)^{\\frac{x}{h} \\cdot \\frac{1}{x}} \\\\&amp;amp;= \\lim_{h \\to 0} \\cfrac{1}{x} \\cdot ln \\bigg(\\cfrac{x+h}{x}\\bigg)^{\\frac{x}{h}} \\\\&amp;amp;= \\lim_{h \\to 0} \\cfrac{1}{x} \\cdot ln \\bigg(1+\\cfrac{h}{x}\\bigg)^{\\frac{x}{h}} \\\\&amp;amp;= \\cfrac{1}{x} \\cdot ln \\lim_{h \\to 0} \\bigg(1+\\cfrac{h}{x}\\bigg)^{\\frac{x}{h}} \\\\&amp;amp;= \\cfrac{1}{x} \\cdot ln \\lim_{h \\to 0} \\bigg(1+\\cfrac{h}{x}\\bigg)^{\\frac{x}{h}} \\\\&amp;amp;= \\cfrac{1}{x} \\cdot lne \\Leftarrow e=\\lim_{x\\to0}(1+x)^{1/x} \\\\&amp;amp;= \\cfrac {1} {x} \\end{aligned}\\]" }, { "title": "Enriching Word Vectors with Subword Information", "url": "/posts/fasttext/", "categories": "ML, Paper Review", "tags": "nlp, fasttext, paper, review", "date": "2020-08-16 00:00:00 +0900", "snippet": " Fasttext 논문(Enriching Word Vectors with Subword Information)을 리뷰해 보았습니다. 슬라이드쉐어에 동일한 내용을 업로드 하였으며, 슬라이드쉐어에서 보시려면 이곳을 확인해 주세요.1   Introduction2   General Model3   Subword Model참고자료 Enriching Word Vectors with Subword Information Distributed Representations of Words and Phrases and their Compositionality" }, { "title": "Bias Variance Decomposition", "url": "/posts/bias_variance_decomposition/", "categories": "Math, Statistics", "tags": "bias, variance, decomposition", "date": "2020-07-28 00:00:00 +0900", "snippet": " 머신러닝의 학습의 판단 기준이 되는 error를 bias, variance, irreducible error의 관점에서 분해해보고 좋은 품질의 데이터가 필요한 이유와 bias 및 variance의 trade-off가 발생할 수밖에 없는 이유를 알아보겠습니다.1   Prerequsite to start with 통계학에서의 추정은 모집단을 설명하는 알 수 없는 미지의 모수를 추정하고자 하는 것입니다. 그러나 우리는 모집단의 분포와 그 분포를 형성시키는 모수를 알 수 없습니다. 우리가 얻을 수 있는 데이터는 특정 분포를 따르는 모집단에서 데이터를 샘플링 한 것으로 생각해야 합니다. 따라서 전통적인 통계학 기법이든, 통계학에 기반을 둔 머신러닝 기법이든 추정을 하기 위해 활용하는 데이터는 모두 표본입니다.2   Problem setting 우리는 궁극적으로 모집단의 데이터에 적합시킨(fit) regressor를 추정하고자 합니다.\\[Y=f(X)+\\epsilon\\] \\(\\epsilon\\)(random gaussian noise)은 평균 0, 분산 \\(\\sigma^2\\)인 가우시안 분포\\[E(\\epsilon) = 0\\]\\[Var(\\epsilon)=\\sigma^2\\] 모집단의 분포에서 크기(size) T만큼의 표본을 무한번 복원 추출을 하여 표본 \\(X^{(i)}\\), \\(Y^{(i)}\\)를 뽑습니다.\\[\\begin{aligned}X_{i} &amp;amp;= (x^{(i)}_{1}, \\space x^{(i)}_{2}, \\space ..., \\space x^{(i)}_{T})\\\\Y_{i} &amp;amp;= (y^{(i)}_{1}, \\space y^{(i)}_{2}, \\space ..., \\space y^{(i)}_{T})\\end{aligned}\\] 각 표본으로 각자의 데이터를 통해 regressor를 fitting 하여 class of models인 estimator를 구합니다.\\[estimator = \\hat{f}(X|\\theta)\\] estimator의 각 model은 자신들이 적합된 표본 데이터에 따라 각기 다른 \\(\\theta\\)값을 가지게 됩니다. 따라서 이후에 살펴볼 bias 수식에 기대값이 있게 됩니다. 이후의 수식은 training시 활용한 표본 데이터가 아니라 모집단 분포에서 새로 추출한 test data에 대한 수식임을 반드시 명심합시다!!(train data와 test data는 결국 같은 분포에 샘플링 된 것임)3   Proof of Bias-Variance Decomposition 먼저, 수식의 단순화를 위해 estimator를 $$\\hat{f}(X \\theta))\\(에서\\)\\theta\\(를 삭제한\\)\\hat{f}(X)$$로 표기하겠습니다. \\[\\begin{aligned}MSE(\\hat{f}(X)) &amp;amp;= E[(Y-\\hat{f}(X))^2] \\qquad (1)\\\\&amp;amp;= E[(f(X) + \\epsilon - \\hat{f}(X))^2] \\qquad (2) \\\\&amp;amp;= E[(f(X) - \\hat{f}(X)) + \\epsilon)^2] \\qquad (3)\\\\&amp;amp;= E[(f(X)-\\hat{f}(X))^2 + \\epsilon^2 + 2(f(X)-\\hat{f}(X))\\epsilon] \\qquad (4)\\\\&amp;amp;= E[(f(X)-\\hat{f}(X))^2] + E[\\epsilon^2] + E[2(f(X)-\\hat{f}(X))\\epsilon] \\qquad (5)\\\\&amp;amp;= E[(f(X)-\\hat{f}(X))^2] + E[\\epsilon^2] + E[2(f(X)-\\hat{f}(X))]E[\\epsilon] \\qquad (6)\\\\&amp;amp;= E[(f(X)-\\hat{f}(X))^2] + E[\\epsilon^2] \\qquad (7) \\\\\\end{aligned}\\] \\((2)\\)는 \\(Y=f(X)+\\epsilon\\)으로 도출됩니다. \\((3), (4)\\)는 square expansion인 \\((a+b)^2 = a^2+b^2+2ab\\)를 통해 도출됩니다. \\((5)\\)는 기대값의 linear property를 이용한 것입니다. \\((6)\\)은 확률변수 \\(\\epsilon\\)와 \\(\\hat{f}\\)의 독립성을 이용한 것입니다. 두 확률변수가 독립일 때, 두 확률변수의 곱의 기대값은 각각의 기대값의 곱으로 분리될 수 있다는 사실을 떠올린다면 쉽게 도출할 수 있습니다. 다음으로 위 단락에서 도출한 마지막 항을 이어서 전개해 보겠습니다.\\[\\begin{aligned}MSE(\\hat{f}(X)) &amp;amp;= E[(f(X)−E[\\hat{f}(X)]+E[\\hat{f}(X)]− \\hat{f}(X))^2] + E[\\epsilon^2] \\qquad (8) \\\\&amp;amp;= E[(f(X)−E[\\hat{f}(X)])+(E[\\hat{f}(X)]− \\hat{f}(X)))^2] + E[\\epsilon^2] \\qquad (9) \\\\&amp;amp;= E[(f(X)−E[\\hat{f}(X)])^2+(E[\\hat{f}(X)]− \\hat{f}(X))^2 + 2(f(X)−E[\\hat{f}(X)])(E[\\hat{f}(X)]− \\hat{f}(X))] + E[\\epsilon^2] \\qquad (10) \\\\&amp;amp;= E[(f(X)−E[\\hat{f}(X)])^2]+E[(E[\\hat{f}(X)]− \\hat{f}(X))^2] + E[2(f(X)−E[\\hat{f}(X)])(E[\\hat{f}(X)]− \\hat{f}(X))] + E[\\epsilon^2] \\qquad (11) \\\\&amp;amp;= (f(X)−E[\\hat{f}(X)])^2+E[(E[\\hat{f}(X)]− \\hat{f}(X))^2] + E[2(f(X)−E[\\hat{f}(X)])(E[\\hat{f}(X)]− \\hat{f}(X))] + E[\\epsilon^2] \\qquad (12) \\\\&amp;amp;= (f(X)−E[\\hat{f}(X)])^2+E[(E[\\hat{f}(X)]− \\hat{f}(X))^2] + 2(f(X)−E[\\hat{f}(X)])(E[E[\\hat{f}(X)]− \\hat{f}(X)]) + E[\\epsilon^2] \\qquad (13) \\\\&amp;amp;= (f(X)−E[\\hat{f}(X)])^2+E[(E[\\hat{f}(X)]− \\hat{f}(X))^2] + 2(f(X)−E[\\hat{f}(X)])(E[\\hat{f}(X)]− E[\\hat{f}(X)]) + E[\\epsilon^2] \\qquad (14) \\\\&amp;amp;= (f(X)−E[\\hat{f}(X)])^2+E[(E[\\hat{f}(X)]− \\hat{f}(X))^2] + E[\\epsilon^2] \\qquad (15) \\\\&amp;amp;= (f(X)−E[\\hat{f}(X)])^2+E[(E[\\hat{f}(X)]− \\hat{f}(X))^2] + E[(\\epsilon − 0)^2] \\qquad (16) \\\\&amp;amp;= (f(X)−E[\\hat{f}(X)])^2+E[(E[\\hat{f}(X)]− \\hat{f}(X))^2] + E[(\\epsilon − E[\\epsilon])^2] \\qquad (17) \\\\&amp;amp;= Bias[\\hat{f}(X)]^2 + Var[\\hat{f}(X)] + \\sigma^{2}_{\\epsilon} \\qquad (18) \\end{aligned}\\] \\((8)\\)은 식의 편리한 유도를 위해 \\(E[\\hat{f}(X)]\\)를 빼고 더한 것입니다. 원래의 식과 완벽하게 동일합니다. \\((9), (10)\\)은 또 다시 square expansion을 활용하였습니다. \\((11)\\)은 기대값의 linear property를 활용한 것입니다. \\((12)\\)는 \\(E[c] = c\\)(\\(c\\) is not r.v but constant)를 활용한 것입니다. 모수인 \\(f(X)\\)는 정해진 상수이며, 확률변수 \\(\\hat{f}(X)\\)의 기대값인 \\(E[\\hat{f}(X)]\\)는 상수입니다. \\(\\hat{f}(X)\\)의 값은 \\(X\\)의 realization(observation)에 따라서 그 값이 변하는 확률변수이지만, 해당 확률변수의 기대값은 고정된 상수임을 반드시 기억해야하겠습니다. \\((13)\\)은 \\((12)\\)와 같은 이유로 기대값 formula에서 상수항을 밖으로 꺼낸 것입니다. \\((14)\\)는 \\(E[E[X]] = E[X]\\) 성질과 linear 성질을 활용하였습니다. 그 결과 3번째 항의 경우 값이 \\(0\\)이 됩니다. \\((15), (16), (17)\\)은 \\(E[\\epsilon] = 0\\)을 이용해 유도하였습니다. 또한 분산의 공식에 의해 마지막 항을 \\(\\sigma^{2}_{\\epsilon}\\)으로 치환할 수 있습니다.결과적으로 추정식의 오차는 \\(Bias^2\\), \\(Variance\\), \\(irreducible \\space error\\)로 decomposition되는 것을 확인할 수 있습니다. irreducible error는 절대로 줄일 수 없는 내재적인 오류를 뜻합니다.2.1   Meaning of Biasdecomposition을 통해 이끌어 낸 bias의 의미2.2   Meaning of Variancedecomposition을 통해 이끌어낸 variance의 의미4   Bias-Variance Trade-off코드를 통해서 시각화Reference The Bias-Variance Tradeoff The Bias-Variance trade-off : Explanation and Demo 계량경제학 입문 Variance Reduction and Ensemble Methods MS&amp;amp;E 226: Fundamentals of Data ScienceLecture 6: Bias and variance 위키피디아-편향-분산 트레이드오프 [머신 러닝] 편향-분산 트레이드오프 (Bias-Variance Tradeoff) Estimating Parameters from Simple Random Samples Why is an estimator considered a random variable? Bias-Variance Analysis: Theory and Practice - CS229" }, { "title": "Taylor Series", "url": "/posts/taylor_series/", "categories": "Math, Calculus", "tags": "taylor series", "date": "2020-07-16 00:00:00 +0900", "snippet": "1   Taylor Series\\(x=a\\)에서 무한번 미분 가능한 함수 \\(f(x)\\)를 근사 다항식으로 표현한 것을 테일러 급수(taylor series, taylor expansion)라고 합니다.\\[\\begin{aligned}f(x)&amp;amp;= \\cfrac{f(a)(x-1)^0}{0!} + \\cfrac{f^{(1)}(a)(x-a)^1}{1!} + \\cfrac{f^{(2)}(a)(x-a)^{2}}{2!} + ... \\\\&amp;amp;= \\sum^{\\infty}_{n=0} \\cfrac {f^{(n)}(a)}{n!}{(x-a)}^{n}\\end{aligned}\\]이를 다르게 표현하면, \\(f(x)\\)를 \\(x=a\\)에서 동일한 미분계수(derivative)를 가지는 다항함수로 근사 시키는 것이라고 할 수 있겠습니다.2   자연상수 \\(e\\)테일러 급수를 통해 자연상수 \\(e\\)를 다항함수로 표현 할 수 있습니다. 자연상수 \\(e\\)의 정의는 다음과 같습니다.\\[e=\\lim\\limits_{n\\rightarrow\\infty}{\\Big(1+\\cfrac{1}{n}\\Big)}^{n} =\\lim\\limits_{n\\rightarrow0}{\\Big(1+n\\Big)^{1/n}}\\]그러나 n이 무한대로 커지면 연산에 필요한 cost가 가중되게 됩니다. 다른 형태의 식으로 2.718281828… 을 근사할 수 없을까요? 테일러 급수를 이용해 봅시다!\\[\\begin{aligned}f(x)&amp;amp;= e^{x} \\\\ &amp;amp;= \\sum_{n=0}^{\\infty}\\cfrac{e^a}{n!}(x-a)^n\\end{aligned}\\]위 식은 \\(e^x\\)를 무한번 미분해도 \\(e^x\\)임을 고려하면 쉽게 도출 할 수 있습니다.위 식에서 \\(a=0\\)이라면,\\[\\begin{aligned}f(x)&amp;amp;= e^{x} \\\\ &amp;amp;= \\sum_{n=0}^{\\infty}\\cfrac{1}{n!}x^n \\\\&amp;amp;= 1+\\cfrac{1}{1!}x+\\cfrac{1}{2!}x^2+\\cfrac{1}{3!}x^3+...\\end{aligned}\\]\\(x=1\\)을 대입하면,\\[\\begin{aligned}f(1)&amp;amp;= e \\\\ &amp;amp;= \\sum_{n=0}^{\\infty}\\cfrac{1}{n!} \\\\&amp;amp;= 1+\\cfrac{1}{1!}+\\cfrac{1}{2!}+\\cfrac{1}{3!}+...\\end{aligned}\\]\\(x=-1\\)을 대입하면,\\[\\begin{aligned}f(-1)&amp;amp;= e^{-1} \\\\ &amp;amp;= \\sum_{n=0}^{\\infty}\\cfrac{(-1)^{n}}{n!} \\\\&amp;amp;= 1-\\cfrac{1}{1!}+\\cfrac{1}{2!}-\\cfrac{1}{3!}+...\\end{aligned}\\]3   매클로린 급수매클로린 급수(maclaurin series)란 talyor seires에서 \\(a=0\\)인 series를 뜻합니다. 위에서 \\(e^x\\)를 테일러 시리즈로 근사할 때 \\(a=0\\)으로 하였는데, 이는 매클로린 급수를 의미한다고 하겠습니다." }, { "title": "Random Forest", "url": "/posts/random_forest/", "categories": "ML, Statistical Learning", "tags": "random forest, ml, statistical learning", "date": "2020-07-15 00:00:00 +0900", "snippet": " 랜덤 포레스트를 이해하기 위해 필요한 bagging과 관련된 확률 이론을 정리해보겠습니다.1   BaggingBootstrapdata point가 n개 있을 때, bootstrap은 n개의 크기를 가진 표본을 복원 추출하는 방법을 말합니다. Bootstrap을 통해 추출된 크기가 \\(n\\)인 표본은 \\(X=\\{X_{1}, X_{2}, ..., X_{n}\\}\\)으로 표기 할 수 있습니다.중요한 점은 \\(n\\)개의 표본단위 \\(X_{1}, X_{2}, ..., X_{n}\\)를 정해진 어떤 값으로 생각하면 안 된다는 것입니다. \\(X_{n}\\)을 \\(n\\)번째에 추출된 어떤 값으로 생각해야하며, 표본 \\(X\\)에 속하는 각각의 표본 단위는 모두 확률 변수(random variable)입니다. 또한 각 표본 단위 \\(X_{n}\\)은 모집단 \\(X\\)와 같은 확률 분포입니다.이를 동일 분포(identical distribution), 독립 분포(independent distribution)인 확률 변수(random variables)라고 말합니다. 동일 분포: 각 표본 단위들이 동일한 분포임을 뜻합니다. 모집단에서 추출한 표본 단위는 모집단의 분포를 그대로 가지고 있으므로, 하나의 표본에 존재하는 모든 표본 단위는 동일한 분포를 가지고 있습니다. 독립 분포: 각 표본 단위가 추출되는 것이 다른 표본 단위가 추출되는 확률에 영향을 끼치지 않는 특성을 뜻합니다. 이는 표본 추출이 ‘무작위 복원 추출’을 전제하기 때문입니다. 따라서 각 표본 단위들이 추출된 확률은 모두 동일합니다. 즉 \\(P(X_{n}) = 1/n\\)입니다.축약어로는 iid(identical and independent distribution)라고 하며, 다음과 같이 표기할 수 있습니다(\\(X\\)는 모집단의 확률 변수를 나타냄)\\[\\{X_{1}, X_{2}, ..., X_{n}\\} \\sim i.i.d \\space f_{X}(x)\\]이를 다른 말고 확률 표본(random sample)이라고도 합니다. 확률 표본이란 모집단에 속하는 모든 단위가 표본에 추출될 확률이 모두 동일하도록 추출되는 표본을 말합니다. 즉 \\(X_{1}, X_{2}, ..., X_{n}\\)의 표본에서 아래의 수식이 성립됩니다.\\(P(X_{1}) = P(X_{2}) = ... = P(X_{n})\\)\\(P(X_{1}, X_{2}, ..., X_{n}) = P(X_{1})P(X_{2})...P(X_{n})\\)1.1   What’s the Bagging?Bagging은 Bootstrap aggregating의 약자 Bootstrap은 모집단에서 복원 추출한 sample들을 뜻합니다. 배깅 방법은 uniform 확률 분포에서 독립적이면서 랜덤 복원 추출로 선택된 data들을 이용합니다.학습 데이터가 \\(X=x_{1}, ..., x_{n}\\) 대응 되는 반응 변수가 \\(Y=y_{1},...,y_{n}\\) 일때, bagging은 \\(B\\)번 만큼 반복 시행됩니다.For \\(b=1,...,B\\): Sample, with replacement, $n$ training examples from \\(X, Y\\); call these \\(X_{b}, Y_{b}\\) Train a classification or regression tree \\(f_{b}\\) on \\(X_{b}, Y_{b}\\)학습이 완료된 후 unseen sampels \\(x&#39;\\)에 대한 prediction은 모든 개별적인 tree의 결과를 averaging 하여 나타냅니다.\\[\\hat{f} = \\cfrac{1}{b}\\sum_{b=1}^{B}f_{b}(x&#39;)\\]bagging은 identical distribution 조건을 만족하지만, independence distribution 조건을 만족시키지 못합니다. 예를들어, tree estimator를 만들 때, 어느 tree에서나 중요하게 사용되는 feature가 있다고 생각해봅시다. 사람의 성별을 예측하는 문제에서는 ‘키’와 같은 변수가 되겠습니다. 이 경우 어느 tree에서나 ‘키’ 변수는 첫번째 split 기준으로 선택될 것입니다. 그 결과 대부분의 tree의 prediction 결과는 비슷해질 것입니다. 다시 말해 각 tree의 prediction 값이 correlated(not independent) 됩니다.이를 볼 때, bagging은 iid 확률 변수들의 sequence(bootstrap samples)를 받아 tree estimator를 통해 id 확률 변수로 변환하는 과정이라고 생각해볼 수 있습니다.1.2   Advantages of Baggingbagging은 모델의 variance을 줄여서(bias는 상승시키지 않으면서) 모델의 성능을 끌어 올릴 수 있습니다. 이는 하나의 tree의 분산이 높아 학습 데이터의 이상치에 지나치게 sensitive 하더라도, 다수의 tree의 결과를 averaging 하면, 이상치에 강건(variance 낮음)한 모델을 만들 수 있다는 것을 의미합니다. 그러나 이는 각 tree가 correlated 되지 않을 것을 전제로 합니다..Bagging succeeds in smoothing out this variance and hence reducing the test error.Bagging can dramatically reduce the variance of unstable procedures like trees, leading to improved prediction. A simple argument shows why bagging helps under squared-error loss, in short because averaging reduces variance and leaves bias unchanged.1.3   Why bagging reduce variance??bootstrapping method is better when the training samples are sparase, and the subspace method is better when the classes are compact and the boundaries are smooth.2   Random subspace method2.1   What’s the Random subspace method?Random subspace method(이하 RSM)는 bagging과 유사하지만, features(attributes, predictors, independent variables)를 랜덤 복원 추출한다는 점에서 차이가 있습니다.RSM는 feature bagging 또는 attribute bagging이라고도 불립니다. RSM은 앙상블 방법에 활용된 각 classifiers(estimators) 간의 correlation을 낮추는 역할을 합니다.In the random subspace method, in each pass all the training points are projected onto a randomly chosen coordinate subspace in which a classifier is derived. The combined classifier is called a random forest2   From Bagging to Random Forests2.1   Advatages of random forest over single tree bagging: it is better when the training samples are sparse Random subspace method: it is better when the classes are compact and the boundaries are smooth.The subsampling method is preferable when the training set is very sparse relative to dimensionality, especiallywhen coupled with a close-to-vanishing maximum Fisher’s ratio (0.3 or below), and when the class boundary is highly nonlinear. Same Bias, but with lower variance over single decision Tree decorrelate trees: Use a random subset of features in each step of growing each tree. train dataset의 feature가 1개만 존재한다면, random forest는 사실상 bagging 알고리즘과 같다(random subspace method를 사용할 수 없기 때문) 3   Appendix bayes error: 이론적으로 달성할 수 있는 최소의 오차(irreducible error, 더 이상 줄일 수 없는 오차)3.1   추정량(estimator)과 추정치(estimate) 대학생들의 한 달 평균 용돈을 알기 위하여 100명의 대학생을 단순 무작위로 추출하여 조사한 결과, 표본 평균 \\(\\overline{X}=30\\)만원 이었습니다. 따라서 모집단의 모수 \\(\\theta=\\mu\\)를 30만원 일것이라고 추정 하였습니다.이 때 표본 통계량 \\(\\hat{\\theta}\\)를 구하는 공식 \\(\\overline{X}=\\cfrac{1}{n}\\sum_{i=1}^{n}X_{i}\\)는 추정량(estimator)라고 하고, 이에 따른 구체적인 수치 \\(\\bar{x}=30\\)만원은 추정치(estimate)가 됩니다. 정리 하면 아래와 같습니다. 추정량(estimator): 표본에 포함된 자료를 이용하여 추정치를 계산할 수 있는 법칙, 공식 또는 알고리즘 추정치(estimate): 추정량을 이용하여 계산된 구체적인 수치값3.2   불편성(bias)아래 공식을 만족하는 추정량을 불편 추정량(unbiased estimator)라고 합니다.\\[E(\\hat{\\theta}) = \\theta\\]참고로 표본의 통계치들은 확률 변수임을 반드시 기억해야 하겠습니다. 모수에서 크기가 \\(n\\)인 표본을 뽑게되면, 뽑을 때마다 표본의 통계치들을 달라질 것입니다. 따라서 표본 통계량 \\(\\hat{\\theta}\\)가 확률 변수이고 그에 상응하는 표본 분포(sample distribution)을 가지므로, 기대값을 구할 수 있는 것입니다.Reference Random forest Random subspace method A Data Complexity Analysis of ComparativeAdvantages of Decision Forest Constructors Understanding the Effect of Bagging on Variance and Bias visually 좋은 추정량(estimator)의 조건 - unbiased, efficiency, consistency 모집단 평균의 추정 확률표본, 통계량, 모수, 표본평균의 분포 Why the trees generated via bagging are identically distributed?" }, { "title": "Probability Notation", "url": "/posts/probability_notation/", "categories": "Math, Statistics", "tags": "probability", "date": "2020-07-12 00:00:00 +0900", "snippet": " 확률과 관련된 공부를 하면서, semicolon(;), commam(,), vertical line(|)이 포함된 probability notation을 많이 보았습니다. 그러나 그 의미가 혼용되어 사용되는 것을 발견하고 그것을 정리하기 위해 포스팅을 작성합니다.1   \\(P(x\\vert\\theta)\\)를 바라보는 2가지 관점\\(P(x\\vert\\theta)\\)는 2가지 관점에서 사용되는 것을 목격할 수 있습니다. \\(x\\)를 변수, \\(\\theta\\)를 상수로 바라보는 관점과 \\(x\\)를 상수, \\(\\theta\\)를 변수로 바라보는 관점이 그것입니다. 두 가지 관점은 어느 부분을 더욱 강조할 것인가와 관련되어 있습니다.1.1   \\(P(x\\vert\\theta)\\)는 \\(x\\)에 대한 함수(\\(\\theta\\)는 상수)\\(\\theta\\)는 RV가 아니라 상수로 취급되면, \\(P(x\\vert\\theta)\\)는 모델의 파라미터 \\(\\theta\\)가 주었졌을 때의 \\(x\\)의 확률입니다. \\(\\theta\\)가 상수이므로(확률변수가 아님) 조건부 확률이라고 부르지 않습니다. 또한 \\(P(x\\vert\\theta)\\)는 \\(P(x;\\theta)\\) 또는 \\(P_{\\theta}(x)\\)로도 표현됩니다.만일 \\(\\theta\\)가 RV이면, \\(P(x\\vert\\theta)\\)는 조건부 확률이며, \\(\\cfrac {P(X, \\theta)} {P(\\theta)}\\)로 정의됩니다.1.2   \\(P(x\\vert\\theta)\\)는 \\(\\theta\\)에 대한 함수(\\(x\\)는 상수)이 경우는 \\(P(x\\vert\\theta)\\)를 최대로 하는 \\(\\theta\\)를 찾는 MLE에서의 likelihood를 의미합니다. 이는 \\(L(\\theta\\vert x)\\)로 표현할 수 있습니다. 따라서 likelihood는 \\(\\theta\\)에 값을 할당하여 얻을 수 있는 특정 데이터 \\(x\\)에 대한 확률인 \\(P(x\\vert\\theta)\\)을 표기하는 약어(shorthand)에 불과합니다. 따라서 이러한 관점에서의 \\(P(x\\vert\\theta)\\)는 objective 함수로 주로 사용됩니다.2   likelihoodReference What is the difference between “likelihood” and “probability”?" }, { "title": "Ligit, Sigmoid, Softmax의 관계", "url": "/posts/logit_sigmoid_softmax/", "categories": "ML, Basic", "tags": "logit, sigmoid, softmax", "date": "2020-06-07 00:00:00 +0900", "snippet": " 왜 NN의 출력층에 sigmoid, softmax 함수를 사용할까요? 이는 출력층의 값을 ‘확률’로서 표현하기 위한 필연적 결과입니다. 본 글에서는 logit, sigmoid, softmax의 관계에 대해서 정리해보았습니다.1. Basic앞으로 내용을 전개할 때 중요하게 사용되는 bayes theorem(베이즈 정리) 및 law of total probability(전확률 법칙)에 대해 간단히 정리하고 넘어가겠습니다.Bayes Theorem불확실성 하에서 의사결정문제를 수학적으로 다룰 때 사용하는 것으로 두 확률 변수의 사전 확률과 사후 확률 사이의 관계를 나타내는 수식입니다. 공식은 아래와 같습니다.\\[\\begin{aligned}P(Y|X) &amp;amp;= {\\cfrac {P(X \\cap Y)} {P(X)}} \\\\P(X|Y) &amp;amp;= {\\cfrac {P(Y \\cap X)} {P(Y)}} \\\\P(Y \\cap X) &amp;amp;= P(X \\cap Y) = P(X|Y)P(Y) = P(Y|X)P(X)\\\\\\therefore P(Y|X) &amp;amp;= {\\cfrac {P(X \\vert Y)P(Y)} {P(X)}} \\end{aligned}\\] \\(P(Y \\vert X)\\): 사후확률(posterior probability) \\(P(X \\vert Y)\\): 가능도(likelihood) \\(P(Y)\\): 확률변수 Y의 사전확률(prior probability) \\(P(X)\\): 확률변수 X의 사전확률(prior probability)Law of total probability표본 공간 \\(S\\)를 \\(n\\)개의 영역으로 나누었을 때, 표본 공간 \\(S\\)의 사건 \\(A\\)의 확률은 다음과 같이 구할 수 있습니다.\\[P(A) = P(A \\cap B_{1}) + P(A \\cap B_{2})+ ... + P(A \\cap B_{n})\\]2. Logit &amp;amp; Sigmoidlogit은 log odds를 뜻합니다. 이를 이해하기 위해서는 odds에 대한 개념 학습이 선행되어야 하겠습니다. odds란 도박에서 얻을(pay off) 확률과 잃을 확률(stake)의 비율을 뜻합니다. 다시 말해 두 확률의 비를 뜻한다고 생각하면 되겠습니다. 도박이 아니라 NN task에서 흔히 다루는 이진 분류 문제에서 생각해봅시다. \\[Classes: C_{1}, C_{2}\\] \\[Probabiliy \\space of \\space C_{1} \\space given\\space X: y=P(C_{1} \\vert X)\\] \\[Probabiliy \\space of \\space C_{2} \\space given\\space X: 1-y=P(C_{2} \\vert X)\\] 우리는 하고자 하는 것은 \\(X\\)가 어떤 클래스일지 맞추는 간단한 문제를 해결하는 것입니다. 이 경우 우리는 간단하게 \\(P(C_{1} \\vert X) = y\\) 와 \\(P(C_{2} \\vert X) = 1-y\\) 중 큰 값을 $X$의 클래스로 예측하면 됩니다.그런데, 앞서 언급한 두 가지 수식을 하나의 수식으로 합쳐서 이와 같은 결정 문제를 표현 할 수 없을까요? 확률의 비인 odds를 통해 해결할수 있습니다. 아래와 같이 말이죠.\\[\\begin{aligned}odds &amp;amp;= \\cfrac{y}{1-y} = \\cfrac{P(C_{1}|X)}{1-P(C_{1}|X)} \\\\\\\\Choose &amp;amp;= \\begin{cases} C_{1} &amp;amp;\\text{if } \\cfrac{y}{1-y}&amp;gt;1 \\\\ C_{2} &amp;amp;\\text{if } \\cfrac{y}{1-y}&amp;lt;1\\end{cases}\\end{aligned}\\]한편 NN의 출력층의 값의 범위를 살펴봅시다. 출력층의 값을 $z$라고 하고, 단순화 시켜서 표현한다면 아래와 같습니다.\\[z = \\theta_{0}+\\theta_{1}x_{1} + ... \\\\\\\\\\]이때 \\(z\\) 값의 범위는,\\[-\\infty &amp;lt; z &amp;lt; \\infty\\]NN 학습에서 주로 사용되는 손실함수는 크로스 엔트로피입니다. $P_{data}$는 데이터의 분포이며, \\(P_{model}\\)은 모델의 예측 분포라고 할 때, 크로스 엔트로피는 다음과 같이 나타낼 수 있습니다.\\[H(P,Q)=−\\sum_{x}P_{data}(x)logP_{model}(x)\\]여기서 중요한 점은 \\(P_{data}(x)\\)와 \\(P_{model}(x)\\)가 확률이라는 것입니다. 그렇다면 \\(z\\)를 어떻게 확률로 개념으로 변환시킬 수 있을까요? 결론적으로 말하면, \\(sigmoid\\) 함수를 통해 \\(-\\infty\\) ~ \\(+\\infty\\)의 값을 \\(0\\)~\\(1\\) 범위로 변환 할 수 있습니다. \\(sigmoid\\) 함수는 \\(logit\\) 함수에서 도출할 수 있습니다.\\[\\begin{aligned}logits &amp;amp;= log(odds)\\\\&amp;amp;= log\\bigg(\\cfrac{y}{1-y}\\bigg) \\\\&amp;amp;= log \\bigg(\\cfrac{P(C_{1}|X)}{1-P(C_{1}|X)} \\bigg) \\\\\\end{aligned}\\]\\[\\therefore -\\infty &amp;lt; logits &amp;lt; +\\infty\\]\\(logits\\)과 \\(z\\)의 범위가 같으니, 두 값을 동치로 놓고, 식을 전개해봅시다.\\[\\begin{aligned}z &amp;amp;= log \\bigg( \\cfrac {y} {1-y} \\bigg) ,\\space e^{z} = \\bigg( \\cfrac {y} {1-y} \\bigg) \\\\\\end{aligned}\\]\\[\\begin{aligned}y &amp;amp;= \\cfrac {e^z} {1+e^z} \\\\&amp;amp;= \\cfrac {(e^z)/e^z} {(1+e^z)/e^z} \\\\&amp;amp;= \\cfrac {1} {1+e^{-z}}\\end{aligned}\\]위 식을 볼때, logit과 sigmoid는 역함수 관계임을 알 수 있으며, 2가지 중요한 사실을 도출할 수 있습니다. logits은 \\(0\\)~\\(1\\)의 범위를 \\(-\\infty\\) ~ \\(+\\infty\\)로 변환 sigmoid는 \\(-\\infty\\) ~ \\(+\\infty\\)를 \\(0\\)~\\(1\\)로 변환 두 함수가 다음과 같은 관계가 있을 때, 두 함수 \\(f\\)와 \\(g\\)를 역함수 관계라고 합니다. \\(f(x) = y \\\\ g(y) = x\\)3. Softmaxsoftmax는 sigmoid 함수를 클래스가 3개 이상일 때로 일반화 하면 유도할 수 있습니다. simoid를 일반화하면 softmax이며, softmax의 특수한 경우가 simoid 함수입니다. 유도 과정에 간단한 산수적인 테크닉이 필요합니다.이진 분류일 때, odds는 아래와 같이 정의됩니다.\\[\\cfrac{P(C_{1}|X)}{P(C_{2}|X)} = e^{z}\\]클래스의 개수가 $K$일때로 일반화 하면 위 식은 아래의 형태로 새로 정의할 수 있습니다.\\[\\tag{1}\\cfrac{P(C_{i}|X)}{P(C_{k}|X)} = e^{z_{i}}\\]양변을 \\(i=1\\) 부터 \\(K-1\\)까지 더해보겠습니다.\\[\\sum_{i=1}^{K-1} \\cfrac{P(C_{i}|X)}{P(C_{k}|X)} = \\sum_{i=1}^{K-1} e^{z_{i}}\\]위 식의 좌항의 분모는 \\(\\sum\\) 연산과 관련이 없기 때문에, 아래처럼 도출됩니다.\\[\\cfrac{P(C_{1}|X)+P(C_{2}|X)+...+P(C_{K-1}|X)}{P(C_{k}|X)} = \\sum_{i=1}^{K-1} e^{z_{i}}\\]확률의 합은 1이므로, 좌항의 분자를 변형하여 식을 아래와 같이 표현할 수 있습니다.\\[\\cfrac{1-P(C_{K} \\vert X)}{P(C_{k} \\vert X)} = \\sum_{i=1}^{K-1} e^{z_{i}}\\]\\(P(C_{K} \\vert X)\\)에 대해서 정리하면,\\[\\tag{2}P(C_{K} \\vert X)= \\cfrac {1} {1+\\sum_{i=1}^{K-1} e^{z_{i}}}\\]\\((1)\\) 식은 아래와 같이 쓸수 있습니다.\\[\\tag{3} P(C_{i}|X) = e^{z_{i}}P(C_{k}|X)\\]\\((2)\\)식을 \\((3)\\)식에 대입 합니다.\\[P(C_{i}|X) = \\cfrac {e^{z_{i}}} {1+\\sum_{i=1}^{K-1} e^{z_{i}}}\\]\\((1)\\)에 \\(i\\)대신 \\(k\\)를 대입하면, \\(e^{z_{k}} = 1\\) 이므로, 최종적으로 우리가 익히 아는 softmax 함수를 도출 할 수 있습니다.\\[\\begin{aligned}P(C_{i}|X) &amp;amp;= \\cfrac {e^{z_{i}}} {e^{z_{i}}+\\sum_{i=1}^{K-1} e^{z_{i}}} \\\\&amp;amp;= \\cfrac {e^{z_{i}}} {\\sum_{i=1}^{K} e^{z_{i}}}\\end{aligned}\\]참고자료 한 페이지 머신러닝 Sigmoid, Logit and Softmax" }, { "title": "Byte Pair Encoding", "url": "/posts/byte_pair-encoding/", "categories": "ML, NLP", "tags": "nlp, byte pair encoding", "date": "2020-06-05 00:00:00 +0900", "snippet": " 최근 NLP에서 tokenizer로 많이 사용되고 있는 BPE에 대해서 간단하게 정리해 보겠습니다. 전체코드는 이곳에서 확인해 보실 수 있습니다.1   Backgroud: Subword Segmentationsubword segmentation(단어 분리, 단어 분절)이란, 하나의 단어(혹은 토큰)는 여러 개의 subword의 조합으로 이루어져 있다는 가정하에 subword 단위의 토크나이징을 수행하여 단어를 이해하려는 목적을 가진 전처리 작업을 말합니다. 이어서 설명할 BPE는 subword segmentation 기법 중 하나입니다.1.1   Example실제로 영어나 한국어는 subword 단위로 의미를 분리할 수 있는 경우가 많습니다. 아래의 예시를 보시면 그 의미를 쉽게 이해할 수 있습니다. 언어 단어 subword 구성 영어 concentrate con(=together) + centr(=center) + ate(=make) 한국어 집중 集(모을 집) + 中(가운데 중) 2   BPE(Byte Pair Encoding)BPE는 subword segmentation의 대표적인 알고리즘입니다. ‘byte’라는 단어에서 알 수 있듯이 원래는 데이터 압축을 위한 알고리즘으로 탄생했지만, 현재는 NLP 분야의 대표적인 토크나이징 방법으로 활용되고 있습니다. 특히 최신 NLP 모델인 BERT 등에서 기본적인 토크나이저로 활용되고 있습니다.2.1   Merits of BPE 단어 사전의 OOV 문제 완화: subword segmentation인 BEP의 최대 장점은 OOV 문제를 완화할 수 있다는 것입니다. 기존의 vocabulary에 없는 신조어나 오타 등도 subword 단위나 character 단위로 토크나이징 하면 known token의 조합으로 표현가능 합니다. 예를 들어 athazagoraphobia처럼 기존 단어 사전에 없던 단어는 UNK토큰이 아니라 [&#39;▁ath&#39;, &#39;az&#39;, &#39;agor&#39;, &#39;aphobia&#39;]와 같이 subword 단위로 쪼개서 OOV 문제를 회피할 수 있습니다(Sennrich et al., 2015). 언어에 관계없는 토크나이저 구축 가능: BPE 토크나이저는 각 언어의 특성에 적합한 사전 전처리 과정이 필요하지 않은 universal tokenizer입니다. 그러나 한국어의 경우 형태소 분석 후 BPE를 적용하는 것이 특정 태스크에서는 더 높은 스코어를 유도한다는 연구 결과도 있으므로(Park et al., 2020) 진리인 것은 아닌 것 같습니다. 2.2   vocabulary 생성 방법BPE를 통한 토크나이징은 크게 1) 사전 구축, 2) 사전을 통한 토크나이징으로 구성되어 있습니다. 본 글에서는 사전 구축에 집중하여 살펴보겠습니다. BPE는 형태소 분석을 통한 사전 구축 방법과 다르게 사용자가 학습 횟수를 임의로 조정하여 사전의 크기를 조절할 수 있는 특징이 있습니다. 사전 구축은 다음의 프로세스를 통해 이루어집니다. 먼저 논문에서는 BPE 토크나이저 구축 프로세스를 아래와 같이 언급하고 있습니다(Sennrich et al., 2015). Firstly, we initialize the symbol vocabulary with the character vocabulary We iteratively count all symbol pairs and replace each occurrence of the most frequent pair (‘A’, ‘B’) with a new symbol ‘AB’ Each merge operation produces a new symbol which represents a character n-gram. Frequent character n-grams (or whole words) are eventually merged into a single symbol, thus BPE requires no shortlist. 이 내용을 조금 더 자세히 풀어보면…Step 1.   corpus 내의 sentence들을 어절 단위로 분리해 둡니다.Stpe 2.   어절 단위로 분리된 token들을 character 단위로 분리(띄어쓰기 처리) 및 딕셔너리 생성(최종 vocabulary를 만들기 위한 기준으로 사용). 이때 각 word의 끝에는 &amp;lt;/w&amp;gt; 토큰을 붙여줍니다.Stpe 3.   가장 많이 등장한 pair를 찾아 merge한 후 딕셔너리를 업데이트 합니다.Stpe 4.   Step 3을 사용자가 지정한 횟수만큼 반복합니다(sentencepiece의 경우에는 최종 vocab size를 지정합니다)Stpe 5.   완성된 딕셔너리를 통해 unique token만 남은 vocabulary를 생성Stpe 6.   final vocab size = # of initial vocab size(special token 포함) + # of merge operations참고로 step 2에서 붙여주는 &amp;lt;/w&amp;gt; 토큰은 생각보다 중요한 역할을 담당할 수 있습니다. 예를 들어 est 토큰을 생각해봅시다. 이 토큰은 est ern에 속할 수도 있고 small est에 속할 수도 있습니다. 이때 est 각 상황 마다 est토큰의 의미는 조금 다르게 느껴집니다. 만일 est가 word의 마지막에 등장하여 est&amp;lt;\\w&amp;gt;로 처리한다면, 모델은 est의 의미를 좀더 명확히 인지할 수 있게 됩니다 [6].3   BEP with python codescorpus는 아래와 같이 주어졌다고 가정하고 시작하겠습니다.corpus = [ &#39;이 영화를 영화관에서 직접 보지 못한 것을 평생 후회할 것 같다. 보는 내내 감탄을 자아냈고 절대 잊지 못할 여운으로 남을 것이다.&#39;, &#39;평점이 이해되지 않는다 최소 9점은 받아야 한다 반전이 정말 끝내준다&#39;, &#39;말로 표현할 수 없다 완벽한 영화 보는 내내 소름이 돋았다&#39;]3.1   어절 단위 분리 및 어절 내 띄어쓰기 처리sentence를 어절 단위로 분리한 후, 어절 token 내에서 character 단위 분리를 한번에 수행해 보겠습니다. 아래의 함수는 그러한 역할을 수행합니다.def get_dictionary(corpus): &quot;&quot;&quot; 데이터를 읽어와 단어 사전 구축 Args: corpus: 여러 텍스트 데이터가 담긴 리스트 Returns: dict(vocab): 문장 데이터 별 character 단위로 구분된(띄어쓰기) 후보 사전 &quot;&quot;&quot; dictionary = defaultdict(int) for line in corpus: tokens = preprocess(line).strip().split(&quot; &quot;) for token in tokens: dictionary[&quot; &quot;.join(list(token)) + &quot; &amp;lt;/w&amp;gt;&quot;] += 1 return dict(dictionary)결과로 아래와 같은 dictionary가 생성됩니다.dictionary = get_dictionary(corpus)print(dictionary){&#39;이 &amp;lt;/w&amp;gt;&#39;: 1, &#39;영 화 를 &amp;lt;/w&amp;gt;&#39;: 1, &#39;영 화 관 에 서 &amp;lt;/w&amp;gt;&#39;: 1, &#39;직 접 &amp;lt;/w&amp;gt;&#39;: 1, &#39;보 지 &amp;lt;/w&amp;gt;&#39;: 1, &#39;못 한 &amp;lt;/w&amp;gt;&#39;: 1, &#39;것 을 &amp;lt;/w&amp;gt;&#39;: 1, &#39;평 생 &amp;lt;/w&amp;gt;&#39;: 1, &#39;후 회 할 &amp;lt;/w&amp;gt;&#39;: 1, &#39;것 &amp;lt;/w&amp;gt;&#39;: 1, &#39;같 다 &amp;lt;/w&amp;gt;&#39;: 1, &#39;보 는 &amp;lt;/w&amp;gt;&#39;: 2, &#39;내 내 &amp;lt;/w&amp;gt;&#39;: 2, &#39;감 탄 을 &amp;lt;/w&amp;gt;&#39;: 1, ...}3.2   가장 많이 등장한 character pair 찾기dictionary에서 가장 많이 등장한 bi-gram pair를 찾아보겠습니다. 아래의 함수는 dictionary내의 bi-gram pair를 count하는 함수입니다.def get_pairs(dictionary): &quot;&quot;&quot; 딕셔너리를 활용한 바이그램 페어 구축 Args: dictionary: 어절 token 별 character 단위로 분리된 dictionary Returns: pairs: bi-gram pair &quot;&quot;&quot; pairs = defaultdict(int) for word, freq in dictionary.items(): word_lst = word.split() for i in range(len(word_lst)-1): pairs[(word_lst[i], word_lst[i+1])] += freq return dict(pairs)함수의 실행 결과는 다음과 같습니다.pairs = get_pairs(dictionary)print(pairs){(&#39;이&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 4, (&#39;영&#39;, &#39;화&#39;): 3, (&#39;화&#39;, &#39;를&#39;): 1, (&#39;를&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 1, (&#39;화&#39;, &#39;관&#39;): 1, (&#39;관&#39;, &#39;에&#39;): 1, (&#39;에&#39;, &#39;서&#39;): 1, (&#39;서&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 1, (&#39;직&#39;, &#39;접&#39;): 1, (&#39;접&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 1, (&#39;보&#39;, &#39;지&#39;): 1, (&#39;지&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 3, (&#39;못&#39;, &#39;한&#39;): 1, (&#39;한&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 2, (&#39;것&#39;, &#39;을&#39;): 1, (&#39;을&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 3, (&#39;평&#39;, &#39;생&#39;): 1, ...}특히 가장 많이 등장한 bi-gram pair를 찾기 위해서는 max 함수에 key값을 지정해 주면 됩니다.print(max(pairs, key=pairs.get))(&#39;다&#39;, &#39;&amp;lt;/w&amp;gt;&#39;)3.3   best bi-gram pair를 merge하고 dictionary 업데이트가장 많이 등장한 bi-gram pair를 dictionary에서 찾아서 merge(공백 제거)를 진행하는 함수입니다.def merge_dictionary(pairs, dictionary): &quot;&quot;&quot; 가장 자주 등장한 bi-gram pair를 merge(공백 제거) Args: pairs: bi-gram pair dictionary: 문장 데이터 별 character 단위로 구분된(띄어쓰기) 후보 사전 Returns: dict(result): 가장 자주 등장한 bi-gram pair를 merge한 dictionary &quot;&quot;&quot; result = defaultdict(int) best_pair = max(pairs, key=pairs.get) for word, freq in dictionary.items(): paired = word.replace(&quot; &quot;.join(best_pair), &quot;&quot;.join(best_pair)) result[paired] = dictionary[word] return dict(result)예를 들어 현재 상태의 dictionary와 pair를 통해 dictionary를 업데이트 할 경우 아래와 같은 결과를 얻을 수 있습니다.가장 많이 등장한 (‘다’, ‘&amp;lt;/w&amp;gt;‘)의 경우 공백이 제거된 모습을 볼 수 있습니다.temp = merge_dictionary(pairs, dictionary)print(temp){... &#39;것 &amp;lt;/w&amp;gt;&#39;: 1, &#39;같 다&amp;lt;/w&amp;gt;&#39;: 1, ... &#39;돋 았 다&amp;lt;/w&amp;gt;&#39;: 1}3.4   반복을 통한 dictionary 업데이트이제 반복을 통한 dictionary 업데이트를 진행해 보겠습니다. 서두에서 언급 했듯이 반복 횟수는 사용자가 지정하는 하이퍼파라미터입니다. 반복 횟수를 통해 사전의 크기를 조절 할 수 있습니다.iter_nums = 20dictionary = get_dictionary(corpus)for i in range(iter_nums): pairs = get_pairs(dictionary) dictionary = merge_dictionary(pairs, dictionary)그 결과 아래의 dictionary를 얻을 수 있습니다. 공백이 포함되었던 어절 token 중 일부에서 공백이 제거된 모습을 확인 하실 수 있습니다.print(dictionary){&#39;이&amp;lt;/w&amp;gt;&#39;: 1, &#39;영화를&amp;lt;/w&amp;gt;&#39;: 1, &#39;영화관에서&amp;lt;/w&amp;gt;&#39;: 1, &#39;직접&amp;lt;/w&amp;gt;&#39;: 1, &#39;보 지&amp;lt;/w&amp;gt;&#39;: 1, &#39;못 한&amp;lt;/w&amp;gt;&#39;: 1, &#39;것 을&amp;lt;/w&amp;gt;&#39;: 1, &#39;평 생 &amp;lt;/w&amp;gt;&#39;: 1, &#39;후 회 할&amp;lt;/w&amp;gt;&#39;: 1, &#39;것 &amp;lt;/w&amp;gt;&#39;: 1, &#39;같 다&amp;lt;/w&amp;gt;&#39;: 1, &#39;보는&amp;lt;/w&amp;gt;&#39;: 2, &#39;내내&amp;lt;/w&amp;gt;&#39;: 2, &#39;감 탄 을&amp;lt;/w&amp;gt;&#39;: 1, &#39;자 아 냈 고 &amp;lt;/w&amp;gt;&#39;: 1, &#39;절 대 &amp;lt;/w&amp;gt;&#39;: 1, &#39;잊 지&amp;lt;/w&amp;gt;&#39;: 1, &#39;못 할&amp;lt;/w&amp;gt;&#39;: 1, &#39;여 운 으 로&amp;lt;/w&amp;gt;&#39;: 1, &#39;남 을&amp;lt;/w&amp;gt;&#39;: 1, &#39;것 이 다&amp;lt;/w&amp;gt;&#39;: 1, &#39;평 점 이&amp;lt;/w&amp;gt;&#39;: 1, &#39;이 해 되 지&amp;lt;/w&amp;gt;&#39;: 1, &#39;않 는 다&amp;lt;/w&amp;gt;&#39;: 1, &#39;최 소 &amp;lt;/w&amp;gt;&#39;: 1, &#39;점 은 &amp;lt;/w&amp;gt;&#39;: 1, &#39;받 아 야 &amp;lt;/w&amp;gt;&#39;: 1, &#39;한 다&amp;lt;/w&amp;gt;&#39;: 1, &#39;반 전 이&amp;lt;/w&amp;gt;&#39;: 1, &#39;정 말 &amp;lt;/w&amp;gt;&#39;: 1, &#39;끝 내 준 다&amp;lt;/w&amp;gt;&#39;: 1, &#39;말 로&amp;lt;/w&amp;gt;&#39;: 1, &#39;표 현 할&amp;lt;/w&amp;gt;&#39;: 1, &#39;수 &amp;lt;/w&amp;gt;&#39;: 1, &#39;없 다&amp;lt;/w&amp;gt;&#39;: 1, &#39;완 벽 한&amp;lt;/w&amp;gt;&#39;: 1, &#39;영화 &amp;lt;/w&amp;gt;&#39;: 1, &#39;소 름 이&amp;lt;/w&amp;gt;&#39;: 1, &#39;돋 았 다&amp;lt;/w&amp;gt;&#39;: 1}3.5   최종 vocabulary 생성반복 횟수만큼 업데이트 된 dictionary를 기반으로 vocabulary를 생성해 봅시다. vocabulary는 dictionary를 띄어쓰기 단위로 분리한 뒤, 그중 unique한 값들만 취하면 됩니다.def get_vocab(dictionary): &quot;&quot;&quot; dictionary에서 최종 vocabulary를 만드는 함수 Args: dictionary: merge가 수행된 dictionary Returns: dict(vocab): 최종 vocabulary &quot;&quot;&quot; result = defaultdict(int) for word, freq in dictionary.items(): tokens = word.split() for token in tokens: result[token] += freq return dict(result)마지막으로 생성된 vocabulary를 확인 해 볼까요?vocab = get_vocab(dictionary)print(vocab){&#39;이&amp;lt;/w&amp;gt;&#39;: 4, &#39;영화를&amp;lt;/w&amp;gt;&#39;: 1, &#39;영화관에서&amp;lt;/w&amp;gt;&#39;: 1, &#39;직접&amp;lt;/w&amp;gt;&#39;: 1, &#39;보&#39;: 1, &#39;지&amp;lt;/w&amp;gt;&#39;: 3, &#39;못&#39;: 2, &#39;한&amp;lt;/w&amp;gt;&#39;: 2, &#39;것&#39;: 3, &#39;을&amp;lt;/w&amp;gt;&#39;: 3, &#39;평&#39;: 2, &#39;생&#39;: 1, &#39;&amp;lt;/w&amp;gt;&#39;: 10, &#39;후&#39;: 1, &#39;회&#39;: 1, &#39;할&amp;lt;/w&amp;gt;&#39;: 3, &#39;같&#39;: 1, &#39;다&amp;lt;/w&amp;gt;&#39;: 7, &#39;보는&amp;lt;/w&amp;gt;&#39;: 2, &#39;내내&amp;lt;/w&amp;gt;&#39;: 2, &#39;감&#39;: 1, &#39;탄&#39;: 1, &#39;자&#39;: 1, &#39;아&#39;: 2, &#39;냈&#39;: 1, &#39;고&#39;: 1, &#39;절&#39;: 1, &#39;대&#39;: 1, &#39;잊&#39;: 1, &#39;여&#39;: 1, &#39;운&#39;: 1, &#39;으&#39;: 1, &#39;로&amp;lt;/w&amp;gt;&#39;: 2, &#39;남&#39;: 1, &#39;이&#39;: 2, &#39;점&#39;: 2, &#39;해&#39;: 1, &#39;되&#39;: 1, &#39;않&#39;: 1, &#39;는&#39;: 1, &#39;최&#39;: 1, &#39;소&#39;: 2, &#39;은&#39;: 1, &#39;받&#39;: 1, &#39;야&#39;: 1, &#39;한&#39;: 1, &#39;반&#39;: 1, &#39;전&#39;: 1, &#39;정&#39;: 1, &#39;말&#39;: 2, &#39;끝&#39;: 1, &#39;내&#39;: 1, &#39;준&#39;: 1, &#39;표&#39;: 1, &#39;현&#39;: 1, &#39;수&#39;: 1, &#39;없&#39;: 1, &#39;완&#39;: 1, &#39;벽&#39;: 1, &#39;영화&#39;: 1, &#39;름&#39;: 1, &#39;돋&#39;: 1, &#39;았&#39;: 1}4   참고자료 월간 자연어 처리 - BPE tutorial Segmentation using Subword (Byte Pare Encoding, BPE) 단어 분리하기(Byte Pair Encoding, BPE) Sennrich, R., Haddow, B., &amp;amp; Birch, A. (2015). Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909. Byte Pair Encoding — The Dark Horse of Modern NLP bpe Park, K., Lee, J., Jang, S., &amp;amp; Jung, D. (2020). An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks. arXiv preprint arXiv:2010.02534." }, { "title": "Continuous Random Variable", "url": "/posts/contiunous_random_variable/", "categories": "Math, Statistics", "tags": "continuous, random variable", "date": "2020-05-12 00:00:00 +0900", "snippet": " 이상화 교수님의 확률 및 통계 5강 ‘이산 확률 변수와 연속 확률 변수’ 강의를 듣고 간단하게 내용을 정리해보도록 하겠습니다.1   왜 연속 확률 변수는 특정 실수값의 확률을 정의할 수 없을까?0과 1사이의 ‘모든’ 실수값들 중에서 ‘0.5’라는 숫자를 뽑을 확률을 정의해봅시다. 0과 1사이에는 무수히 많은 숫자들이 있을 것이고. 그 중에서 0.5라는 숫자를 뽑을 확률을 실질적으로는 ‘0’이라고 생각할 수 있습니다.\\[\\cfrac{1}{\\infty} = 0\\]2   그렇다면 연속 확률 변수는 ‘확률’을 어떻게 정의해야 할까?‘특정한’ 값이 아니라 ‘아주 작은 구간’에서 정의할 수 있다. \\(F(x)\\)에 아주 작은 값을 더한 값을 구한 후(\\(F(x+\\Delta x)\\)) , 이를 단위 구간으로 나누어 봅시다.\\[\\begin{aligned}\\lim_{\\Delta \\to 0}\\cfrac{P(x&amp;lt;X&amp;lt;x+\\Delta x)}{\\Delta x} &amp;amp;= \\lim_{\\Delta \\to 0} \\cfrac{F(x+\\Delta x )-F(x)}{\\Delta x}\\\\\\\\&amp;amp;=F&#39;(x)\\end{aligned}\\]이를 통해 다음과 같은 사실을 알 수 있습니다. 연속 확률 변수에서 특정한 값의 ‘확률’을 정의할 수는 없지만 ‘밀도(density)’는 정의할 수 있습니다(밀도는 단위 길이당 특정 확률값을 표현한 것). 밀도는 누적 분포 함수를 ‘미분’ 하면 구할 수 있습니다. 즉 아래와 같은 식이 성립합니다.\\[\\begin{aligned}F&#39;(x) &amp;amp;= f(x)\\\\F(x) &amp;amp;= \\int f(x)dx\\end{aligned}\\] \\(f(x)\\)는 확률 밀도 함수(probability density function, PDF)라고 합니다.확률 밀도 함수(PDF)가 되기 위해서는 다음의 두 조건을 반드시 만족해야 합니다. \\(0\\leq f(x)\\), (그러나 \\(f(x) \\leq1\\)일 필요는 없다. 확률이 아니라 밀도이기 때문). \\(\\int_{-\\infty}^{\\infty} f(x) =1\\).3   마지막으로 헷갈릴만한 개념들을 정리 해봅시다. PMF의 경우, 특정 확률 변수에 상응하는 값이 ‘확률’입니다. 그러나 PDF의 경우, 특정 확률 변수에 상응하는 값이 ‘확률’이 아니라 ‘밀도’입니다. 누적 분포 함수(CDF)는 특정 확률 변수에 해당하는 값이 ‘확률’입니다. 이는 PMF의 CDF나 PDF의 CDF 모두에 공통적으로 해당됩니다." }, { "title": "MAB와 Thomson Sampling", "url": "/posts/MAB/", "categories": "ML, Recommender", "tags": "MAB", "date": "2020-05-07 00:00:00 +0900", "snippet": "MAB를 이해하기 위해 필요한 베타분포(Beta Dist.), 이항분포(Binomial Dist.), 베이지안 추정(Bayesian Estimation), 톰슨 샘플링(Tompson Sampling)과 관련된 내용을 정리하였습니다.1   A/B 테스트 자동화의 필요성특정 캠페인을 진행하면서, 어떤 캠페인의 배너가 더 잘 구매 전환을 유도하는지를 알기 위해 가장 간단하게 시행할 수 있는 A/B 테스트 방법은 배너별 노출 비율을 수동으로 설정하는 것입니다. 동일한 기간에 A 배너와 B 배너의 노출 비율을 50:50으로 고정하여 데이터를 수집하고 평균 분석 등의 통계적 방법론을 적용하는 것이죠. 만일 테스트 종료 후 A 배너가 B배너 보다 더 효과적으로 구매 전환을 유도하는 것으로 결론이 났다고 가정해 봅시다. 기업의 의사결정자 입장에서는 A 배너가 B 배너에 비해서 더 나은 결과를 보인다는 것을 통계적으로 확인하였으니 A 배너를 계속 노출하자는 의사결정을 하게 되겠죠.그런데 그러한 결론을 유도하기 위한 데이터 수집기간 동안 B 배너는 어쨌든 계속 노출될수밖에 없습니다. 결과론적으로 보면 A 배너가 더 좋은 결과를 가져다주는 것을 알 수 있음에도 불구하고 말이죠. 다시말해, B 배너 노출에 따른 손실이 발생하게 된 것으로 볼 수도 있습니다.. A 배너를 더 많이 노출 했으면 더 높은 수익을 얻을 수 있었을 텐데 말이죠. 만일 A 배너와 B 배너의 노출 비율을 상황에 적합하게 실시간으로 조정할 수만 있다면 배너 노출 테스트하는 기간 동안의 기회비용을 줄일 수 있지 않을까요? 이제 MAB에 대해서 알아봅시다.2   MAB 문제MAB(Multi-armed Bandits)란 이름에서 알 수 있듯이 도박꾼이 카지노의 여러 슬롯머신의 레버(arm)을 당겨서 최대의 이익을 달성하려는 모습에서 비롯되었습니다. 도박꾼이 최대 이익을 달성하려면 알려지지 않은 분포를 가진 여러 슬롯머신의 arm을 당겨서 데이터 패턴을 얻어내야 합니다. 그러나 주어진 자원은 한정적이기 때문에 모든 arm을 무한번 당길 수는 없습니다. 다시말해 탐색(exploration)과 선택(exploitation)의 trade-off 문제를 잘 해결할 수 있어야 한다는 것이죠. 이것이 MAB 문제 해결 전략의 핵심이라고 할 수 있습니다.2.1   분포의 필요성우리는 서비스를 진행하면서 어떤 배너에 대해 노출수와 구매 건수(목표 conversion이 구매전환 일 경우) 얻을 수 있습니다. 또한 단순한 사칙연산을 통해서 구매 전환율(구매 건수/노출수)을 얻어 낼 수 있죠. 그런데 그렇게 해서 얻어낸 구매 전환율이 실제 모수를 대표한다고 확신할 수 있을까요? 저희가 얻은 데이터는 표본에 불과하기 때문에, 단순한 표본 통계량으로는 이것이 모수를 대표한다고 단정지어 말할 수 없겠습니다. 그렇다면 얻어진 구매 전환율이 어느정도의 신뢰도 혹은 확신도로 실제 모수를 반영하고 있는지를 ‘정량적’ 지표로 나타낼 수 없을까요? 베타분포(beta)와 이항분포(binomial)를 통해서 표본 데이터에 기반한 모수의 신뢰도를 지속적으로 업데이트 할 수 있습니다.결론부터 말하자면 사전확률분포와 데이터 발생 분포를 각각 베타분포, 이항분포로 가정하면, 사후확률분포도 베타분포임을 도출할 수 있습니다(베타분포는 이항분포의 켤레사전확률분포). 베타분포는 2개의 모수 \\(\\alpha, \\beta\\)를 통해 분포의 모양을 비교적 자유롭게 바꿀 수 있으며, 확률변수가 0~1사이의 실수값이므로, ‘구매 전환율’의 신뢰도를 나타내기의 안성맞춤인 분포이죠.2.2   사전 분포: 베타분포(beta distribution)베타분포는 \\(RV = \\theta(\\in [0,1])\\)을 가지는 분포를 말합니다. 여기서 \\(\\theta\\)는 0~1사이의 실수값을 가지므로, 확률로 해석할 여지가 있습니다. \\(\\theta\\)를 구매 전환율로 볼때, 표본 데이터를 통해 도출한 전환율이 실제 모수임을 어느 정도의 확신 혹은 신뢰할 수 있는지를 이끌어 낼 수 있습니다.\\[\\begin{aligned}Beta(\\alpha, \\beta) &amp;amp;= f(\\theta; \\alpha, \\beta) = P(\\theta; \\alpha, \\beta) \\\\\\\\&amp;amp;= \\cfrac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\\space, \\theta \\in [0, 1] \\\\\\\\&amp;amp;=\\cfrac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\space\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\\end{aligned}\\]\\[B(\\alpha, \\beta) = \\int_{0}^{1}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}d\\theta = \\cfrac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}\\]2.3   데이터 분포(가능도 분포): 이항분포(binomial distibution)이항분포는 독립적인 베르누이 시행을 \\(n\\)번 시행했을 때의 성공 횟수 \\(k\\) 에 대한 분포를 나타냅니다. 이항분포의 PDF는 다음과 같습니다.\\[\\begin{aligned}P(X=k|\\theta) &amp;amp;= B(n, \\theta)\\\\&amp;amp;=\\binom{n}{k} \\theta^{k}(1-\\theta)^{n-k}\\end{aligned}\\] 이항분포에 왜 조합(combination)이 있을까요? 독립적인 동전 던지기 시행을 5번 했을 때, 2번 성공(=앞면이 나옴) 했을 때를 가정해봅시다. 첫번째, 세번째에서 동전의 앞면이 나왔을 때와 두번째 다섯번째에서 동전이 앞면이 나오는 경우는 모두 같은 확률을 나타냅니다. 다시말해, 5개 중 2개를 순서와 상관없이 뽑는 경우를 모두 고려해야하며, 각각의 사건은 서로 배반사건(disjoint, 동시에 발생할 수 없음)입니다.2.4   사후 분포: 베타분포(beta distribution)사후 분포는 사전 분포인 베타분포 \\(P(\\theta)\\)와 데이터 분포인 이항분포 \\(P(k)\\)의 조건부 결합 확률 밀도 함수(joint probability density function)으로로 나타낼 수 있습니다. 결합 확률 밀도 함수에 대한 자세한 내용은 이곳을 참조해 주세요. 아래 식의 결론은 가능도 분포가 이항분포이고 사전확률분포가 베타분포이면 사후 확률분포도 베타분포라는 결론을 나타냅니다.\\[\\begin{aligned}P(\\theta|X=k) &amp;amp;= \\cfrac{P(X=k|\\theta)P(\\theta)}{P(X=k)} \\\\\\\\&amp;amp;=\\cfrac{P(X=k|\\theta)P(\\theta)}{\\int_{0}^{1} P(X=k|\\theta)P(\\theta)d\\theta} \\\\\\\\&amp;amp;= \\cfrac{P(X=k|\\theta)P(\\theta)}{\\int_{0}^{1} P(X=k|\\theta)P(\\theta)d\\theta} \\\\\\\\&amp;amp;= \\cfrac{\\dbinom{n}{k} \\theta^k(1-\\theta)^{(n-k)}{\\cfrac{\\theta^{\\alpha-1}\\theta^{\\beta-1}}{B(\\alpha, \\beta)}}}{\\int P(k|\\theta)P(\\theta)d\\theta} \\\\\\\\&amp;amp;= \\cfrac{\\dbinom{n}{k}{\\cfrac{\\theta^{(\\alpha+k)-1}\\theta^{(\\beta+n-k)-1}}{B(\\alpha, \\beta)}}}{\\int_{0}^{1} P(X=k|\\theta)P(\\theta)d\\theta} \\\\\\\\&amp;amp;= \\cfrac{\\dbinom{n}{k}{\\cfrac{\\theta^{(\\alpha+k)-1}\\theta^{(\\beta+n-k)-1}}{B(\\alpha, \\beta)}}}{\\int_{0}^{1}\\dbinom{n}{k}\\theta^{k}(1-\\theta)^{n-k} \\cfrac {\\theta^{\\alpha-1}\\theta^{\\beta-1}} {B(\\alpha, \\beta)} } \\\\\\\\&amp;amp;= \\cfrac{\\dbinom{n}{k}{\\cfrac{\\theta^{(\\alpha+k)-1}\\theta^{(\\beta+n-k)-1}}{B(\\alpha, \\beta)}}}{\\dbinom{n}{k} \\cfrac{1}{B(\\alpha, \\beta)}\\int_{0}^{1}\\theta^{k}(1-\\theta)^{n-k} \\theta^{\\alpha-1}\\theta^{\\beta-1}} \\\\\\\\&amp;amp;= \\cfrac{\\dbinom{n}{k}{\\cfrac{\\theta^{(\\alpha+k)-1}\\theta^{(\\beta+n-k)-1}}{B(\\alpha, \\beta)}}}{\\dbinom{n}{k} \\cfrac{1}{B(\\alpha, \\beta)}\\int_{0}^{1}\\theta^{\\alpha+k-1}(1-\\theta)^{\\beta+n-k-1}} \\\\\\\\&amp;amp;= \\cfrac{\\dbinom{n}{k}{\\cfrac{\\theta^{(\\alpha+k)-1}\\theta^{(\\beta+n-k)-1}}{B(\\alpha, \\beta)}}}{\\dbinom{n}{k} \\cfrac{B(\\alpha+k, \\beta+n-k)}{B(\\alpha, \\beta)}} \\\\\\\\&amp;amp;= \\cfrac{1}{B(\\alpha+k, \\space \\beta+n-k)} \\space \\theta^{(\\alpha+k)-1}(1-\\theta)^{(\\beta+n-k)-1} \\\\\\\\&amp;amp;= Beta(\\alpha+k, \\space \\beta+(n-k)) \\end{aligned}\\]참고로 \\(P(X=k)\\)는 결합확률분포의 관점에서는 marginal probability이므로, 전확률의 법칙에 따라 아래와 같이 쓸수 있습니다.\\[\\begin{aligned}P(k) &amp;amp;= \\int P(X=k, \\theta)d\\theta \\\\&amp;amp;= \\int P(X=k|\\theta)P(\\theta)d\\theta\\end{aligned}\\]2.5   켤레 사전 확률 분포(conjugate prior distribution)켤레 분포란, 모수는 다르지만, 사전 분포와 사후 분포의 형태를 같게 하는 사전 분포를 뜻합니다.사전분포와 데이터 분포를 각각 베타분포, 이항분포로 가정했을 때, 사후분포는 베타분포이므로 사전분포는 켤레 사전 확률 분포라고 할 수 있습니다.3   배너 선택 전략: 톰슨 샘플링(Thompson Sampling)톰슨 샘플링이란, 도출된 베타 분포에서 확률변수의 observaion을 샘플링하는 기법을 말합니다. 배너 \\(A\\)의 conversion 횟수, expression 횟수를 알고 있으면, \\(\\alpha_{A}\\)와 \\(\\beta_{A}\\)를 다음과 같이 정의할 수 있고 이 두가지 모수만 있으면 각 배너의 베타분포를 그릴 수 있습니다.\\(\\alpha_{A} =\\) 배너 \\(A\\)의 conversion 횟수\\(\\beta_{A} =\\) 배너 \\(A\\)의 expression 횟수 \\(-\\) 배너 \\(A\\)의 conversion 횟수쉽게 와 닿지 않으니 예시를 들어서 설명해보겠습니다. 배너 A는 expression 13회, conversion 4회. 배너 B는 expression 11회, conversion 5회라면 각 배너의 베타 분포는 아래와 같이 나타납니다.여기서 노출시킬 배너를 선택할 수 있는 가장 쉬운 방법은 배너 A와 배너 B의 conversion rate의 기댓값을 뽑아서 기댓값이 높은 배너를 노출 시키는 전략을 취하면 될 것 같습니다. 현재 예시에서 배너 A의 conversion rate 기댓값은 0.307, 배너 B의 conversion rate 기댓값은 0.454입니다. 따라서 우리는 배너 B만 계속 노출시키면 되겠군요(0.307&amp;lt;0.454).그러나 한번만 더 생각 해봅시다. conversion rate의 기댓값이 높은 배너만 계속해서 노출시키는 것이 좋은 판단인지에 대해서 말이죠. 배너 B가 배너 A에 비해 초기 어느 시점에서는 기댓값이 높을 수는 있습니다. 그러나 이러한 현상이 ‘우연히’ 발생 했을 수도 있지 않을까요? 우연히 배너 B를 선호하는 고객이 데이터 수집기간 초기 어느 시점에 잔뜩 유입돼서 배너 B에 편향된 결과를 만들 수도 있었지 않을까요? 우리는 배너 A에 대한 충분한 탐색(exploration)을 하지 못했습니다.아래의 Algorithm 3.1이 greedy 방식의 sampling을 나타냅니다. 우리는 Algorithm 3.2 방식의 톰슨 샘플링을 적용해 보겠습니다. 톰슨 샘플링이란 단순히 기대값이 높은 arm을 선택하는 것이 아니라 베타 분포에서 랜덤 샘플링을 통해 적절한 탐색(exploration)을 진행하고, 새로 관찰된 데이터를 기반으로 베타 분포를 업데이트 하는 방식을 통해 각 arm에 대한 모수를 추정해 나가는 기법을 말합니다. 톰슨 샘플링 기법을 활용하면 탐색(exploration)과 선택(exploitation)을 적절하게 수행해 나갈 수 있습니다.Russo, D., Van Roy, B., Kazerouni, A., Osband, I., &amp;amp; Wen, Z. (2017). A tutorial on thompson sampling.계속 예시를 들어보죠. 톰슨 샘플링 결과 배너 A에서는 0.337, 배너 B에서는 0.271가 샘플링 되었습니다. 배너 A의 conversion rate 기댓값은 더 낫지만, 현재 시점에서는 샘플링 된 conversion rate가 더 큰 배너 A를 노출 시키는 전략(exploration)을 취하면 되겠습니다.결과적으로 N개의 배너 당 2개의 값(conversion 횟수, expression 횟수)만 계속 저장 및 업데이트하면, 베타 분포와 톰슨 샘플링 알고리즘을 통해 적절한 exploration과 exploitation을 진행하여 최적의 배너를 통계 기반으로 찾아갈 수 있겠습니다.4   베이지안 확률값의 비교: 각 배너간 \\(\\theta\\)의 차이가 통계적으로 유의미할까?(추후 업데이트) 각 배너간 구매전환율이 실질적으로 차이가 있는지를 베이지안 확률로 도출할 수 있음 p-value에 의한 가설 검정(빈도주의 방식)은 여러가지 문제점은 안고 있음 베이지안 방법으로 A/B 테스트를 해보자는 것이 요지 https://brunch.co.kr/@gimmesilver/152324" }, { "title": "NLP Transfer Learning History", "url": "/posts/nlp_transfer_learning_history/", "categories": "ML, NLP", "tags": "nlp, transfer learning", "date": "2020-03-05 00:00:00 +0900", "snippet": " 김성현 연구원님의 T아카데미 토크ON세미나 ‘딥러닝 기반의 자연어 언어 모델 BERT’ 라는 세미나를 듣고 알게된 정보와 구글링을 통해 알게된 정보를 종합하여 관련 내용을 정리해 보고자 합니다.1   From word embedding To pretrained language models1.1   Traditional context-free representation1.1.1   One-hot encoding 특징: 단어를 수치화하여 표현하기 위해서 단어 사전 크기의 차원을 가지는 벡터를 만들고 단어의 인덱스에 해당하는 원소만 1, 나머지는 0으로 하여 표현 단점: 단어의 의미(meaning)를 인코딩 할 수 없음, 단어끼리의 유사성을 계산할 수 없음, 매우 sparse한 벡터 표현으로 연산 자원의 낭비를 초래함1.1.2   TF-IDF representation - 통계 기반 기법 특징: 통계적 접근 방법으로서 TF(term frequency)와 IDF(inverse document frequency) 값을 이용하여 단어의 document 내에서의 중요도를 표현할 수 있는(수치화 할 수 있는) 방법 단점: 단어의 의미(meaning)을 인코딩 할 수 없음, one-hot encoding 보다는 덜 하지만 여전히 sparse한 벡터 표현으로 연산 자원의 낭비를 초래함1.2   Distributed similarity based representation: Word embeddings1.2.1   word2vec - 추론 기반 기법 특징: 어떤 단어의 의미는 주변 단어들에 의해 결정된다는 분포가설(distributed hypothesis)에 기초하여 은닉층이 1개인 간단한 인공신경망을 통해 context 단어를 통해 target 단어를 예측 하거나(CBOW), target 단어를 이용하여 context 단어를 예측(skip-gram) 방식을 통해 확률 분포를 모델링함. 그 결과로 얻어진 은닉층 가중치 벡터를 단어의 representation으로 활용함 장점: 단어의 의미(meaning)를 인코딩 할 수 있고, 단어 사이의 유사성도 추론하는 작업을 할 수 있음 단점: OOV(out of vocabulary) 단어들을 처리할 수 없음. 동음이의어처럼 ‘문맥(context)’에 뜻이 달라질 수 있는 상황을 고려하지 못함. subword information이 무시됨(‘서울’, ‘서울시’ 두 단어를 서로 독립된 두 단어로 취급함). 단어의 DF가 낮을 경우(corpus에서 등장 빈도 자체가 적을 경우) 유사한 단어를 찾지 못함1.2.2   Glove(Global vector) - 추론 기반 + 통계 기반 기법 특징: word2vec과 같은 방법은 window size내의 맥락들만 고려 할 수 있고 corpus의 전역적인 특성을 고려하지 못한다는 단점이 존재. 따라서 학습시 corpus 전체의 통계 정보(동시 발생 행렬, co-occurence matrix)를 손실함수에 도입하여 이와 같은 단점을 해소하고자 함 장점: ? 단점: 여전히 OOV 단어를 처리할 수 없음. 단어의 문맥에 따른 의미 변화를 반영할 수 없음.1.2.3   Fasttext 특징: facebook research에서 공개함. word2vec과 유사하지만, 그 과정에서 단어를 n-gram으로 나누어서 학습을 진행한다는 점에서 차이점이 존재함. 장점: OOV에 대응할 수 있음(테스트 단어가 학습 시의 사전에 존재하면 해당 단어의 벡터를 그대로 리턴하지만, OOV일 경우 입력 단어의 n-gram 벡터들의 합을 리턴함). OOV에 대응할 수 있다는 것은 학습시 사용되지 않았지만 오탈자가 없는 ‘정상적인 단어’에 대해서도 대응을 할 수 있다는 것 외에도 ‘오탈자’에 대해서도 대응을 할 수 있다는 것을 의미함. subword information을 고려할 수 있기 때문에 DF가 낮은 단어도 word2vec에 비해 유사한 단어를 잘 찾을 수 있음 단점: 여전히 단어의 문맥에 따른 의미의 변화를 고려할 수 없음2   contextualized representationscontext-free representation 방법론은 공통적으로 한 단어의 의미가 항상 고정(stable)하다고 보는 큰 한계점이 있었다. 다시말해 동음이의어인 단어를 여러가지 의미로 보는 것이 아니라 단어의 ‘형태’가 같으면 같은 의미로 파악하는 것이다. 이것을 개선하기 위해서 언어모델(language model)에 기반한 contextualize representation 방법론이 등장하게 되었다.NLP task의 데이터셋의 크기는 높은 성능을 얻기 위한 재료의 관점에서 볼 때, 그 사이즈가 부족한 것이 현실인데 이 때문에 NLP task에 사용할 neural network를 깊게 디자인 하기 힘들다(작은 데이터셋에 깊은 신경망을 쓰면 overfit이 발생하고 일반화 성능을 얻기 힘듦). 반면에 vision task의 경우 대규모의 학습 데이터셋인 ImageNet이 공개 되어 있다. 따라서 자신의 실제 task에 적용시키기 전에 pre-training을 통해 일반적인 이미지 feature를 추출는 방법을 모델로 하여금 학습하도록 하고, 실제 task에서는 소규모의 데이터셋으로 fine-tuning을 통해 높은 성능을 끌어낼 수 있었다.NLP task에서도 소규모 데이터셋을 이용하면서도 높은 성능을 이끌어 내기 위해 pre-training 방법론이 제안되어져 왔다. 이는 언어 모델(language model)을 통해서 실현이 가능하다.NLP task를 진행하는 전통적인 방법은 word embedding 기술을 활용하여 학습을 수행할 모델의 input값을 초기화 시킨 후 모델의 학습을 진행하는 것이었다면, 최근의 NLP task의 흐름은 pre-trained language model(문장 내에서 단어들의 관계성을 high-level 수준으로 이미 알고 있는 모델)을 활용하여 마지막 레이어만 특정 task에 맞게 수정하여 사용하는 방식으로 바뀌었다.2.1   ELMo(Embeddings from Language Models)문장에 등장하는 단어는 그 문맥에 따라 다른 의미를 지니고 있는 경우가 많다. 예를 들어 ‘사과’는 ‘사과가 맛있다.’라는 문장에서는 ‘과일’을 의미하며, ‘그녀에서 나의 잘못을 사과하였다.’라는 문장에서는 ‘자기의 잘못을 인정하고 용서를 빎’이라는 의미이다. 이처럼 자연어는 형태는 같지만 다양한 의미를 지니고 있다. 다시 말해서 해당 단어가 어떤 문맥 에서 사용되었는지에 따라 그 의미가 다르다는 것이다. 그러나 앞서 언급한 것처럼 그간 word prepresentaion 방법은 어떤 문맥에서 단어가 상관되었는지에 관계없이 고정된 하나의 벡터만을 가질 수 있었다.ELMo는 그간의 word representation이 문맥을 반영하지 못한다는 한계점을 지적하며, 문맥에 따라 representation을 다르게 하여 context를 반영한 representation 방법을 제안한다. ELMo는 NLP의 전이학습의 시작점을 제공한 모델로서, bi-directional LSTM 모델을 통해 다음에 올 토큰을 예측하는 언어 모델(language model)이다.2.2   ULMFiT(Universal Language Model Fine-tuning)2.3   TransformerNMT(neural machine translation) 문제를 해결하기 위해 고안된 모델로서 기존의 NMT에서 주로 사용되던 LSTM이 가지는 병렬연산 불가 문제를 해결하였다. seq2seq 모델과 마찬가지로 encoder와 decoder 구조로 이루어져 있지만, RNN 계열의 cell을 사용하지 않고 이를 transformer로 대체하였다. 특히 self-attention 구조를 제안한 것이 특징이다. 기존의 seq2seq with attention 모델의 경우에는 source sentence를 target sentence로 변환하는 과정에서 target word와 source word 관계에 대해서만 설명할 수 있었고(디코더의 출력이 인코더의 어느 부분에 주목한 결과인지 알 수 있음). 그러나 source word 간의 관계에 대해서를 설명할 수 없는 단점이 있었다. 예를 들어 “나는 배가 고파서 사과를 먹었는데, 그것은 상해 있었다.”라는 문장에 대해서 ‘사과’와 ‘그것’의 관계를 주목할 수 없었다는 것이다. transformer는 self-attention 구조를 통해서 이를 해결하였다. 이후에 등장하는 GPT, BERT는 NMT 문제에 적용된 transfomer를 어떻게 downstream task에 적용 할 수 있을지를 고민하여 탄생한 모델이다.2.4   GPT(Generative Pre-Training Transformer)transfomer의 decoder 부분만 활용하였다.2.5   BERT(Bidirectional Encoder Representation from Transformer)지금까지 transformer 기반의 모델은 ELMo가 제안하였던 bi-directional 방법을 고려하지 못하였다. BERT는 transformer의 encoder만을 활용한 모델인데, 인풋 토큰의 일부를 가리는 mask 토큰을 삽입하여 모든 문맥을 고려한(mask 토큰의 앞과 뒤) mask language model이다. 이를 통해 transformer와 ELMo의 장점을 모두 취할 수 있었다.참고자료 김성현, T아카데미 토크ON 세미나 - 딥러닝 기반의 자연어 언어 모델 BERT From Word Embeddings to Pretrained Language Models — A New Age in NLP [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](" } ]
