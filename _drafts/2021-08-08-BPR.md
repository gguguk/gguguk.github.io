---
title: "'Bayesian Personalized Ranking from Implicit Feedback' 논문 리뷰"
author: Gukwon Koo
categories: [ML, Paper Review]
tags: [bpr, review]
pin: false
math: true
comments: false
date: 2021-08-08 17:37:00 +0900
---

![](/assets/img/post_img/bpr_paper.png)_"BPR: Bayesian Personalized Ranking from Implicit Feedback" 논문_

<br>

추천 시스템 분야는 일반적인 다른 머신러닝 분야와 다르게 데이터에 '랭킹'이라는 특성이 있습니다. 다시 말해 어떤 유저에게 아이템을 추천해 줄 때, 추천 아이템 간의 상대적인 순위의 차이가 있다는 것입니다. 이처럼 데이터에서 랭킹을 학습하는 추천을 LTR(Learning To Rank)라고 부르며, loss function에서 몇 개의 데이터를 고려하는지에 따라 point-wise, pair-wise, list-wise approach로 분류됩니다(조금 더 자세한 내용은 잘 정리된 [블로그](https://yamalab.tistory.com/119)를 추천드립니다).

BPR 논문은 pair-wise approach 입니다(또 다른 유명한 pair-wise approach로는 [RankNet](https://dl.acm.org/doi/pdf/10.1145/1102351.1102363?casa_token=c_IDknR7MdsAAAAA:iEW47ml6hOG5_BH3jE26pDyANzMhIfp6nR5D5L_6QZZnoQNV0yR_AGKAMmXm_zoA6v0gGljBIG3adS4J)이 있습니다). 조금 더 정확히 말하면, 베이지안의 개념을 빌려와서 pair-wise approach를 optimization 하는 방법을 제안합니다. 본 글에서는 저자가 주장하는 핵심 개념을 정리합니다.

### **Keyword**

MAP, Bayesian, pair-wise ranking loss

<br>

# Introduction

---

## Implicit data

아이템을 추천하는 task는 user의 과거 interaction 데이터(e.g., 평점, 클릭 등)를 기반으로 특정 item set에 대해 user-specific 한  ranking을 생성하는 것입니다. 따라서 과거 user의 interaction 데이터가 추천 품질에 있어 매우 중요한데, 대부분의 최근 연구들은 explicit 데이터에 집중되어 있었습니다. 그러나 explicit data 보다는 implicit data(e.g., 클릭, 구매 등)가 훨씬 수집이 용이하고, 이러한 데이터가 기반한 추천 시스템이 현실적인 시나리오 더 적합하다고 볼 수 있습니다. 그러므로 본 논문에서는 implicit data에 기반한 ranking 최적화 기법을 제안합니다.



## Contribution

본 논문에서는 implicit data에 기반하여 개인화된 ranking을 제공하는 모델을 제안합니다. 특히 다음과 같은 기여점이 있습니다.

- BPR-OPT 제안
  - MAP(Maximum a Posteriori)에 기반한 최적화 기법. 
  - 사후 확률을 최대화 시키는 parameter $$\Theta$$ 학습
- LearnBPR
  - BPR-OPT를 최대화 하기 위해 SGD(Stochastic Gradient Decent)에 기반한 학습 알고리즘

<br>

# Personalized Ranking

---

## Formalization

먼저 다음과 같이 notation을 정의합니다.

- 모든 유저의 집합 $$U$$, 모든 아이템의 집합 $$I$$
- implicit feedback 데이터 $$S (\subset U \times I)$$

추천 시스템의 task는 유저 $$u$$에게 개인화된 아이템 집합인 $$\gt_{u} (\subset I^2)$$를 제공하는 것입니다. $$\gt_{u}$$는 다음의 속성을 만족하는 집합입니다.

<br>

$$\forall i,j \in I: i \neq j \Rightarrow i \gt_{u} j \space \vee j \gt_{u} i \tag{totality}$$

$$\forall i, j \in I: i \gt_{u} j \space \wedge j \gt_{u} i \Rightarrow i=j \tag{antisymmetry}$$

$$\forall i,j,k \in I : i \gt_{u} j \space \wedge j \gt_{u} k \Rightarrow i \gt_{u} k \tag{transitivity}$$

<br>

Formalization 부분이 매우 간단하게 설명되어 있어서 이해하느라 좀 애를 먹었습니다... 먼저 전체 아이템 셋이 $$I=\{I_{1}, I_{2}, I_{3}\}$$이라고 할 때 $$I^{2}$$는 [카테시안 곱](http://www.ktword.co.kr/test/view/view.php?m_temp1=6201)입니다. 

<br>

$$I^{2}=\{ (a, b) \vert  i, j \in I\} = \{ (i_1, j_1), (i_1, j_2), \dots, (i_3, j_2), (i_3, j_3) \}$$

<br>

만일 유저 $$u$$가 $$I_2$$보다 $$I_1$$을 선호하고, $$I_3$$ 보다 $$I_1$$를 선호하면 $$\gt_{u}$$는 다음과 같이 나타낼 수 있겠습니다.

<br>

$$\gt_{u} = \{(i_1, j_2), (i_1, j_3), (j_1, i_2), (j_1, i_3)\}$$

<br>

이때 $$\gt_{u}$$는 $$I^{2}$$의 부분 집합으로서 유저의 개인화된 아이템 쌍의 집합이라고 이해하면 쉽습니다. 그 쌍의 아이템끼리 선호의 순위가 있는 것입니다.

<br>

## Analysis of the problem setting

본 논문에서는 유저별 개인화된 아이템 랭킹을 implicit data를 기반으로 도출합니다. implicit feedback 데이터는 오직 positive observation만 활용 가능하다는 흥미로운 특성이 있습니다. non-observed user-item 쌍은 단순히 negative feedback을 의미하지 않는다는 것이 중요합니다. 예를 들어 어떤 유저 $$u$$가 아이템 $$i$$를 아직 구매하지 않아서 해당 쌍이 로그 데이터에 없다고 가정해봅시다. 무조건 유저 $$u$$가 아이템 $$i$$에 만족하지 않아서 구매하지 않았다고 할 수 있을까요? 혹시 아이템 $$i$$에 흥미를 느꼈지만 나중에 구매하려고 미뤄두었을 수도 있지 않을까요? 저자는 이를 조금 유식하게 표현하는데요. 관측되지 않는 데이터에는 negative feedback과 missing value가 혼재되어 있다고 표현합니다.

non-observed data를 다루는 가장 평범한 접근 방법은 이를 모두 negative feedback으로 처리하는 방법입니다. 이러한 경우를 user-item matrix로 표현 하면 다음과 같이 표현할 수 있습니다.

![](/assets/img/post_img/bpr_missing_value.png){:width=200}

좌측의 matrix에서 $$+$$는 관측된 데이터, $$-$$는 관측되지 않는 데이터를 말합니다. 이 데이터를 이용하여 학습을 하기 위해서는 적절한 숫자로 변환시켜 주어야 하는데요. 우측의 matrix처럼 관측된 데이터는 1로, 관측되지 않는 데이터는 0으로 변환할 수 있습니다. **그러나 데이터를 이러한 방법으로 표현하면 향후에 유저가 선호할수도 있는 아이템을 '싫어한다는' 것으로 표현되는 문제가 있습니다.** 다시 말해 관측되지 않는 데이터를 단순히 negative feedback으로만 표현하는 것이 문제라는 것이죠. missing value 일수도 있는데 말이죠.

따라서 저자는 몇가지 가정에 기반하여 pair-wise 데이터 셋을 만들어서 사용합니다.

- 1) 유저는 관측된 아이템 $$i_1$$을 관측되지 않는 아이템 $$i_2$$ 보다 선호함 ($$i_1 \gt_{u} i_2$$)
- 2) 관측된 아이템 간에는 선호의 차이를 알 수 없음
- 3) 관측되지 않은 아이템 간에는 선호의 차이를 알 수 없음

![](/assets/img/post_img/bpr_new_approach.png){:width=200}

왼쪽 데이터셋을 보면 유저 $$u_1$$는 아이템 $$i_2(=j_2)$$, $$i_3(=j_3)$$과 interaction이 있었네요. 저자는 이러한 데이터 셋을 오른쪽 데이터셋 처럼 pair-wise 형태로(두 쌍의 아이템은 선호의 순위가 있음) 표현하였습니다. 여기서 (+)는 아이템 $$i$$를 $$j$$ 보다 선호하는 것을 나타내며 (-)는 아이템 $$j$$를 $$i$$ 보다 선호하는 것으로 표현하였습니다. 오른쪽 데이터셋에서 유저 $$u_1$$을 보면 쉽게 이해할 수 있는데요. *가정 1)*에 의해서 아이템 $$i_2$$가 $$j_1$$과 $$4$$ 보다 선호되며, $$i_3$$은 $$j_1$$과 $$j_4$$ 보다 선호되는 것을 알 수 있습니다. ? 기호는 *가정 2)* 와 *가정 3)*에 의해서 선호의 차이를 알 수 없는 경우입니다.

이런 데이터셋 $$D_s$$는 다음과 같이 수식으로 표현 할 수 있습니다. $$(u, i, j) \in D_s$$는 유저 $$u$$가 아이템 $$i$$를 아이템 $$j$$ 보다 선호한다는 의미입니다.

<br>

$$D_s := \{(u, i, j) \vert i \in I^{+}_{u} \wedge j \in I^{-}_{u} \}$$

<br>

# Bayesian Personalized Ranking(BPR)

---

본 섹션에서는 개인화된 아이템 랭킹 task를 다루기 위한 방안을 제안합니다. 이는 크게 베이즈 추론에 기반하여 optimization score를 구하는 **BPR-OPT**와 BPR-OPT를 기반으로 사후확률을 최대화하는 파라미터 $$\Theta$$를 찾는(MAP) **LearnBPR** 알고리즘으로 이루어져 있습니다.
<br>

## BPR Optimization Criterion (BPR-OPT)

MAP(Maximum a posteriori)는 다음의 수식을 최대화 하는 파라미터 $$\Theta$$를 찾는 알고리즘입니다.

$$p(\Theta \vert \gt_u)$$

# Reference

---

- [Pointwise vs. Pairwise vs. Listwise Learning to Rank](https://medium.com/@nikhilbd/pointwise-vs-pairwise-vs-listwise-learning-to-rank-80a8fe8fadfd)
- [Learning to Rank와 nDCG](https://yamalab.tistory.com/119)
- [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://wonjun.oopy.io/papers/bpr-bayesian-personalized-ranking-from-implicit-feedback)

